% -*- latex -*-

%
% MICO documentation
%
%  Copyright by Kay Roemer, Arno Puder & Frank Pilhofer
%
%  This file may be freely distributed and copied, but you may *not*
%  change or modify it. This copyright also applies to all the figures
%  which are part of the documentation.
%

\documentclass[12pt,a4paper]{report}

\usepackage{html}
\usepackage{a4}
\usepackage{vmargin}
\usepackage{supertabular}
\usepackage{epsfig}

\setpapersize{A4}
\setmargrb{2.5cm}{2cm}{2.5cm}{2cm}

% Variable \halftextwidth defines a bit less than half of \textwidth
\newlength{\halftextwidth}
\setlength{\halftextwidth}{7.5cm}


\newcommand{\MICO}{\textsc{Mico}}


\begin{document}

\begin{latexonly}

\thispagestyle{empty}

\vspace*{2cm}
\begin{center}
\mbox{\psfig{file=mico.ps,width=\textwidth}}\\[3cm]
{\LARGE An Open Source CORBA 2.3 Implementation}\\[10cm]
\hrule
\vspace*{2mm}\raggedleft Version @VERSION@
\end{center}

\newpage

\section*{Acknowledgements}

Many people have worked on \MICO\ to make it what it is today. The
CORBA core has been implemented by Kay R\"omer, Arno Puder and Frank
Pilhofer.\\[1ex]

\noindent
The following people have made contributions to \MICO: Kai-Uwe
Sattler, Lars Doelle, Owen Taylor, Elliot Lee, Christian Becker, Ben
Eng, Andrew Metcalfe, Christoph Best, Andreas Schultz, Martin Sander,
Rudolf Janz, Marcus M"uller, Karel Gardas, Leif Jakobsmeier, Torben
Weis, Jacques Tremblay, Wil Evers, Massimo Di Giorgio, Carsten Zerbst.


\setcounter{page}{1} 
\pagenumbering{roman}

\tableofcontents

\listoffigures
\addcontentsline{toc}{chapter}{List of Figures}

\newpage
\setcounter{page}{1}
\pagenumbering{arabic}

\end{latexonly}

\newpage


%-------------------------------------------------------------------------
\chapter{What is MICO?}

The acronym \MICO\ expands to \textbf{M}ICO \textbf{I}s
\textbf{CO}RBA. The intention of this project is to provide a
\emph{freely available} and \emph{fully compliant} implementation of
the CORBA standard (see \cite{corba}). \MICO\ has become quite popular
as an OpenSource project and is widely used for different purposes. As
a major milestone, \MICO\ has been branded as <a CORBA compliant by
the OpenGroup, thus demonstrating that OpenSource can indeed produce
industrial strength software. Our goal is to keep \MICO\ compliant to
the latest CORBA standard. The sources of \MICO\ are placed under the
GNU--copyright notice (see chapter \ref{SEC_GNU_LICENSE}). The
following design principles guided the implementation of \MICO:\\[1.5ex]

\noindent
\begin{minipage}[b]{12cm}
\begin{enumerate}
\item start from scratch: only use what standard UNIX API has to offer;
  don't rely on proprietary or specialized libraries.
\item use C++ for the implementation.
\item only make use of widely available, non--proprietary tools.
\item omit ``bells and whistles'': only implement what is required for
  a CORBA compliant implementation.
\item clear design even for implementation internals to ensure
  extensibility.
\end{enumerate}
\end{minipage}
\hfill
\begin{minipage}[t]{3cm}
\psfig{file=corba-brand.ps,width=3cm}
\end{minipage}

$ $\\[1.5ex]
You should visit our homepage frequently for updates. We will continue
to develop \MICO, providing bug fixes as well as new features.
Information about the \MICO\ project is available at 
\texttt{http://www.mico.org}.

Further informations about \MICO\ can be found in the book \emph{MICO:
  An Open Source CORBA Implementation} published by dpunkt.verlag
(\texttt{http://www.dpunkt.de/mico}) in Europe and Morgan Kaufmann
Publishers, Inc.
(\verb|http://www.mkp.com/mico|) in North
America. The book includes a CD with the complete source code of
\MICO\ as well as binaries for various platforms as ready to run
executables.  It explains how to install and use \MICO. A little
tutorial gets you going with a sample CORBA application. All features
of \MICO\ are well documented both in the manual and in online
man--pages. \MICO\ is fully interoperable with other CORBA
implementations, such as Orbix from Iona or VisiBroker from Inprise.
The manual contains a step--by--step procedure showing how to connect
\MICO\ with other CORBA implementations. It even includes sample
programs from various CORBA textbooks to show you all aspects of
CORBA.


\newpage
\noindent
\textbf{How to support MICO}\\[1.5ex]
The authors have worked very hard to make \MICO\ a usable and free
CORBA 2.3 compliant implementation. If you find \MICO\ useful and
would like to support it, there is an easy way to do so: contribute to
the development of \MICO\ by implementing those parts of the CORBA
standard, which are still missing in \MICO. Although \MICO\ is fully
CORBA 2.3 compliant, there are some parts of the standard (like the
CORBAservices) which are not mandatory and which we did not implement.
We hope that our decision to place the complete sources of \MICO\ 
under the GNU public license will encourage other people to contribute
their code (see section \ref{SEC_GNU_LICENSE} for details).

%-------------------------------------------------------------------------
\chapter{Installation}
\label{SEC_INSTALLATION}

This chapter explains from where \MICO\/ can be obtained, the
prerequisites for compiling \MICO\/, how to compile and install
\MICO\/, and on which platforms \MICO\/ has been tested.


%-------------------------------------------------------------------------
\section{Getting MICO}
\label{SEC_GETTING_MICO}

The latest \MICO\/ release is always available at

\small
\begin{verbatim}
  http://www.vsb.cs.uni-frankfurt.de/~mico/
  http://www.icsi.berkeley.edu/~mico/
  ftp://diamant.vsb.cs.uni-frankfurt.de/pub/projects/mico/mico-@VERSION@.tar.gz
\end{verbatim}
\normalsize

\noindent
New releases are announced over the \MICO\/ mailing list. If you want to
subscribe send a message containing

\begin{verbatim}
  subscribe mico-devel
\end{verbatim}

\noindent
to \verb|majordomo@vsb.cs.uni-frankfurt.de|.


%-------------------------------------------------------------------------
\section{Prerequisits}
\label{SEC_PREREQUISITS}

\subsection{Unix}

Before trying to compile \MICO\/ make sure you have installed the following
software packages:

\begin{itemize}
\item gnu make version 3.7 or newer (required)
\item C++ compiler and library (required):
  \begin{itemize}
  \item g++ 2.7.2.x and libg++ 2.7.2, or
  \item g++ 2.8.x and libg++ 2.8.x, or
  \item egcs 1.x
  \end{itemize}
\item flex 2.5.2 or newer (optional)
\item bison 1.22 or newer (optional)
\item JDK 1.1.5 (SUN's Java developers kit) (optional)
\item JavaCUP 0.10g (parser generator for Java) (optional)
\end{itemize}

\noindent
\texttt{flex} and \texttt{bison} are only necessary if you change
their input files (files having the suffix \texttt{.l} and
\texttt{.y}) or if you want to compile the graphical user unterface.
The last two items (JDK and JavaCUP) are only needed for the graphical
interface repository browser, not for \MICO\/ itself. So you can get
along without installing the Java stuff.

It is important that you use one of the above listed C++ compilers and
a C++ library that matches the version of the compiler. Your best bet
is using either egcs or g++ 2.8. In contrast to gcc 2.7.2 both of them
have proper support for exceptions. egcs is a bit easier to install
than g++, because it includes a matching C++ library.

\subsection{Windows 95/NT using Cygnus CDK}

In order to run \MICO\/ on Windows 95 or NT you have to use the
\emph{Cygnus CDK beta 19}, a port of the GNU tools to Win32 or
Microsoft's Visual--C++ compiler. For instructions on how to compile
\MICO\ using the Visual--C++ compiler, refer to Section
\ref{SEC_MICO_INSTALL_WIN32}.

\noindent
Install the CDK by running its setup program. Note that you have to
install it in the directory the setup program suggests
(\texttt{c:$\backslash$Cygnus$\backslash$CDK$\backslash$B19});
otherwise \texttt{bison} won't be able to find its skeleton
files. Then create \texttt{c:$\backslash$bin} and put an
\texttt{sh.exe} into it.  Likewise create \texttt{c:$\backslash$lib}
and put a \texttt{cpp.exe} into it:

\begin{verbatim}
  mkdir c:\bin
  copy c:\Cygnus\CDK\B19\H-i386-cygwin32\bin\bash.exe c:\bin\sh.exe
  mkdir c:\lib
  copy c:\Cygnus\CDK\B19\H-i386-cygwin32\lib\gcc-lib\2.7-B19\cpp.exe c:\lib
\end{verbatim}

\noindent
Now you are ready to unpack and compile \MICO\/ as described in section
\ref{SEC_INSTALLING_MICO}.

There are some problems with the current release of the CDK:

\begin{itemize}
\item On standalone machines which are not connected to a name server
  resolving IP addresses other than 127.0.0.1 into host names
  will hang forever. This is either a problem with the CDK or with
  Windows in general. On standalone machines you therefore have to
  make all servers bind to 127.0.0.1 by specifying
  \texttt{-ORBIIOPAddr inet:127.0.0.1:<port>} on the command line.
\item The gcc 2.7 that comes with the CDK has broken exception
  handling.  Furthermore it seems to be unable to use virtual memory,
  at least I get \texttt{out of virtual memory} errors although there
  is a lot of free swap space.  I know there are ports of egcs and gcc
  2.8 (which might do better), but didn't give them a try.
\item There seems to be a problem with automatic TCP port number selection.
  Usually one binds to port number 0 and the system automatically picks
  an unused port for you. This basically works with CDK, but sometimes
  causes hanging connections. The solution is to always explicitely
  specify port numbers, i.e. give \emph{all} servers---even ones that
  are started by \texttt{micod}---the option
  \texttt{-ORBIIOPAddr inet:<host>:<port>}, where \texttt{<port>} is nonzero.
\end{itemize}


%-------------------------------------------------------------------------
\section{Installing MICO under Unix}
\label{SEC_INSTALLING_MICO}

The \MICO\/ source release is shipped as a tar'ed and
gzip'ed archive called 

\small
\begin{verbatim}
  mico-@VERSION@.tar.gz
\end{verbatim}
\normalsize

\noindent
Unpack the archive using the following command:

\small
\begin{verbatim}
  gzip -dc mico-@VERSION@.tar.gz | tar xf -
\end{verbatim}
\normalsize

\noindent
You are left with a new directory \texttt{mico} containing the \MICO\/
sources.  To save you the hassle of manually editing \texttt{Makefile}'s
and such, \MICO\/ comes with a configuration script that checks your
system for required programs and other configuration issues. The script,
called \texttt{configure}, supports several important command line
options:

\begin{description}
\item[\texttt{--help}]
  ~\newline
  Gives an overview of all supported command line options.
\item[\texttt{--prefix=<install-directory>}]
  ~\newline
  With this options you tell configure where the \MICO\/ programs and
  libraries should be installed after compilation. This defaults to
  \texttt{/usr/local}.
\item[\texttt{--enable-corba2-1}]
  ~\newline
  This option makes \MICO\ compliant to the version 2.1 of
  the CORBA standard due to some backward incompatibilities with later 
  releases of the standard.
\item[\texttt{--disable-optimize}]
  ~\newline
  Do not use the \texttt{-O} option when compiling C/C++ files. It is
  now safe to use this option because only files that do not use
  exceptions are compiled using \texttt{-O}, which is why optimization
  is now turned on by default.
\item[\texttt{--enable-debug}]
  ~\newline
  Use the \texttt{-g} option when compiling C/C++ files.
\item[\texttt{--enable-repo}]
  ~\newline
  Use the \texttt{-frepo} flag when compiling C++ files. This works only
  with a patched g++ 2.7.2 and will greatly reduce the size of the
  binaries, at the cost of much slower compilation (this option
  instructs g++ to do some sort of template repository). You \emph{must}
  use this option on HP--UX, otherwise you will get lots of error during
  linking.
\item[\texttt{--disable-shared}]
  ~\newline
  Build the \MICO\/ library as a static library instead as a shared one.
  Shared libraries currently only work on ELF based systems (e.g., Linux,
  Solaris, Digital Unix, AIX, and HP--UX). If you do not use
  the \texttt{--disable-shared} option you have to make
  sure the directory where the \MICO\/ library resides is either
  by default searched for shared libraries by the dynamic linker
  (\verb|/usr/lib| and \verb|/lib| on most systems) or you have to include
  the directory in the environment variable that tells the dynamic linker
  where to search for additional shared libraries. This variable is called
  \verb|LIBPATH| on AIX, \verb|SHLIB_PATH| on HP--UX and
  \verb|LD_LIBRARY_PATH| on all the other systems. To run
  the generated binaries before doing a \texttt{make install} you have to
  set this environment variable like this:
  \begin{verbatim}
    # AIX
    export LIBPATH=<mico-path>/mico/orb:$LIBPATH
    # HP-UX
    export SHLIB_PATH=<mico-path>/mico/orb:$SHLIB_PATH
    # others
    export LD_LIBRARY_PATH=<mico-path>/mico/orb:$LD_LIBRARY_PATH
%$
  \end{verbatim}
  where \texttt{<mico-path>} is the absolute path of the directory
  the \MICO\/ sources were unpacked in.
\item[\texttt{--disable-dynamic}]
  ~\newline
  This option disables dynamic loading of CORBA objects into a running
  executable. For dynamic loading to work your system must either support
  \texttt{dlopen()} and friends or \texttt{shl\_load()} and friends.
  See section \ref{SEC_ACTIV_MODES} for details.
\item[\texttt{--enable-final}]
  ~\newline
  Build a size optimized version of the \MICO\/ library. This will need
  lots of memory during compilation but will reduce the size of the resulting
  library a lot. Works with and without
  \texttt{--enable-shared}. Does not work on HP--UX.
\item[\texttt{--disable-mini-stl}]
  ~\newline
  As mentioned before, \MICO\/ makes use of the Standard Template
  Library (STL). For environments that do not provide an STL
  implementation, \MICO\/ comes with its own slim STL (called
  MiniSTL), which is simply a subset of the standard STL sufficient to
  compile \MICO. By default \MICO\/ will use MiniSTL. If you want to use
  the system supplied STL for some reason you have to use the option
  \texttt{--disable-mini-stl}. MiniSTL works well with g++ and
  greatly reduces compilation time and size of the binaries.  Using
  MiniSTL one could try to compile \MICO\/ using a C++ compiler other
  than g++. But this still has not been tested and may therefore lead to
  problems.
\item[\texttt{--disable-except}]
  ~\newline
  Disable exception handling. On some platforms (e.g., DEC alpha) g++
  has very buggy exception handling support that inhibit the
  compilation of \MICO\/ with exception handling enabled. If this
  happens try turning off exception handling using this option.
\item[\texttt{--with-qt=<qt-path>}]
  ~\newline
  Enable support for QT. \texttt{<qt-path>} is the directory where QT has
  been installed in.
\item[\texttt{--with-gtk=<gtk-path>}]
  ~\newline
  Enable support for GTK. \texttt{<gtk-path>} is the directory where
  GTK has been installed in.
\item[\texttt{--with-tcl=<tcl-path>}]
  ~\newline
  Enable support for TCL. \texttt{<tcl-path>} is the directory where
  TCL has been installed in.
\item[\texttt{--with-ssl=<SSLeay-path>}]
  ~\newline
  Enable support for SSL. \texttt{<SSLeay-path>} is the directory where
  SSLeay has been installed in.
\end{description}

\noindent
Now you should run \texttt{configure} with the proper command line options
you need, e.g.:

\small
\begin{verbatim}
  cd mico
  ./configure --with-qt=/usr/local/qt
\end{verbatim}
\normalsize

\noindent
Use \texttt{gmake} to start compilation and install the programs and libraries,
possibly becoming root before installation:

\small
\begin{verbatim}
  gmake
  gmake install
\end{verbatim}
\normalsize

\noindent
On some systems you have to take special actions after installing a
shared library in order to tell the dynamic linker about the new library.
For instance on Linux you have to run \verb|ldconfig| as root:

\small
\begin{verbatim}
  /sbin/ldconfig -v
\end{verbatim}
\normalsize

%-------------------------------------------------------------------------
\section{Installing MICO using Visual--C++}
\label{SEC_MICO_INSTALL_WIN32}

Installing \MICO\ under Windows using the Visual--C++ compiler is
sufficiently different to dedicate it its own section. Beware that
this compiler is not among the technically most solid pieces of
engineering and you should make sure that you have applied all Service
Packs there are (Microsoft terminology for bug fixes). It is also
advisable to check the latest release notes for \MICO\ on the Windows
platform which are contained in the file \texttt{README-WIN32}.


\subsection{Prerequisits}
\label{SEC_PREREQ_WIN32}

You will need Visual--C++ 5.0 Service Pack 3 or (preferred)
Visual--C++ 6.0 Service Pack 2 to compile \MICO\ for Windows. Note
that without Service Pack 3 for Visual--C++, you will not be able to
compile the sources or write \MICO\ applications. Windows version of
flex and bison are not required. The \MICO\ distribution already
contains the files generated by these tools. VC++ 5.0 SP3 is
available from:

\small
\begin{verbatim}
http://www.microsoft.com/msdownload/vs97sp/full.asp
\end{verbatim}
\normalsize

\noindent
VC++ 6.0 service packs are available at:

\small
\begin{verbatim}
http://msdn.microsoft.com/vstudio/sp/default.asp
\end{verbatim}
\normalsize

The Windows 95 implementation of the TCP/IP protocol stack cause
problems with \MICO\ applications. You need to download and install
the WinSock2 library which fixes these problems. You can download
WinSock2 from the Microsoft web server for free:

\small
\begin{verbatim}
http://www.microsoft.com/windows95/downloads/contents/wuadmintools/\
           s_wunetworkingtools/w95sockets2/default.asp?site=95
\end{verbatim}
\normalsize


IMPORTANT: You also need to make sure that the environment variables
are set properly for Visual--C++. There is a batch file called
\texttt{VCVARS32.bat} specifically for this purpose. Be sure to run
this batch file --- which is part of VC++ --- before you try to
compile \MICO.

Once you have made sure that your Windows platform meets all the above
mentioned prerequisits, you can unpack the \MICO\ sources. The sources
are shipped as a zipped archive on the CD called

\small
\begin{verbatim}
  mico-<version>.zip
\end{verbatim}
\normalsize

\noindent
Where \texttt{<version>} is the version number of the \MICO\/ release
contained on the CD. Unpack the archive at the desired location.



\subsection{Compiling the MICO sources}

Change to the directory where you have unzipped the \MICO\ sources and
edit the file \texttt{MakeVars.win32}. Set the \texttt{SRCDIR}
variable to the location of the \MICO\ directory (no trailing
backslash). There is no need to run a configure script. \MICO\ is
pre-configured for Windows.

VC++ comes with its own Makefile tool called nmake. Unfortunately
this tool is sufficiently incompatible with other make tools. For this
reason the \MICO\ distribution contains a second set of Makefiles.
These Makefiles have the suffix \texttt{.win32} and are tailored to
work with nmake. To compile \MICO\ on your system, type the following
in the \MICO\ top level directory:

\small
\begin{verbatim}
  nmake /f Makefile.win32
\end{verbatim}
\normalsize

\noindent
If you are running Windows 95/98, the command line shell suffers from
some serious deficiencies. On those platforms you need to invoke the
compilation process using the following command instead:

\small
\begin{verbatim}
  nmake /f Makefile.win32 w95-all
\end{verbatim}
\normalsize

\noindent
The make process will build all the necessary DLLs and executables in
a subdirectory called \texttt{win32-bin}, which will be created during
compilation. The content of this directory is the only thing you need
for building \MICO\ applications. You can move it to your preferred
location. The build will require around 150MB (the demo directory
another 90MB).

You should modify the \texttt{PATH} environment variable to include
this directory. If, for example, the MICO sources were unzipped in
\verb|C:\mico|, then type the following:

\small
\begin{verbatim}
  PATH C:\mico\win32-bin;%PATH%
\end{verbatim}
\normalsize


\subsection{Writing MICO applications using the IDE}

All the examples that come with \MICO\ depend on Makefiles for the
building process. The advantage of a tool like Visual--C++ is that it
offers an \emph{Integrated Development Environment} (IDE), which
combines editor, compiler and debugger in one tool. The IDE also
manages all the files which belong to a project. This section gives
you an indication on how to use the IDE together with \MICO.  First
you have to tell Visual--C++, where MICO is located. You do this in
the \emph{Tools/Options} dialog, in the \emph{Directories} tab, you
have to set the \emph{Include path} to the following directories:

\small
\begin{verbatim}
  C:\mico\win32-bin\include\windows
  C:\mico\win32-bin\include
\end{verbatim}
\normalsize

\noindent
These lines have to be first in the list (use the move buttons to move
them to the first position). Next, set the \emph{Library path} to
(order does not matter):

\small
\begin{verbatim}
  C:\mico\win32-bin\lib
\end{verbatim}
\normalsize

\noindent
and the \emph{Executables path} accordingly to:

\small
\begin{verbatim}
  C:\mico\win32-bin
\end{verbatim}
\normalsize

\noindent
In the project settings you have to make the following changes:

\begin{description}
\item[Compiler:] You have to define \texttt{\_WINDOWS} in the
  \emph{Preprocessor} options.  In the \emph{Code Generation} options
  you have to use the Multi--Threaded DLL version of the runtime
  library, because that is the way MICO was compiled.
\item[Linker:] You have to add \texttt{micoXXX.lib} and
  \texttt{wsock32.lib} (where \texttt{XXX} is the three digit version
  number of \MICO\ without the dots) to the \emph{Object/Library
    modules} input field (Hint: Before you do this select \emph{All
    configurations} in the upper left combo box named \emph{Settings
    for})
\end{description}

Additionally, you can integrate your IDL files in the build process.
First you have to add the IDL file to your project, then goto
\emph{Project/Settings} and select this file, or right click on the
IDL file and choose \emph{Settings}, select the \emph{Custom Build}
tab and enter:

\small
\begin{verbatim}
  idl --c++-suffix=cpp [other options] $(InputPath)
\end{verbatim}
\normalsize

\noindent
into the \emph{Build Command} listbox. In the \emph{Output} files list
box enter:

\small
\begin{verbatim}
  $(InputName).h
  $(InputName).cpp
\end{verbatim}
\normalsize

%$
\noindent
For inserting \texttt{\$(..)} you can also use the popup buttons at
the bottom of the dialog, or you can use the real filename instead.
The output files of the IDL compiler are created in the current
directory; normally the root of the project. If the output filename is
\texttt{foo.cpp}, then you have to add \texttt{foo.cpp} to the
project. This can be done even before the file exists, by entering it
into the file dialog.


%-------------------------------------------------------------------------
\section{Supported Platforms}
\label{SEC_SUPPORTED_PLATFORMS}

\MICO\/ has been tested on the following operating systems:

\begin{itemize}
\item Solaris 2.5, 2.6, and 7 on Sun SPARC
\item AIX 4.2 on IBM RS/6000
\item Linux 2.x on Intel x86 and DEC Alpha
\item Digital Unix 4.x on DEC Alpha
\item HP--UX 10.20 on PA--RISC
\item Ultrix 4.2 on DEC Mips (no shared libs, no dynamic loading)
\item Windows 95/NT (Visual C++ and Cygnus CDK)
\end{itemize}

\noindent
Addionally some users reported \MICO\/ runs on the following
platforms:

\begin{itemize}
\item FreeBSD 3.x on Intel x86
\item SGI--Irix on DEC Mips
\item OS/2 on Intel x86 using emx 0.9
\item DG/UX on Intel x86
\item LynxOS
\end{itemize}

\noindent
Please let us know if you fail/succeed in running \MICO\/ on any
unsupported platform.


%-------------------------------------------------------------------------
\chapter{Guided tour through MICO}

%-------------------------------------------------------------------------
\section{Objects in distributed systems}

Modern programming languages employ the \emph{object paradigm} to
structure computation within a single operating system process. The next
logical step is to distribute a computation over multiple processes on
one single or even on different machines. Because object orientation has
proven to be an adequate means for developing and maintaining large
scale applications, it seems reasonable to apply the object paradigm to
distributed computation as well: objects are distributed over the
machines within a networked environment and communicate with each other.

As a fact of life the computers within a networked environment differ in
hardware architecture, operating system software, and the programming
languages used to implement the objects. That is what we call a
\emph{heterogenous distributed environment}. To allow communication
between objects in such an environment one needs a rather complex piece of
software called a \emph{middleware platform}. Figure \ref{FIG_MIDDLEWARE}
illustrates the role of a middleware platform within a heterogenous
distributed environment.

\begin{figure}
\begin{center}
\ \psfig{file=pics/middleware.eps,width=11cm}
\end{center}
\caption{\label{FIG_MIDDLEWARE} Middleware support for objects in
  distributed systems.}
\end{figure}

The \emph{Common Object Request Broker Architecture (CORBA)} is a
specification of such a middleware platform by the \emph{Object
Management Group (OMG)} (see \cite{corba}). \MICO\/ provides a full
CORBA 2.3 compliant implementation. CORBA addresses the following
issues:

\begin{description}
\item[object orientation]
  ~\newline
  objects are the basic building blocks of CORBA applications.
\item[distribution transparency]
  ~\newline
  a caller uses the same mechanisms to invoke an object whether it is
  located in the same address space, the same machine or on a remote machine.
\item[hardware--, operating system--, and language independence]
  ~\newline
  CORBA components can be implemented using different programming languages
  on different hardware architectures running different operating systems.
\item[vendor independence]
  ~\newline
  CORBA compliant implementations from different vendors interoperate.
\end{description}

\noindent
CORBA is an open standard in the sense that anybody can obtain the
specification and implement it like we did. Besides its technical
features this is considered one of CORBA's main advantages over
other proprietary solutions.


%-------------------------------------------------------------------------
\section{State of development}
\label{SEC_STATE_OF_DEVEL}

\MICO\/ is a fully compliant CORBA 2.3 implementation. Everything that
is implemented is CORBA 2.3 compliant, including but not limited to
the following features:

\begin{itemize}
\item
  Dynamic Invocation Interface (DII)
\item
  Dynamic Skeleton Interface (DSI)
\item
  IDL to C++ mapping
\item
  Interface Repository (IR)
\item
  graphical Interface Repository browser that allows you to
  invoke arbitrary methods on arbitrary interfaces
\item
  IIOP as native protocol
\item
  IIOP over SSL
\item
  modular ORB design: new transport protocols and object adapters
  can easily be attached to the ORB --- even at runtime using loadable
  modules
\item
  support for nested method invocations
\item
  interceptors
\item
  \verb|Any| offers an interface for inserting and extracting
  contructed types that were not known at compile time
\item
  \verb|Any| and \verb|TypeCode| support recursive subtyping as
  defined by the RM--ODP
\item
  support of recursive data types
\item
  full BOA implementation, including all activation modes,
  support for object migration, object persistence and the
  implementation repository
\item
  BOA can load object implementations into clients at runtime using
  loadable modules
\item
  Portable Object Adapter (POA)
\item
  support for using \MICO\ from within X11 applications (Xt and Qt)
\item
  Interoperable Naming Service
\item
  event service
\item
  relationship service
\item
  property service
\item
  trading service
\item
  DynAny support
\end{itemize}

Our goal is to keep the core of \MICO\ fully compliant to the latest
version of the CORBA specification, while integrating new CORBA
services. Be sure to check the \MICO\ homepage frequently for updates.

%-------------------------------------------------------------------------
\section{Sample Program}
\label{SEC_SAMPLE_IDL}

To get you started with \MICO, this section presents an example of how
to turn a single--process object oriented program into a \MICO\/
application.

%-------------------------------------------------------------------------
\subsection{Standalone program}
\label{SEC_STANDALONE_PROG}

Imagine a bank which maintains accounts of its customers. An object
which implements such a bank account offers three
operations\footnote{This is a somewhat idealistic assumption but
  sufficient for the scope of this example.}: \emph{deposit} a certain
amount of money, \emph{withdraw} a certain amount of money, and an
operation called \emph{balance} that returns the current account
balance.  The state of an account object consists of the current
balance. The following C++ code fragment shows the class declaration for
such an account object:

\footnotesize
\begin{verbatim}
  class Account {
      long _current_balance;
  public:
      Account ();
      void deposit (unsigned long amount);
      void withdraw (unsigned long amount);
      long balance ();
  };
\end{verbatim}
\normalsize

\noindent
The above class declaration describes the \emph{interface} and the
\emph{state} of an account object, the actual \emph{implementation}
which reflects the behavior of an account, is shown below:

\footnotesize
\begin{verbatim}
  Account::Account ()
  {
      _current_balance = 0;
  }
  void Account::deposit (unsigned long amount)
  {
      _current_balance += amount;
  }
  void Account::withdraw (unsigned long amount)
  {
      _current_balance -= amount;
  }
  long Account::balance ()
  {
      return _current_balance;
  }
\end{verbatim}
\normalsize

\noindent
Here is a piece of code that makes use of a bank account:

\footnotesize
\begin{verbatim}
  #include <iostream.h>

  int main (int argc, char *argv[])
  {
      Account acc;

      acc.deposit (700);
      acc.withdraw (250);
      cout << "balance is " << acc.balance() << endl;

      return 0;
  }
\end{verbatim}
\normalsize

\noindent
Since a new account has the initial balance of $0$, the above code
will print out \emph{``balance is 450''}.


%-------------------------------------------------------------------------
\subsection{MICO application}
\label{SEC_MICO_APP}

Now we want to turn the standalone implementation from the previous
section into a \MICO\/ application. Because CORBA objects can be
implemented in different programming languages\footnote{The CORBA
specification currently defines language mappings for a variety of
high level languages like C, C++, Smalltalk, Cobol  and Java.} the
specification of an object's \emph{interface} and \emph{implementation}
have to be separated. The implementation is done using the selected
programming language, the interface is specified using the so called
\emph{Interface Definition Language (IDL)}. Basically the CORBA IDL
looks like C++ reduced to class and type declarations (i.e., you
\emph{cannot} write down the implementation of a class method using
IDL). Here is the interface declaration for our account object in
CORBA IDL:

\footnotesize
\begin{verbatim}
  interface Account {
      void deposit (in unsigned long amount);
      void withdraw (in unsigned long amount);
      long balance ();
  };
\end{verbatim}
\normalsize

\noindent
As you can see it looks quite similar to the class declaration in
section \ref{SEC_STANDALONE_PROG}. The \texttt{in} declarator declares
\texttt{amount} as an input parameter to the \texttt{deposit()} and
\texttt{withdraw()} methods. Usually one would save the above
declaration to a file called \texttt{account.idl}.

The next step is to run this interface declaration through the
\emph{IDL compiler} that will generate code in the selected
implementation programming language (C++ in our example). The \MICO\/
IDL compiler is called \texttt{idl} and is used like this:

\small
\begin{verbatim}
  idl --boa --no-poa account.idl
\end{verbatim}
\normalsize

\noindent
The IDL compiler will generate two files: \texttt{account.h} and
\texttt{account.cc} (see figure \ref{FIG_STUB_GEN}). The former
contains class declarations for the base class of the account object
implementation and the stub class a client will use to invoke methods
on remote account objects. The latter contains implementations of
those classes and some supporting code. For each interface declared in
an IDL--file, the \MICO\ IDL compiler will produce three C++
classes\footnote{Note that C++ is currently the only language which is
  supported by \MICO.}.


\begin{figure}
\begin{center}
\ \psfig{file=pics/stub-gen.eps,width=11cm}
\end{center}
\caption{\label{FIG_STUB_GEN} Creation process of a \MICO\ application.}
\end{figure}

The three classes are depicted in figure \ref{FIG_STUB_SKEL_HIERARCHY}
between the two dashed lines. The class \texttt{Account} serves as a base
class. It contains all definitions which belong to the interface
\texttt{Account}, like local declarations of user defined data
structures. This class also defines a pure virtual function for each
operation contained in the interface. The following shows a bit of the
code contained in class \texttt{Account}:

\footnotesize
\begin{verbatim}
  // Code excerpt from account.h
  class Account : virtual public CORBA::Object {
      ...
  public:
      ...
      virtual void deposit (CORBA::ULong amount) = 0;
      virtual void withdraw (CORBA::ULong amount) = 0;
      virtual CORBA::Long balance () = 0;
  }
\end{verbatim}
\normalsize

\noindent
The class \texttt{Account\_skel} is derived from \texttt{Account}. It
adds a dispatcher for the operations defined in class
\texttt{Account}. But it does not define the pure virtual functions of
class \texttt{Account}. The classes \texttt{Account} and
\texttt{Account\_skel} are therefore abstract base classes in C++
terminology.  To implement the account object you have to subclass
\texttt{Account\_skel} providing implementations for the pure virtual
methods \texttt{deposit()}, \texttt{withdraw()} and
\texttt{balance()}.

The class \texttt{Account\_stub} is derived from class
\texttt{Account} as well. In contrast to class \texttt{Account\_skel}
it defines the pure virtual functions.  The implementation of these
functions which is automatically generated by the IDL--compiler is
responsible for the parameter marshalling. The code for
\texttt{Account\_stub} looks like this:

\footnotesize
\begin{verbatim}
  // Code excerpt from account.h and account.cc
  class Account;
  typedef Account *Account_ptr;

  class Account_stub : virtual public Account {
      ...
  public:
      ...
      void deposit (CORBA::ULong amount)
      {
         // Marshalling code for deposit
      }
      void withdraw (CORBA::ULong amount)
      {
         // Marshalling code for withdraw
      }
      CORBA::Long balance ()
      {
         // Marshalling code for balance
      }
  }
\end{verbatim}
\normalsize

\noindent
This makes \texttt{Account\_stub} a concrete C++ class which can be
instantiated. The programmer never uses the class
\texttt{Account\_stub} directly. Access is only provided through class
\texttt{Account} as will be explained later.

\begin{figure}
\begin{center}
\ \psfig{file=pics/stub-skel-hierarchy.eps,width=10cm}
\end{center}
\caption{\label{FIG_STUB_SKEL_HIERARCHY} Inheritance relationship
  between stub-- and skeleton classes.}
\end{figure}

It is worthwile to see where the classes \texttt{Account} and
\texttt{Account\_skel} are derived from. \texttt{Account} inherits
from \texttt{Object}, the base class for all CORBA objects. This class
is located in the \MICO\ library. The more interesting inheritance
path is for \texttt{Account\_skel}. \texttt{Account\_skel} inherits
from \texttt{StaticMethodDispatcher}, a class located again in the
\MICO\ library. This class is responsible for dispatching a method
invocation. It maintains a list of method dispatchers\footnote{In this
  example the list contains only one dispatcher, namely for the
  Account--object.  Later when we discuss interface inheritance this
  list will contain a dispatcher for each class in the inheritance
  hierarchy.}. The class \texttt{StaticMethodDispatcher} inherits from
\texttt{StaticImplementation}. This class mirrors the behaviour of the
\emph{dynamic skeleton interface} (DSI), but is more efficiently
designed.

Up until now we have written the interface of an account object using
CORBA IDL, saved it as \texttt{account.idl}, ran it through the IDL
compiler which left us with two files called \texttt{account.cc} and
\texttt{account.h} that contain the class declarations for the account
implementation base class (\texttt{Account\_skel}) and the client stub
(\texttt{Account\_stub}). Figure \ref{FIG_STUB_GEN} illustrates this.
What is left to do is to subclass \texttt{Account\_skel} (implementing
the pure virtual methods) and write a program that uses the bank
account. Here we go:

\footnotesize
\begin{verbatim}
 1: #include "account.h"
 2: 
 3: class Account_impl : virtual public Account_skel
 4: {
 5: private:
 6:   CORBA::Long _current_balance;
 7: 
 8: public:
 9:   Account_impl()
10:   {
11:     _current_balance = 0;
12:   };
13:   void deposit( CORBA::ULong amount )
14:   {
15:     _current_balance += amount;
16:   };
17:   void withdraw( CORBA::ULong amount )
18:   {
19:     _current_balance -= amount;
20:   };
21:   CORBA::Long balance()
22:   {
23:     return _current_balance;
24:   };
25: };
26: 
27: 
28: int main( int argc, char *argv[] )
29: {
30:   // ORB initialization
31:   CORBA::ORB_var orb = CORBA::ORB_init( argc, argv, "mico-local-orb" );
32:   CORBA::BOA_var boa = orb->BOA_init( argc, argv, "mico-local-boa" );
33: 
34:   // server side
35:   Account_impl* server = new Account_impl;
36:   CORBA::String_var ref = orb->object_to_string( server );
37:   cout << "Server reference: " << ref << endl;
38:   
39:   //----------------------------------------------------------------------
40:   
41:   // client side
42:   CORBA::Object_var obj = orb->string_to_object( ref );
43:   Account_var client = Account::_narrow( obj );
44: 
45:   client->deposit( 700 );
46:   client->withdraw( 250 );
47:   cout << "Balance is " << client->balance() << endl;
48: 
49:   // We don't need the server object any more. This code belongs
50:   // to the server implementation
51:   CORBA::release( server );
52:   return 0;
53: }
\end{verbatim}
\normalsize

\noindent
Lines 3--25 contain the implementation of the account object, which is
quite similar to the implementation in section
\ref{SEC_STANDALONE_PROG}. Note that the class \texttt{Account\_impl}
inherits the from class \texttt{Account\_skel}, which contains the
dispatcher for this interface, via a virtual public derivation.
Although the keyword \texttt{virtual} is not required in this case, it
is a good practise to write it anyway. This will become important when
interface inheritance is discussed in section
\ref{SEC_INTERF_INHERITANCE}.

The \texttt{main()} function falls into two parts which are seperated
by the horizontal line (line 39): Above the separator is the server
part that provides an account object, below the line is the client
code which invokes methods on the account object provided by the
server part. Theoretically the two parts could be moved to two
seperate programs and run on two distinct machines and almost nothing
had to be changed in the code. This will be shown in the next section.

In line 32 the \MICO\/ initialization function is used to obtain a
pointer to the \emph{Object Request Broker (ORB)} object---a central
part of each CORBA implementation. Among others the ORB provides
methods to convert object references into a string representation and
vice versa. In line 35 an account object called \texttt{server} is
instantiated. Note that it is not permitted to allocate CORBA objects
on the run--time stack. This is because the CORBA standard prescribes
that every object has to be deleted with a special function called
\texttt{CORBA::release()}. Automatic allocation of an object would
invoke its destructor when the program moves out of scope which is not
permissible. In our little sample program the server object is deleted
explicitly in line 51.

In line 36 the ORB is used to convert the object reference into a
string that somehow has to be transmitted to the client (e.g., using
Email, a name service or a trader). In our example client and server
run in the same address space (i.e. the same process) so we can turn
the string into an object reference back again in line 42. Line 43
uses the \texttt{Account::\_narrow()} method to downcast the object
reference to an \texttt{Account\_var}. The rest of \texttt{main()}
just uses the account object which was instantiated in line 35.

\texttt{Account\_var} is a smart pointer to \texttt{Account}
instances. That is an \texttt{Account\_var} behaves like an
\texttt{Account\_ptr} except that the storage of the referenced object
is automatically freed via the aforementioned \texttt{release()}
function when the \texttt{Account\_var} is destroyed. If you use
\texttt{Account\_ptr} instead you would have to use
\texttt{CORBA::release()} explicitly to free the object when you are
done with it (\emph{never} use \texttt{delete} instead of
\texttt{CORBA::release()}).

Assuming the above code is saved to a file called \texttt{account\_impl.cc}
you can compile the code like this\footnote{\texttt{mico-c++} and
  \texttt{mico-ld} are wrapper scripts for the C++ compiler and the linker,
  see section \ref{SEC_WRAPPERS} for details}:

\small
\begin{verbatim}
  mico-c++ -I. -c account_impl.cc -o account_impl.o
  mico-c++ -I. -c account.cc -o account.o
  mico-ld -I. -o account account_impl.o account.o -lmico@DOTVERSION@
\end{verbatim}
\normalsize

\noindent
This will generate an executable called \texttt{account}. Running it
produces the following output:

\small
\begin{verbatim}
  Server reference: IOR:010000001000000049444c3a4163636f756e743a312e3\
  0000200000000000000300000000101000013000000752d6d61792e7468696e6b6f\
  6e652e636f6d00007b0900000c000000424f410a20b0530000055f0301000000240\
  0000001000000010000000100000014000000010000000100010000000000090101\
  0000000000
  Balance is 450
\end{verbatim}
\normalsize

\noindent
You can find the source code for this example in the
\texttt{demo/boa/account} directory within the \MICO\/ source tree.
Note that the IOR may look different on different systems. This is
because it contains information which depend on the hostname, port
number and object ID for the server object among other things. There
is a tool called \emph{iordump} (see directory
\texttt{mico/tools/iordump}) which shows the content of the IOR.
Feeding the IOR above into \emph{iordump} yields the following output:

\small
\begin{verbatim}
    Repo Id:  IDL:Account:1.0

IIOP Profile
    Version:  1.0
    Address:  inet:u-may.thinkone.com:2427
   Location:  iioploc://u-may.thinkone.com:2427/BOA%0a%20%b0S%00%00%05%5f%03
        Key:  42 4f 41 0a 20 b0 53 00 00 05 5f 03             BOA. .S..._.

Multiple Components Profile
 Components:  Native Codesets:
              normal: ISO 8859-1:1987; Latin Alphabet No. 1
                wide: ISO/IEC 10646-1:1993; UTF-16, UCS Transformation Format\
                                               16-bit form
        Key:  00                                              .
\end{verbatim}
\normalsize


%-------------------------------------------------------------------------
\subsection{Separating client and server}

CORBA would be pretty useless if you always had to run the object
implementation (\emph{server}) and the \emph{client} that uses the
server in the same process. Here is how to separate the client and
server parts of the example in the previous section into two processes
running on the same or on different machines\footnote{Of course you can
have some of the object implementations in the same process and some
in other processes. The ORB hides the actual locations of the object
implementations from the user}.

One problem you have to cope with when moving object implementation
and client into separate address spaces is how the client gets to know
the server. The solution to this problem is called a \emph{naming
service}.

%-------------------------------------------------------------------------
\subsubsection{Stringified Object References}
\label{SEC_STR_OBJREF}

The example in section \ref{SEC_MICO_APP} already used the ORB
methods \verb|object_to_string()| and \verb|string_to_object()| to
make a stringified representation of an object reference and to
turn back this string into an object, respectively.

When separating client and server you have to find a way to transmit
the stringified object reference from the server to the client. If
client and server run on machines that share a single file system
you can make the server write the string into a file which is read by the
client. Here is how to do it:

\footnotesize
\begin{verbatim}
 1: // file account_server.cc
 2:
 3: #include <iostream.h>
 4: #include <fstream.h>
 5: #include "account.h"
 6: 
 7: class Account_impl : virtual public Account_skel
 8: {
 9:   // unchanged, see section "MICO Application"
10:   // ...
11: };
12: 
13: 
14: int main( int argc, char *argv[] )
15: {
16:   // ORB initialization
17:   CORBA::ORB_var orb = CORBA::ORB_init( argc, argv, "mico-local-orb" );
18:   CORBA::BOA_var boa = orb->BOA_init( argc, argv, "mico-local-boa" );
19: 
20:   Account_impl* server = new Account_impl;
21:   CORBA::String_var ref = orb->object_to_string( server );
22:   ofstream out ("/tmp/account.objid");
23:   out << ref << endl;
24:   out.close ();
25:
26:   boa->impl_is_ready( CORBA::ImplementationDef::_nil() );
27:   orb->run ();
28:   CORBA::release( server );
29:   return 0;
30: }
\end{verbatim}
\normalsize

\noindent
\verb|Account_impl|, the implementation of the account object in lines
7--11 is the same as in section \ref{SEC_MICO_APP}. The \verb|main()|
function performs ORB and BOA\footnote{The Basic Object Adapter}
initialization in lines 16--18, which will evaluate and remove CORBA
specific command line options from \verb|argv|, see section
\ref{SEC_ORB_INIT} for details. In line 20 an account
object is created, lines 21--24 obtain a stringified object reference
for this object and write it to a file called \verb|account.objid|.

In line 26 the \verb|impl_is_ready()| method of the BOA is called to
activate the objects implemented by the server. The ORB method \verb|run()|,
which is invoked in line 27 will enter a loop to process incoming
invocations\footnote{You can make \texttt{run()} exit by
  calling the ORB method \texttt{shutdown()}, see section
  \ref{SEC_ACTIV_MODES} for details.}.
Just before returning from
\verb|main()|, \verb|CORBA::release()| is used in line 28 to destroy
the account server object.

\footnotesize
\begin{verbatim}
 1: // file account_client.cc
 2:
 3: #include <iostream.h>
 4: #include <fstream.h>
 5: #include "account.h"
 6: 
 7: int main( int argc, char *argv[] )
 8: {
 9:   // ORB initialization
10:   CORBA::ORB_var orb = CORBA::ORB_init( argc, argv, "mico-local-orb" );
11:   CORBA::BOA_var boa = orb->BOA_init( argc, argv, "mico-local-boa" );
12:
13:   ifstream in ("/tmp/account.objid");
14:   char ref[1000];
15:   in >> ref;
16:   in.close ();
17:
18:   CORBA::Object_var obj = orb->string_to_object (ref);
19:   Account_var client = Account::_narrow( obj );
20: 
21:   client->deposit( 700 );
22:   client->withdraw( 250 );
23:   cout << "Balance is " << client->balance() << endl;
24:
25:   return 0;
26: }
\end{verbatim}
\normalsize

\noindent
After ORB and BOA initialization the client's \verb|main()| function reads
the stringified object reference in lines 13--16 and turns it back into an
account object stub in lines 18--19. After making some method invocations
in lines 21-23 \verb|client| will be destroyed automatically because we
used and \verb|Account_var| smart pointer.

\noindent
Compile the client and server programs like this:

\small
\begin{verbatim}
  mico-c++ -I. -c account_server.cc -o account_server.o
  mico-c++ -I. -c account_client.cc -o account_client.o
  mico-c++ -I. -c account.cc -o account.o
  mico-ld -o server account_server.o account.o -lmico@DOTVERSION@
  mico-ld -o client account_client.o account.o -lmico@DOTVERSION@
\end{verbatim}
\normalsize

\noindent
First run \verb|server| and then \verb|client| in a different shell. The
output from \verb|client| will look like this:

\small
\begin{verbatim}
  Balance is 450
\end{verbatim}
\normalsize

\noindent
Note that running the client several times without restarting the
server inbetween will increase the balance the client prints out by
450 each time! You should also note that client and server do not
necessarily have to run on the same machine. The stringified object
reference, which is written to a file called
\verb|/tmp/account.objid|, contains the IP address and port number of
the server's address. This way the client can locate the server over
the network. The same example would also work in a heterogeneous
environment. In that case you would have to compile two versions of
\verb|account.o|, one for each hardware architecture. But the
conversion of the parameters due to different data representations is
taken care of by \MICO.


%-------------------------------------------------------------------------
\subsubsection{Naming Service}

What we have actually done in the last section is to implement some
very simple kind of \emph{naming service} on top of the file system.
A naming service is a mapping between names and addresses which allows
you to look up the address for a given name. For example a phone
directory is a naming service: it maps people's names to phone numbers.

In the CORBA context a naming service maps names to object references.
The simple naming service we implemented in the previous section maps
file names to stringified object references. The OMG has
defined a more elaborate naming service as a set of CORBA objects, an
implementation of which is now shipped with \MICO. To use the name
service you have to

\begin{itemize}
\item run the name service daemon \verb|nsd|
\item tell server and client the address of \verb|nsd| using the
  \texttt{-ORBNamingAddr} option (see section \ref{SEC_ORB_INIT}
  for details)
\item make the server register its offered objects with the name service
\item make the client query the name server for the server
\end{itemize}

There is a program called \verb|nsadmin| that can be used to browse
and change the contents of the naming service. The
\verb|demo/services/naming| directory contains an example how to use
the name service.

%-------------------------------------------------------------------------
\subsubsection{The MICO Binder (CORBA Extension)}
\label{SEC_MICO_BINDER}

There is still one problem left: How do you get an object reference
for the naming service itself? Especially if the naming service and
the client reside on machines that do not share a file system that
could be used to pass around stringified object references as in the
previous section\footnote{The CORBA standard offers the ORB method
  \texttt{resolve\_initial\_references()} to obtain an object
  reference for the naming service. But that only moves the problem to
  the ORB instead of solving it.}.  Because the CORBA standard does
not offer a solution to this problem \MICO\/ has to invent its own.
Because it might be useful for other purposes as well we decided to
make the solution available to you, dear user.  Note that using this
feature makes your programs incompatible with other CORBA
implementations.

The \MICO\ Binder is a very simple naming service that maps
(\emph{Address}, \emph{RepositoryId}) pairs to object references.  A
\emph{RepositoryId} is a string that identifies a CORBA IDL--object
and consists of the absolute name of the IDL--object and a version
number.  RepositoryId's are generated by the IDL compiler. The
RepositoryId for the \verb|Account| interface looks like this:

\begin{verbatim}
  IDL:Account:1.0
\end{verbatim}

\noindent
See section $[$6.6$]$ of \cite{corba} for details on RepositoryId's.
An \emph{Address} identifies one process on one computer. \MICO\/ currently
defines three kinds of addresses: \emph{internet addresses},
\emph{unix addresses}, and \emph{local addresses}. An \emph{internet address}
is a string with the format

\begin{verbatim}
  inet:<host name>:<port number>
\end{verbatim}

\noindent
which refers to the process on machine \verb|<host name>| that owns the
TCP port \verb|<port number>|. \emph{Unix addresses} look like

\begin{verbatim}
  unix:<socket file name>
\end{verbatim}

\noindent
and refer to the process on the current machine that owns the unix--domain
socket\footnote{Unix--domain sockets are named, bidirectional pipes.} bound
to \verb|<socket file name>|. \emph{Local addresses} look like

\begin{verbatim}
  local:
\end{verbatim}

\noindent
and refer to the process they are used in (i.e., \emph{this} process).
Here is an adaption of the account example which uses the \MICO\/ binder:

\footnotesize
\begin{verbatim}
 1: // file account_server2.cc
 2:
 3: #include "account.h"
 4:
 5: class Account_impl : virtual public Account_skel
 6: {
 7:   // unchanged, see section "MICO Application"
 8:   // ...
 9: };
10: 
11: 
12: int main( int argc, char *argv[] )
13: {
14:   // ORB initialization
15:   CORBA::ORB_var orb = CORBA::ORB_init( argc, argv, "mico-local-orb" );
16:   CORBA::BOA_var boa = orb->BOA_init( argc, argv, "mico-local-boa" );
17: 
18:   Account_impl* server = new Account_impl;
19:
20:   boa->impl_is_ready( CORBA::ImplementationDef::_nil() );
21:   orb->run ();
22:   CORBA::release( server );
23:   return 0;
24: }
\end{verbatim}
\normalsize

The server is essentially the same as in \ref{SEC_STR_OBJREF} except
that it does not write a stringified object reference to a file. Here
is the client:

\footnotesize
\begin{verbatim}
 1: // file account_client2.cc
 2:
 3: #include "account.h"
 4:
 5: 
 6: int main( int argc, char *argv[] )
 7: {
 8:   // ORB initialization
 9:   CORBA::ORB_var orb = CORBA::ORB_init( argc, argv, "mico-local-orb" );
10:   CORBA::BOA_var boa = orb->BOA_init( argc, argv, "mico-local-boa" );
11:
12:   CORBA::Object_var obj
13:     = orb->bind ("IDL:Account:1.0", "inet:localhost:8888");
14:   if (CORBA::is_nil (obj)) {
15:      // no such object found ...
16:   }
17:   Account_var client = Account::_narrow( obj );
18: 
19:   client->deposit( 700 );
20:   client->withdraw( 250 );
21:   cout << "Balance is " << client->balance() << endl;
22:
23:   return 0;
24: }
\end{verbatim}
\normalsize

\noindent
After completing ORB and BOA initialization the client uses \verb|bind()|
to bind to an object with repository id \verb|IDL:Account:1.0| that
is running in the process that owns port 8888 on the same machine.
Lines 14--16 check if the bind failed. Everything else is the same as in
section \ref{SEC_STR_OBJREF}. Compile:

\small
\begin{verbatim}
  mico-c++ -I. -c account.cc -o account.o
  mico-c++ -I. -c account_server2.cc -o account_server2.o
  mico-c++ -I. -c account_client2.cc -o account_client2.o
  mico-ld -o server2 account.o account_server2.o -lmico@DOTVERSION@
  mico-ld -o client2 account.o account_client2.o -lmico@DOTVERSION@
\end{verbatim}
\normalsize

\noindent
Start the server like this, telling it to run on port number 8888:

\small
\begin{verbatim}
  ./server2 -ORBIIOPAddr inet:localhost:8888
\end{verbatim}
\normalsize

\noindent
Run the client in a different shell without any arguments. It should behave
the same way as the client from section \ref{SEC_STR_OBJREF}.

If a server offers several objects (lets say \verb|A| and \verb|B|) of the
same type (i.e., with the same repository id) and a client wants to bind
to \verb|A| it needs a means to distinguish objects of the same type.
This is accomplished by assigning objects an identifier during creation
in the server and specifying this identifier as an extra argument to
\verb|bind()| in the client. The identifier is of type
\verb|BOA::ReferenceData|, which is a sequence of octets. You can use
\verb|ORB::string_to_tag()| and \verb|ORB::tag_to_string()| to convert
a string into such an identifier and vice versa. Here are the changes
to the server code:

\footnotesize
\begin{verbatim}
 1: #include "account.h"
 2: 
 3: class Account_impl : virtual public Account_skel {
 4: public:
 5:  Account_impl (const CORBA::BOA::ReferenceData &refdata)
 6:     : Account_skel (refdata)
 7:   {
 8:     _current_balance = 0;
 9:   }
10:   // remaining parts unchanged
11: };
12:  
13: int main( int argc, char *argv[] )
14: {
15:   ...
16:   CORBA::BOA::ReferenceData_var id
17:     = CORBA::ORB::string_to_tag ("foo");
18:   Account_impl* server = new Account_impl (id);
19:   ...
20: }
\end{verbatim}
\normalsize

\noindent
Changes to the client:

\footnotesize
\begin{verbatim}
 1: #include "account.h"
 2: 
 3: int main( int argc, char *argv[] )
 4: {
 5:   ...
 6:   CORBA::BOA::ReferenceData_var id
 7:     = CORBA::ORB::string_to_tag ("foo");
 8:   CORBA::Object_var obj
 9:     = orb->bind ("IDL:Account:1.0", id, "inet:localhost:8888");
10:   ...
11: }
\end{verbatim}
\normalsize

To avoid hardcoding the address of the server into the client you can
leave out the second argument to \verb|bind()| and specify a list of
addresses to try using the \verb|-ORBBindAddr| command line option.
For example

\small
\begin{verbatim}
  ./client -ORBBindAddr local: -ORBBindAddr inet:localhost:8888
\end{verbatim}
\normalsize

\noindent
will make \verb|bind()| try to bind to an account object in the same
process and if that fails it will try to bind to an account object running
in the server than owns port 8888 on the same machine. Note that addresses
specified using \verb|-ORBBindAddr| are only taken into account if you
to not specify an explicit address.

The \verb|demo/boa/account2| directory contains an example that uses
the \MICO\/ binder.

%XXX!!!
%Where to go from here? (books, demo/, test/, directories
%We should also have a section on the benefits of CORBA from
%a broader perspective; especially things like interoperability
%with other ORBs (IIOP) and multiple language mappings.

%-------------------------------------------------------------------------
\chapter{Implementation Overview}

This chapter gives you an overview of how \MICO\/ implements the CORBA
2 specification, the implementation components it consists of and how
those components are being used.

A CORBA 2 implementation consists of the following logical components:

\begin{itemize}
\item
  the \emph{Object Request Broker (ORB)} provides for object location
  and method invocation.
\item
  the \emph{interface repository} stores runtime type information.
\item
  one or more \emph{object adapters} which form the interface between
  object implementations and the ORB; at least the \emph{Basic Object
  Adapter (BOA)} has to be provided, part of which is the
  \emph{implementation repository} that stores information about how
  to activate object implementations.
\item
  the \emph{IDL compiler} generates client stubs, server skeletons
  and marshalling code from a CORBA IDL according to the supported
  language mappings.
\end{itemize}

\noindent
Each of these logical components has to be mapped to one or more
implementation components, which are described in the next sections.


%-------------------------------------------------------------------------
\section{ORB}

The ORB is implemented as a library (\texttt{libmico@DOTVERSION@.a})
that is linked into each \MICO\/ application.


%-------------------------------------------------------------------------
\subsection{ORB Initialization}
\label{SEC_ORB_INIT}

Every \MICO\/ application has to call the ORB initialization function
\verb|ORB_init()| before using \MICO\/ functionality.

\begin{verbatim}
  int main (int argc, char *argv[])
  {
     CORBA::ORB_var orb = CORBA::ORB_init (argc, argv, "mico-local-orb");
     ...
  }
\end{verbatim}

\noindent
That way the ORB has access to the applications command line arguments.
After evaluating them the ORB removes the command line options it understands
so the application doesn't have to care about them. You can also put
ORB command line arguments into a file called \verb|.micorc| in your home
directory. Arguments given on the command line override settings from
\verb|.micorc|. Here is a description of all ORB specific command line
arguments:

\begin{description}
\item[\texttt{-ORBNoIIOPServer}]
  ~\newline
  Do not activate the IIOP server. The IIOP server enables other processes
  to invoke methods on objects in this process using the \emph{Internet
  Inter ORB Protocol (IIOP)}. If for some reason you do not want other
  processes to be able to invoke objects in this process you can use this
  option. Default is to activate the IIOP server.
\item[\texttt{-ORBNoIIOPProxy}]
  ~\newline
  Do not activate the IIOP proxy. The IIOP proxy enables this process to
  invoke methods on objects in other processes using IIOP. If you do not
  want or need this you can use this option. Default is to activate the
  IIOP proxy.
\item[\texttt{-ORBIIOPAddr <address>}]
  ~\newline
  Set the address the IIOP server should run on. See section
  \ref{SEC_MICO_BINDER} for details on addresses. If you do not specify
  this option the IIOP server will choose an unused address. This option
  can be used more than once to make the server listen on several addresses
  (e.g., a \texttt{unix:} and an \texttt{inet:} address).
\item[\texttt{-ORBIIOPBlocking}]
  ~\newline
  Make IIOP use sockets in blocking mode. This gains some extra
  performance, but nested method invocations do not work in this mode.
\item[\texttt{-ORBId <ORB identifier>}]
  ~\newline
  Specify the ORB identifier, \verb|mico-local-orb| is currently the
  only supported ORB identifier. This option is intended for programs
  that needed access to different CORBA implementations in the same
  process. In this case the option \verb|-ORBId| is used to select one
  of the CORBA implementations.
\item[\texttt{-ORBImplRepoIOR <impl repository IOR>}]
  ~\newline
  Specify a stringified object reference\footnote{IOR means
  \emph{Interoperable Object Reference}} for the implementation repository
  the ORB should use.
\item[\texttt{-ORBImplRepoAddr <impl repository address>}]
  ~\newline
  Specify the address of a process that runs an implementation repository.
  The ORB will then try to bind to an implementation repository object using
  the given address. See \ref{SEC_MICO_BINDER} for details on addresses and
  the binder. If the bind fails or if you did neither specify
  \verb|-ORBImplRepoAddr| nor \verb|-ORBImpRepoIOR| the ORB will run a local
  implementation repository.
\item[\texttt{-ORBIfaceRepoIOR <interface repository IOR>}]
  ~\newline
  The same as \verb|-ORBImplRepoIOR| but for the interface repository.
\item[\texttt{-ORBIfaceRepoAddr <interface repository address>}]
  ~\newline
  The same as \verb|-ORBImplRepoAddr| but for the interface repository.
\item[\texttt{-ORBNamingIOR <naming service IOR>}]
  ~\newline
  The same as \verb|-ORBImplRepoIOR| but for the naming service.
\item[\texttt{-ORBNamingAddr <naming address>}]
  ~\newline
  The same as \verb|-ORBImplRepoAddr| but for the naming service.
\item[\texttt{-ORBInitRef <Identifier>=<IOR>}]
  ~\newline
  Sets the value for the initial reference by the name of \verb|identifer|
  to the given object reference. This mechanism can be used both for
  custom and for standard initial references (see above).
\item[\texttt{-ORBDefaultInitRef <IOR-base>}]
  ~\newline
  Defines a location for initial references. \verb|IOR-base| is an
  \verb|iioploc-| or \verb|iiopname-|Style object reference. When
  a previously unknown initial reference is searched for using
  \verb|resolve_initial_references()|, the searched-for identifier
  is concatenated to the \verb|IOR-base| string to produce the
  service's location.
\item[\texttt{-ORBNoResolve}]
  ~\newline
  Do not resolve given IP addresses into host names. Use dotted
  decimal notation instead.
\item[\texttt{-ORBDebugLevel <level>}]
  ~\newline
  Specify the debug level. \verb|<level>| is a non--negative integer
  with greater values giving more debug output on \verb|cerr|.
\item[\texttt{-ORBBindAddr <address>}]
  ~\newline
  Specify an address which \verb|bind(const char *repoid)| should try to
  bind to. This option can be used more than once to specify multiple
  addresses.
\item[\texttt{-ORBConfFile <rcfile>}]
  ~\newline
  Specifies the file from which to read additional command line options
  (defaults to  \verb|~/.micorc|).
\item[\texttt{-ORBNoCodeSets}]
  ~\newline
  Do not add code set information to object references. Since code set
  conversion is a CORBA 2.1 feature this option may be needed to talk
  to ORBs which are not CORBA 2.1 compliant. Furthermore it may gain
  some extra speed.
\item[\texttt{-ORBNativeCS <pattern>}]
  ~\newline
  Specifies the code set the application uses for characters and
  strings. \verb|<pattern>| is a shell--like pattern that must match
  the \verb|description| field of a code set in the OSF code set
  registry\footnote{See files \texttt{admin/code\_set\_registry.txt} and
    \texttt{admin/mico\_code\_set\_registry.txt} in the \MICO\/ source
    tree.}.
  For example the pattern \verb|*8859-1*| will make the ORB use the
  code set ISO--8859--1 (Latin 1) as the native char code set, which is
  the default if you do not specify this option. The ORB uses this
  information to automatically convert characters and strings when talking
  to an application that uses a different code set.
\item[\texttt{-ORBNativeWCS <pattern>}]
  ~\newline
  Similar to \verb|-ORBNativeWCS|, but specifies the code set the
  application uses to wide characters and wide strings. Defaults
  to UTF-16, a 16 bit encoding of Unicode.
\end{description}

%-------------------------------------------------------------------------
\subsection{Obtaining Initial References}
\label{SEC_INIT_REFS}

The ORB offers two functions for obtaining object references for the
interface repository, the implementation repository, and the naming
service. Here is an example that shows how to obtain a reference for
the interface repository using \verb|resolve_initial_references()|:

\begin{verbatim}
  int main (int argc, char *argv[])
  {
    CORBA::ORB_var orb = CORBA::ORB_init (argc, argv, "mico-local-orb");
    ...
    CORBA::Object_var obj =
      orb->resolve_initial_references ("InterfaceRepository");
    CORBA::Repository_var repo = CORBA::Repository::_narrow (obj);
    ...
  }
\end{verbatim}

\noindent
If you specify the interface repository by using the ORB command line option
\verb|-ORBIfaceRepoAddr| or \verb|-ORBIfaceRepoIOR|, the reference returned
from \verb|resolve_initial_references()| will be the one you specified.
Otherwise the ORB will run a local interface repository and you will get
a reference to this one.

Obtaining a reference to the implementation repository
(\verb|"ImplementationRepository"|) and the naming service
(\verb|"NameService"|) works the same way as for the interface repository.

There is another method called \verb|list_initial_services()| that returns
a list of names which can be used as arguments for
\verb|resolve_initial_references()|. Here is how to use it:

\begin{verbatim}
  int main (int argc, char *argv[])
  {
    CORBA::ORB_var orb = CORBA::ORB_init (argc, argv, "mico-local-orb");
    ...
    CORBA::ORB::ObjectIdList_var ids = orb->list_initial_services ();
    for (int i = 0; i < ids->length(); ++i)
      cout << ids[i] << endl;
    ...
  }
\end{verbatim}

Initial references can also be specified using the
\verb|-ORBInitRef| and \verb|-ORBDefaultInitRef| command line
options.

%-------------------------------------------------------------------------
\section{Interface Repository}
\label{SEC_IR}

The interface repository is implemented by a separate program
(\verb|ird|).  The idea is to run one instance of the program and make
all \MICO\/ applications use the same interface repository. As has
been mentioned in section \ref{SEC_INIT_REFS} the command line option
\verb|-ORBIfaceRepoAddr| can be used to tell a \MICO\/ application
which interface repository to use.  But where to get the address of
the \verb|ird| program from? The solution is to tell \verb|ird| an
address it should bind to by using the \verb|-ORBIIOPAddr|. Here is an
example of how to run \verb|ird|:

\begin{verbatim}
  ird -ORBIIOPAddr inet:<ird-host-name>:8888
\end{verbatim}

\noindent
where \verb|<ird-host-name>| should be replaced by the name of the host
\verb|ird| is executed. Afterwards you can run \MICO\/ applications this
way:

\begin{verbatim}
  some_mico_application -ORBIfaceRepoAddr inet:<ird-host-name>:8888
\end{verbatim}

\noindent
To avoid typing in such long command lines you can put the option into
the file \verb|.micorc| in your home directory:

\begin{verbatim}
  echo -ORBIfaceRepoAddr inet:<ird-host-name>:8888 > ~/.micorc
\end{verbatim}

\noindent
Now you can just type:

\begin{verbatim}
  some_mico_application
\end{verbatim}

\noindent
and \verb|some_mico_application| will still use the \verb|ird|'s interface
repository.

\noindent
\verb|ird| can be controlled by the following command line arguments:

\begin{description}
\item[\texttt{--help}]
  ~\newline
  Show a list of all supported command line arguments and exit.
\item[\texttt{--db <database file>}]
  ~\newline
  Specifies the file name where \verb|ird| should save the contents of the
  interface repository when exiting\footnote{\texttt{ird} is terminated by
  pressing \texttt{ctrl-c} or by sending it the \texttt{SIGTERM} signal}.
  When \verb|ird| is restarted afterwards it will read the file given
  by the \verb|--db| option to restore the contents of the interface
  repository. Notice that the contents of this database file is just
  plain ASCII representing a CORBA IDL specification.
\end{description}

%-------------------------------------------------------------------------
\section{BOA}
\label{SEC_BOA}

The \emph{Basic Object Adapter (BOA)} is the only object adapter specified
by CORBA 2. One of its main features is the ability to \emph{activate}
object implementations\footnote{which basically means running a program
that implements an object} when their service is requested by a client.
Using the \emph{implementation repository} the BOA decides how an object
implementation has to be activated\footnote{i.e. which program has to be
run with which options and what activation policy has to be used for the
implementation}.

To fulfill these requirements of the CORBA 2 specification the BOA is
implemented partially by a library (\texttt{libmico@DOTVERSION@.a}) and
partially by a separate program (\verb|micod|) called the \emph{BOA daemon}.

%-------------------------------------------------------------------------
\subsection{BOA Initialization}
\label{SEC_BOA_INIT}

Similar to the ORB initialization described in section \ref{SEC_ORB_INIT}
the BOA has to be initialized like this:

\begin{verbatim}
  int main (int argc, char *argv[])
  {
     CORBA::ORB_var orb = CORBA::ORB_init (argc, argv, "mico-local-orb");
     CORBA::BOA_var boa = orb->BOA_init (argc, argv, "mico-local-boa");
     ...
  }
\end{verbatim}

\noindent
That way it has access to the applications command line arguments. After
evaluating them the BOA will remove the command line options it knows about
from \verb|argv|. As for the ORB you can put BOA specific command line
options into a file called \verb|.micorc| in your home directory. Arguments
given on the command line override settings from \verb|.micorc|. Here is
a list of command line options the BOA understands:

\begin{description}
\item[\texttt{-OAId <BOA identifier>}]
  ~\newline
  Specify the BOA identifier, \verb|mico-local-boa| is the only currently
  supported BOA identifier.
\item[\texttt{-OAImplName <name of the object implementation>}]
  ~\newline
  Tell a server its implementation name. This option must be used when
  launching a persistent server that should register with the BOA daemon.
\item[\texttt{-OARestoreIOR <IOR to restore>}]
  ~\newline
  This options is part of the interface between the BOA daemon and an object
  implementation. Do not use this option!
\item[\texttt{-OARemoteIOR <remote BOA IOR>}]
  ~\newline
  This options is part of the interface between the BOA daemon and an object
  implementation. Do not use this option!
\item[\texttt{-OARemoteAddr <remote BOA address>}]
  ~\newline
  This option tells an object implementation the address of the BOA daemon.
  You should use this option only when starting persistent servers that
  should register with the BOA daemon. See section \ref{SEC_ACTIV_MODES}
  for details.
\end{description}

%-------------------------------------------------------------------------
\subsection{BOA Daemon}
\label{SEC_BOA_DAEMON}

The BOA daemon (\verb|micod|) is the part of the basic object adapter
that activates object implementations when their service is requested.
Moreover \verb|micod| contains the implementation repository. To make all
\MICO\/ applications use a single implementation repository you have to
take similar actions as for the interface repository as described in
section \ref{SEC_IR}. That is you have to tell \verb|micod| an address
to bind to using the \verb|-ORBIIOPAddr| option and tell all \MICO\/
applications this address by using the \verb|-ORBImplRepoAddr| option.
For example:

\begin{verbatim}
  micod -ORBIIOPAddr inet:<micod-host-name>:9999
\end{verbatim}

\noindent
Now you can run all \MICO\/ applications like this:

\begin{verbatim}
  some_mico_application -ORBImplRepoAddr inet:<micod-host-name>:9999
\end{verbatim}

\noindent
or you can put the option into \verb|.micorc| and run
\verb|some_mico_application| without arguments.

\noindent
\verb|micod| understands the following command line arguments:

\begin{description}
\item[\texttt{--help}]
  ~\newline
  Show a list of all supported command line arguments and exit.
\item[\texttt{--forward}]
  ~\newline
  This option instructs \verb|micod| to make use of GIOP location
  forwarding, which results in much better performance (there is
  nearly no overhead compared to not using micod at
  all). Unfortunately this requires some client side GIOP features
  that some ORBs do not support properly although prescribed in the
  CORBA specification. Therefore you may encounter problems when using
  clients implemented using such broken ORBs. That is why this feature
  is off by default.
\item[\texttt{--db <database file>}]
  ~\newline
  Specifies the file name where \verb|micod| should save the contents of the
  implementation repository when exiting\footnote{\texttt{micod} is
  terminated by pressing \texttt{ctrl-c} or by sending it the
  \texttt{SIGTERM} signal}. 
  When \verb|micod| is restarted afterwards it will read the file given
  by the \verb|--db| option to restore the contents of the implementation
  repository.
\end{description}

%-------------------------------------------------------------------------
\subsection{Implementation Repository}
\label{SEC_IMR}

The implementation repository is the place where information about
an object implementation (also known as \emph{server}) is stored. The CORBA
2 specification gives you only an idea what the implementation repository
is for, but does not specify the interface to it. So the design of the
implementation repository is \MICO\/ specific. Here is the IDL for \MICO's
implementation repository:

\footnotesize
\begin{verbatim}
 1:  module CORBA {
 2:    /*
 3:     * Implementation Repository Entry
 4:     */
 5:    interface ImplementationDef {
 6:
 7:      enum ActivationMode {
 8:        ActivateShared, ActivateUnshared,
 9:        ActivatePerMethod,
10:        ActivatePersistent,
11:        ActivateLibrary
12:      };
13:
14:      typedef sequence<string> RepoIdList;
15:
16:      attribute ActivationMode mode;
17:      attribute RepoIdList repoids;
18:      readonly attribute string name;
19:      attribute string command;
20:    };
21:
22:    /*
23:     * Implementation Repository
24:     */
25:    interface ImplRepository {
26:      typedef sequence<ImplementationDef> ImplDefSeq;
27:
28:      ImplementationDef create (...);
29:      void destroy (in ImplementationDef impl_def);
30:      ImplDefSeq find_by_name (in string name);
31:      ImplDefSeq find_by_repoid (in string repoid);
32:      ImplDefSeq find_all ();
33:    };
34:  };
\end{verbatim}
\normalsize

\noindent
Interface \verb|ImplRepository| defined in lines 25--33 is the
implementation repository itself. It contains methods for creating,
destroying and finding entries. An implementation repository entry is defined
by interface \verb|ImplementationDef| in lines 5--20. There is exactly one
entry for each server which contains

\begin{itemize}
\item name
\item activation mode
\item shell command or loadable module path
\item list of repository ids
\end{itemize}

\noindent
for the sever. The name uniquely identifies the server. The activation mode
tells the BOA whether the server should be activated once
(\emph{shared server}), once for each object instance (\emph{unshared server}),
once for each method invocation (\emph{per method server}), or not at all
(\emph{persistent server}). See section \ref{SEC_ACTIV_MODES} for details
on activation modes. The shell command is executed by the BOA whenever the
server has to be (re)started. Activation mode \emph{library} is used for
loading servers into the same process as the client during runtime. Instead
of a shell command you have to specify the path of the loadable server module
for library activation mode. Finally there is a repository id for each IDL
interface implemented by the server. See section \ref{SEC_MICO_BINDER} for
details on repository ids.

If you have written a server that should be activated by the BOA daemon
when its service is requested you have to create an entry for that server.
This can be accomplished by using the program \verb|imr|. \verb|imr| can be
used to list all entries in the implementation repository, to show detailed
information for one entry, to create a new entry, and to delete an entry.

The implementation repository is selected by the \verb|-ORBImplRepoAddr|
or \verb|-ORBImplRepoIOR| options, which you usually put into your
\verb|.micorc| file.

\subsubsection{Listing All Entries}

Just issue the following command:

\begin{verbatim}
  imr list
\end{verbatim}

\noindent
and you will get a listing of the names of all entries in the
implementation repository.

\subsubsection{Details For One Entry}

\begin{verbatim}
  imr info <name>
\end{verbatim}

\noindent
will show you detailed information for the entry named \verb|<name>|.

\subsubsection{Creating New Entries}

\begin{verbatim}
  imr create <name> <mode> <command> <repoid1> <repoid2> ...
\end{verbatim}

\noindent
will create a new entry with name \verb|<name>|. \verb|<mode>| is one of

\begin{itemize}
\item \texttt{persistent}
\item \texttt{shared}
\item \texttt{unshared}
\item \texttt{permethod}
\item \texttt{library}
\item \texttt{poa}
\end{itemize}

\noindent
\verb|<command>| is the shell command that should be used to start the server.
Note that all paths have to be absolute since \verb|micod|'s current
directory is probably different from your current directory. Furthermore
you have to make sure that the server is located on the same machine as
\verb|micod|, otherwise you have to use \verb|rsh|; see below for examples.
\verb|<repoid1>|, \verb|<repoid2>| and so on are the repository ids for
the IDL interfaces implemented by the server.

\subsubsection{Deleting Entries}

\begin{verbatim}
  imr delete <name>
\end{verbatim}

\noindent
will delete the entry named \verb|<name>|.

\subsubsection{Forcing Activation of an Implementation}

Registering an implementation in the implementation repository does not
automatically activate the implementation. Usually a non--persistent
implementation is only activated by the BOA daemon when its service
is requested by a client. But sometimes you have to force activation
of an implementation, for instance to make the implementation register
itself with a naming service.

\begin{verbatim}
  imr activate <name> [<micod-address>]
\end{verbatim}

\noindent
will activate the implementation named \verb|<name>|. To do this
\verb|imr| needs to know the address of the BOA daemon. Usually this
is the same address as for the implementation repository and you do
not need to specify \verb|<micod-address>|. Only if the BOA daemon is
bound to an address different from the implementation repository
address and different from the addresses specified using the
\verb|-ORBBindAddr| option you have to specify \verb|<micod-address>|
as a command line option to \verb|imr|.

\subsubsection{Examples}

Assume we want to register the account server \verb|account_server2|
from section \ref{SEC_MICO_BINDER} as a shared server. Furthermore assume
that neither \verb|micod| nor \verb|ird| have been started yet, so we have
to get them running first. Assuming the hostname is \verb|zirkon|, you have
to do the following:

\begin{verbatim}
  # create .micorc (only do that once)
  echo -ORBIfaceRepoAddr inet:zirkon:9000 > ~/.micorc
  echo -ORBImplRepoAddr inet:zirkon:9001 >> ~/.micorc

  # run ird
  ird -ORBIIOPAddr inet:zirkon:9000

  # run micod in a different shell
  micod -ORBIIOPAddr inet:zirkon:9001
\end{verbatim}

\noindent
Now we are prepared to create the implementation repository entry for
\verb|account_server2|. Recall that this server implemented the interface
\verb|Account| whose repository id is \verb|IDL:Account:1.0|. Assuming
\verb|account_server2| has been copied to \verb|/usr/bin| you
can create the implementation repository entry using the following
command:

\begin{verbatim}
  imr create Account shared /usr/bin/account_server2 IDL:Account:1.0
\end{verbatim}

\noindent
If \verb|account_server2| is located on host \verb|diamant| (i.e.,
\emph{not} on \verb|zirkon|) you have to use the \verb|rsh| command.
This requires of course that you have entries in your \verb|.rhosts|
file that allow \verb|micod| to execute programs on \verb|diamant|.
Here is the command to create the implementation repository entry:

\begin{verbatim}
  imr create Account shared "rsh diamant /usr/bin/account_server2" \
    IDL:Account:1.0
\end{verbatim}

Now you should change \verb|account_client2.cc| to bind to the address
of \verb|micod|. Note that you no longer need to know the address of
the account server \verb|account_server2|, you only need to know the
address of \verb|micod|. Here is the part of \verb|account_client2.cc|
that has to be changed:

\begin{verbatim}
  // account_client2.cc
  ...
    CORBA::Object_var obj =
      orb->bind ("IDL:Account:1.0", "inet:zirkon:9001");
  ...
\end{verbatim}

\noindent
Running the recompiled client will automatically activate
\verb|account_server2|.

Creating an entry for a loadable module (library activation mode) looks
like this if \verb|/usr/local/lib/module.so| is the path to the module:

\begin{verbatim}
  imr create Account library /usr/local/lib/module.so IDL:Account:1.0
\end{verbatim}

\noindent
Note that you have to make sure that a loadable module and a client that
wants to make use of the module reside on the same machine.

%-------------------------------------------------------------------------
\subsection{Activation Modes}
\label{SEC_ACTIV_MODES}

As mentioned in the previous section the BOA supports several activation
modes. Using them is not simply a matter of creating an implementation
repository entry, instead an object implementation has to use special
BOA functionality according to the selected activation mode. This section
gives you some details on this topic.

\subsubsection{Activation Mode \emph{Shared}}

\emph{Shared} servers can serve any number of object instances, which is
probably the most widely used approach. The account server from section
\ref{SEC_MICO_BINDER} is an example for a shared server. Lets look at the
code again:

\footnotesize
\begin{verbatim}
 1: // file account_server2.cc
 2:
 3: #include "account.h"
 4:
 5: class Account_impl : virtual public Account_skel
 6: {
 7:   // unchanged, see section "MICO Application"
 8:   // ...
 9: };
10: 
11: 
12: int main( int argc, char *argv[] )
13: {
14:   // ORB initialization
15:   CORBA::ORB_var orb = CORBA::ORB_init( argc, argv, "mico-local-orb" );
16:   CORBA::BOA_var boa = orb->BOA_init( argc, argv, "mico-local-boa" );
17: 
18:   Account_impl* server = new Account_impl;
19:
20:   boa->impl_is_ready( CORBA::ImplementationDef::_nil() );
21:   orb->run ();
22:   CORBA::release( server );
23:   return 0;
24: }
\end{verbatim}
\normalsize

After creating the implementation repository entry for the account server
using the \verb|imr| utility the account server stays inactive until the
account client wants to bind to an object with repository id
\verb|IDL:Account:1.0|. The BOA daemon recognizes that there are no active
account objects and consults the implementation repository for servers that
implement objects with repository id \verb|IDL:Account:1.0|. It will find
the account server and run it. The account server in turn creates an
account object in line 18, which will be announced to the BOA daemon.
The server uses \verb|impl_is_ready()| to tell the BOA daemon that
it has completed initialization and is prepared to receive method
invocations. The BOA daemon in turn finds the newly created account object
and answers the bind request from the client with it. Finally \verb|run()|
is called on the ORB to start processing events.

\verb|run()| will wait for requests and serve them as they arrive
until the \verb|deactivate_impl()| method is called, which deactivates
the server. Calling the ORB method \verb|shutdown()| will make
\verb|run()| return and the account server will exit. If method
invocations arrive after the server has exited the BOA daemon will
restart the server. See section \ref{SEC_PERS_OBJS} for details on
restaring servers.

There are many reasons for calling \verb|deactivate_impl()|. For example we
could augment the account objects interface by a management interface that
offers a method \verb|exit()| that will shut down the account
server\footnote{Usually one would define a new interface \texttt{ManagedObject}
that contains the management operations and derive \texttt{Account}
from \texttt{ManagedObject}. We don't do this here for ease of exposition.}:

\footnotesize
\begin{verbatim}
  // account.idl
  interface Account {
    ...
    void exit ();
  };
\end{verbatim}
\normalsize

\noindent
The implementation of the \verb|exit()| method would look like this:

\footnotesize
\begin{verbatim}
  // account.idl
  class Account_impl : virtual public Account_skel {
    ...
  public:
    ...
    virtual void exit ()
    {
      CORBA::BOA_var boa = _boa();
      CORBA::ORB_var orb = _orb();
      boa->deactivate_impl (CORBA::ImplementationDef::_nil());
      orb->shutdown (TRUE);
    }
  };
\end{verbatim}
\normalsize

\noindent
Note that we passed a NIL \verb|ImplementationDef| to
\verb|deactivate_impl()| as well as to \verb|impl_is_ready()|. Usually
the implementation repository has to be searched to find the entry for
the server and pass this one.  When passing NIL the entry will be
searched by the BOA. \verb|shutdown()| has a \verb|boolean wait|
parameter which controls whether the ORB should immediately stop
processing events (\verb|wait=FALSE|) or wait until all pending
requests have completed (\verb|wait=TRUE|).

\subsubsection{Activation Mode \emph{Persistent}}

\emph{Persistent} servers are just like shared servers, except that
the BOA daemon does not activate them. Instead they have to be started
by means outside of the BOA, e.g. by a system administrator or a shell
script. The code of a persistent server looks exactly like that of a a
shared server.  But note that once \verb|deactivate_impl()| and
\verb|shutdown()| are called the server will \emph{not} be restarted
by the BOA daemon.

That means persistent servers do not need a running BOA daemon. Instead
clients can connect directly to the object implementation, giving you better
performance. See section \ref{SEC_MICO_BINDER} for an example. However,
there is a reason to have even persistent servers register with the
BOA daemon: you can do a \verb|bind()| using the address of the BOA daemon,
that is you do not need to know the address of the persistent server. Making
a persistent server register with the BOA daemon is done like this:

\small
\begin{verbatim}
  some_server -OARemoteAddr <micod-address> -ORBImplRepoAddr <micod-address> \
    -OAImplName <impl-name>
\end{verbatim}
\normalsize

\noindent
where \verb|<micod-address>| is the address \verb|micod| is bound
to\footnote{The \texttt{-ORBImplRepoAddr} option is usually already in
your \texttt{.micorc} file, so you do not have to specify it.}. This
is usually the same address you used as an argument to \verb|-ORBIIOPAddr|
when starting \verb|micod|. See section \ref{SEC_MICO_BINDER} for details
on addresses, sections \ref{SEC_ORB_INIT} and \ref{SEC_BOA_INIT} for details
on command line arguments. \verb|<impl-name>| is the name of the entry in
the implementation repository the corresponds to the server.

\subsubsection{Activation Mode \emph{Unshared}}

\emph{Unshared} servers are similar to shared servers. The difference is that
each instance of an unshared server can only serve \emph{one} object
instance. That is for $N$ objects you need $N$ running instances of an
unshared server.

Furthermore you cannot use \verb|impl_is_ready()| and
\verb|deactivate_impl()| but have to use \verb|obj_is_ready()| and
\verb|deactivate_obj()| instead. Here is the \verb|main()| function of an
unshared account server:

\footnotesize
\begin{verbatim}
 1: // file account_server2.cc
 2:
 3: #include "account.h"
 4:
 5: class Account_impl : virtual public Account_skel
 6: {
 7:   // unchanged, see section "MICO Application"
 8:   // ...
 9: };
10: 
11: 
12: int main( int argc, char *argv[] )
13: {
14:   // ORB initialization
15:   CORBA::ORB_var orb = CORBA::ORB_init( argc, argv, "mico-local-orb" );
16:   CORBA::BOA_var boa = orb->BOA_init( argc, argv, "mico-local-boa" );
17: 
18:   Account_impl* server = new Account_impl;
19:
20:   boa->obj_is_ready (server, CORBA::ImplementationDef::_nil());
21:   orb->run ();
22:   CORBA::release( server );
23:   return 0;
24: }
\end{verbatim}
\normalsize

\noindent
The \verb|exit()| method would look like this in an unshared server:

\footnotesize
\begin{verbatim}
  // account.idl
  class Account_impl : virtual public Account_skel {
    ...
  public:
    ...
    virtual void exit ()
    {
      CORBA::BOA_var boa = _boa();
      CORBA::ORB_var orb = _orb();
      boa->deactivate_obj (this);
      orb->shutdown (TRUE);
    }
  };
\end{verbatim}
\normalsize

Although an unshared server instance can only \emph{serve} one object
instance it can \emph{create} more than one object instance. Imagine
for instance a bank object

\footnotesize
\begin{verbatim}
  // bank.idl
  interface Bank {
    Account create ();
    void destroy (in Account account);
  };
\end{verbatim}
\normalsize

\noindent
that can create new account objects and destroy account objects that are
no longer needed\footnote{Such a design pattern is called a \emph{factory}.}.
The implementation of the \verb|create()| method in an unshared server
would look like this:

\footnotesize
\begin{verbatim}
 1:  // bank_server.cc
 2:  class Bank_impl : virtual public Bank_skel {
 3:    ...
 4:  public:
 5:    ...
 6:    virtual Account_ptr create ()
 7:    {
 8:      Account_ptr account = new Account_impl;
 9:
10:      CORBA::BOA_var boa = _boa();
11:      boa->deactivate_obj (account);
12:
13:      return Account::_duplicate (account);
14:    }
15:  };
\end{verbatim}
\normalsize

\noindent
Note that line 11 calls \verb|deactivate_obj()| on the newly created
object\footnote{If you delete lines 10 and 11 you will get the code for
\texttt{create()} in a shared or persistent server.}. This will tell the
BOA daemon that you are not going to serve this object, instead a new
server instance has to be activated for serving the newly created
account object. For this to work you must of course implement saving
and restoring for your objects as described in section
\ref{SEC_PERS_OBJS}.

If you need access to the newly created account object from within the
server where it was first created you need to take special actions. The
reason for this is that the created account object is initially an account
object implementation (\verb|Account_impl|), but in order to access the moved
account object in the other server you need an account stub
(\verb|Account_stub|). Here is how to create this stub:

\footnotesize
\begin{verbatim}
 1:  // bank_server.cc
 2:  class Bank_impl : virtual public Bank_skel {
 3:    ...
 4:  public:
 5:    ...
 6:    virtual Account_ptr create ()
 7:    {
 8:      CORBA::BOA_var boa = _boa();
 9:      CORBA::ORB_var orb = _orb();
10:
11:      Account_ptr account = new Account_impl;
12:      boa->deactivate_obj (account);
13:
14:      // turn 'account' into a stub
15:      CORBA::String_var ref = orb->object_to_string (account);
16:      CORBA::release (account);
17:      CORBA::Object_var obj = orb->string_to_object (ref);
18:      account = Account::_narrow (obj);
19:
20:      // now you can invoke methods on (the remote) 'account'
21:      account->deposit (100);
22:
23:      return Account::_duplicate (account);
24:    }
25:  };
\end{verbatim}
\normalsize

The \verb|demo/boa/account3| directory contains a complete example for
an unshared server that creates more than one object.


\subsubsection{Activation Mode \emph{Per Method}}

\emph{Per Method} servers are similar to unshared servers, except that
a new server instance is launched for each method invocation. The code
for a per method server looks the same as for an unshared server. But
note that \verb|run()| will return after the first method
invocation, whereas in an unshared server \verb|run()| will
not return until you call \verb|shutdown()|.

\subsubsection{Activation Mode \emph{Library}}

All activation modes discussed up until now assume client and server are
different programs that run in separate processes. This
approach has the advantage that client and server can be bound to each
other dynamically during runtime. The drawback is the overhead for doing
method invocations across process boundaries using some kind of IPC. The
activation mode \emph{library} eliminates this drawback while still
allowing runtime binding. This is achieved by loading an object
implementation (called a \emph{module} from now on) into the running
client. Invoking methods on an object loaded this way is as fast as
a C++ method invocation.

A client that wants to use this feature does not differ from other clients,
only the loadable module requires special code and you have to create a
special entry in the implementation repository. To give you an example we
want to change the bank account example from section \ref{SEC_MICO_BINDER}
to make use of dynamic loading. The only change in the client is the
address specified in the call to \verb|bind()|: we have to use
\verb|"local:"| instead of \verb|"inet:localhost:8888"|, because we want
to bind to the dynamically loaded object running in the same process:

\footnotesize
\begin{verbatim}
 1: // file account_client2.cc
 2:
 3: #include "account.h"
 4:
 5: 
 6: int main( int argc, char *argv[] )
 7: {
 8:   // ORB initialization
 9:   CORBA::ORB_var orb = CORBA::ORB_init( argc, argv, "mico-local-orb" );
10:   CORBA::BOA_var boa = orb->BOA_init( argc, argv, "mico-local-boa" );
11:
12:   CORBA::Object_var obj
13:     = orb->bind ("IDL:Account:1.0", "local:");
14:   if (CORBA::is_nil (obj)) {
15:      // no such object found ...
16:   }
17:   Account_var client = Account::_narrow( obj );
18: 
19:   client->deposit( 700 );
20:   client->withdraw( 250 );
21:   cout << "Balance is " << client->balance() << endl;
22:
23:   return 0;
24: }
\end{verbatim}
\normalsize

\noindent
Here is the code for the loadable module:

\footnotesize
\begin{verbatim}
 0: // file module.cc
 1:
 2: #include "account.h"
 3: #include <mico/template_impl.h>
 4:
 5: class Account_impl : virtual public Account_skel
 6: {
 7:   // unchanged, see section "MICO Application"
 8:   // ...
 9: };
10:
11: static Account_ptr server = Account::_nil();
12: 
13: extern "C" CORBA::Boolean
14: mico_module_init (const char *version)
15: {
16:   if (strcmp (version, MICO_VERSION))
17:     return FALSE;
18:   server = new Account_impl;
19:   return TRUE;
20: }
21:
22: extern "C" void
23: mico_module_exit ()
24: {
25:   CORBA::release (server);
26: }
\end{verbatim}
\normalsize

\noindent
Lines 13--20 define a function \verb|mico_module_init()| that is called when
the module is loaded into the running client. Note that this function must
be declared as \verb|extern "C"| to avoid C++ name mangling.
The \verb|version| argument to \verb|mico_module_init()| is a string
specifying the \MICO--version of the client the module is loaded into.
Lines 16 and 17 check if this version is the same as the \MICO--version
the module was compiled with and make module initialization fail by returning
\verb|FALSE| if they differ. Otherwise a new account object is created and
\verb|TRUE| is returned indicating successful module initialization. Note
that \verb|mico_module_init()| must not perform ORB and BOA initialization
since the client the module is loaded into did this already. The function
\verb|mico_module_exit()| is called just before the module is unloaded from
the client and should release all allocated resources: in our example the
account object created in \verb|mico_module_init()|.
\verb|mico_module_exit()| is only called if \verb|mico_module_init()| returned
\verb|TRUE|. Modules have to be compiled as a shared library, see section
\ref{SEC_WRAPPERS} for details and an example.

Although communication does not go through the BOA daemon when using
loadable modules you need a running \verb|micod| because
you have to create an implementation repository entry for the module.
See section \ref{SEC_IMR} for details. The directory \verb|demo/shlib|
contains a complete example.

There is currently one problem with loadable modules: throwing
exceptions from a loadable module into non--loadable module code
results in a segmentation fault. This is not a bug in \MICO\/ but
in the GNU--C++ compiler and/or dynamic loader.

%-------------------------------------------------------------------------
\subsection{Making Objects Persistent}
\label{SEC_PERS_OBJS}

In the last section we saw two cases where an object had to be
``moved'' between two different instances of a server\footnote{ Note
that the CORBA 2 specification only gives you some vague idea of
object persistence but omits any implementation details. That is why
everything explained in this section is \MICO--specific and will not
work with other CORBA implementations.}:

\begin{itemize}
\item
  if an unshared or per method server creates a second object it
  has to be moved to a new server instance.
\item
  if a server terminates and is restarted later all the objects of the
  terminated server have to be moved to the restarted server.
\end{itemize}


In all these cases the state of the moved object has to be saved before
and restored after moving. Because the BOA has no information about the
internal state of an object the user has to provide code for saving and
restoring. However, the BOA offers you some support methods.

Saving is done in the \verb|_save_object()| method of the object
implementation. If you do not provide this method for an object,
\verb|_save_object()| from the base class will be used, which will cause
the object to be treated as transient (i.e., it will not be restored
later). Let us again consider the account example. The internal
state of an account object consists of the current balance. Here is how to
save the state:

\footnotesize
\begin{verbatim}
 1:  // account_server3.cc
 2:
 3:  #include "account.h"
 4:  #include <iostream.h>
 5:  #include <fstream.h>
 6:
 7:  class Account_impl : virtual public Account_skel {
 8:    CORBA::Long _current_balance;
 9:  public:
10:    ...
11:    virtual CORBA::Boolean _save_object ()
12:    {
13:       ofstream out (_ident());
14:       out << _current_balance;
15:       return TRUE;
16:    }
17:  };
\end{verbatim}
\normalsize

\noindent
Pretty simple, eh? We just open a file and write the balance into it. The
only noteworthy thing is the file name, which is obtained by using the
\verb|_ident()| method. The returned string is guaranteed to be unique
among all objects managed by a single BOA daemon. If you use multiple
BOA daemons or use persistent servers that do not register with the BOA
you have to make sure no name clashes occur. One way to do this is to
create a new directory where all the files are created, in our example
\verb|/tmp/account/| would be appropriate. Another way to distinguish
different instances (objects) of on interface (class) is to use
\verb|BOA::ReferenceData|. See \verb|demo/boa/account2| for an example.

Restoring the state takes a bit more code. You need to subclass the
abstract baseclass \verb|CORBA::BOAObjectRestorer| providing an
implementation for the \verb|restore()| method:

\footnotesize
\begin{verbatim}
 1:  // account_server3.cc
 2:
 3:  class AccountLoader : public CORBA::BOAObjectRestorer {
 4:  public:
 5:    CORBA::Boolean restore (CORBA::Object_ptr obj)
 6:    {
 7:       if (!strcmp (obj->_repoid(), "IDL:Account:1.0")) {
 8:         new Account_impl (obj);
 9:         return TRUE;
10:       }
11:       // dont know about such objects
12:       return FALSE;
14:    }
15:  };
\end{verbatim}
\normalsize

\noindent
\verb|restore()| receives an object reference for the object that has to
be restored. We use the \verb|_repoid()| method to find out the
repository id\footnote{See section \ref{SEC_MICO_BINDER} for details on
repository ids.} of the object to be restored. If it is equal to the
repository id of account objects (\verb|"IDL:Account:1.0"|) we can go on
with restoring, otherwise we just return \verb|FALSE| indicating that
we cannot restore the object.

Restoring the object is now just a matter of calling a special
\verb|Account_impl| constructor which we still have to define:

\footnotesize
\begin{verbatim}
 1:  // account_server3.cc
 2:
 3:  class Account_impl : virtual public Account_skel {
 4:    CORBA::Long _current_balance;
 5:  public:
 6:    ...
 7:    Account_impl (CORBA::Object_ptr obj)
 8:      : Account_skel (obj)
 9:    {
10:      ifstream in (obj->_ident());
11:      in >> _current_balance;
12:    }
13:  };
\end{verbatim}
\normalsize

\noindent
The constructor is basically the counterpart to \verb|_save_object()|.
It uses \verb|_ident()| to obtain the identification string of the
object to be restored, opens the associated file and reads in the
current balance. Note the invocation of the base class constructor in
line 8, which is very important. If you forget this line the code will
still compile but will give you strange results, because the default
\verb|Account_skel| constructor will be used, which is an error.

Note that we have omitted error handling for the ease of exposition.
Usually one would check if the file exists and its contents are valid.
If an error is detected you should make
\verb|AccountLoader::restore()| return 
\verb|FALSE|\footnote{For instance by throwing an exception that is caught
in \texttt{restore()}.}.

Now what is left to do is to create an instance of the
\verb|AccountLoader| class. Note that you have to create at least
one such instance \emph{before} you do ORB and BOA initialization,
because restoring can already occur during BOA initialization. Of
course you can create serveral different \verb|BOAObjectRestorer|
subclasses each of which handles special kinds of objects. When an
object has to be restored the \verb|restore()| methods of the existing
restorer objects are called until eventually one returns \verb|TRUE|.
Note that you should not create new objects if any objects are being
restored, because otherwise you would get an infinitely growing number
of objects over time. The BOA method \verb|restoring()| returns
\verb|TRUE| if objects are being restored, \verb|FALSE| otherwise.
Here is the \verb|main()| function:

\footnotesize
\begin{verbatim}
 1:  // account_server3.cc
 2:
 3:  int main (int argc, char *argv[])
 4:  {
 5:    // create loader *before* BOA initialization
 6:    AccountLoader loader;
 7:
 8:    CORBA::ORB_var orb = CORBA::ORB_init (argc, argv, "mico-local-orb");
 9:    CORBA::BOA_var boa = orb->BOA_init (argc, argv, "mico-local-boa");
10:
11:    if (!boa->restoring()) {
12:      // create new objects only if not restoring
13:      new Account_impl;
14:    }
15:    boa->impl_is_ready (CORBA::ImplementationDef::_nil());
16:    orb->run ();
17:    return 0;
18:  }
\end{verbatim}
\normalsize

\noindent
In an unshared or per method server you would call

\begin{verbatim}
  boa->obj_is_ready (CORBA::Object::_nil(),
                     CORBA::ImplementationDef::_nil());
\end{verbatim}

\noindent
instead of \verb|impl_is_ready()|. The sources for a complete example
can be found in \verb|demo/boa/account2|.

Sometimes it is handy to know when saving of objects can occur. But you
cannot rely on this being the only occurences of object saving:

\begin{enumerate}
\item
  Just before a server is exiting all the objects that have not been released
  are saved. If you do not want an object to be saved you must make its
  \verb|_save_object()| method return \verb|FALSE| or do not provide a
  \verb|_save_object()| method at all. The object will then be treated as
  transient (i.e., it will not outlive the process it was created in).
\item
  When you call \verb|deactivate_obj()| on an object in an unshared or
  per method server saving is done during the call to \verb|deactivate_obj()|.
  Objects saved this way will \emph{not} be saved again at server exit
  according to 1.
\item
  When you call \verb|deactivate_impl()| in a shared or persistent server
  saving of all currently activate objects is done during the call to
  \verb|deactivate_impl()|.
  Objects saved this way will \emph{not} be saved again at server exit
  according to 1.
\item
  When you migrate an object saving of it is done during the call to
  \verb|change_implementation()|, see section \ref{SEC_MIGRATE} for details.
  Objects saved this way will \emph{not} be saved again at server exit
  according to 1.
\end{enumerate}

Note that it is quite likely that invocations on objects will occure
after a call to \verb|deactivate_obj()|, \verb|deactivate_impl()|, or
\verb|change_implementation()| because the server has to execute all
(buffered) invocations that arrived up until your call to one of the
above mentioned methods. So your code must be prepared to handle this.

Although the actual code for saving and restoring the state of an account
object are two--liners each real world applications often require complex
code for making objects persistent. Therefore the OMG has specified the
\emph{Persistent Object Service (POS)}, an implementation of which is not
yet provided by \MICO.

%-------------------------------------------------------------------------
\subsection{Migrating Objects}
\label{SEC_MIGRATE}

Up until now we described how objects are moved between different
\emph{instances} of the same server. Here we explain how to move
objects between two completely different servers. This is for example
useful if a server has to be replaced by a new version without interrupting
usual business.

Recall that we augmented the account object by a management interface
in section \ref{SEC_ACTIV_MODES}. The management interface offered a method
\verb|exit()| that terminates the server when invoked. Now let us add a
method \verb|migrate()| that migrates an account object to a new server.
The new server is specified through an implementation repository entry.

\footnotesize
\begin{verbatim}
  // account.idl
  interface Account {
    ...
    void migrate (in CORBA::ImplementationDef destination);
  };
\end{verbatim}
\normalsize

\noindent
Here is the implementation of the \verb|migrate()| method:

\footnotesize
\begin{verbatim}
 1:  #include "account.h"
 2:
 3:  class Account_impl : virtual public Account_skel {
 4:    ...
 5:  public:
 6:    ...
 7:    virtual void migrate (CORBA::ImplementationDef_ptr dest)
 8:    {
 9:       CORBA::BOA_var boa = _boa();
10:       boa->change_implementation (this, dest);
11:    }
12:  };
\end{verbatim}
\normalsize

\noindent
The \verb|change_implementation()| in line 10 does the whole job. It will
save the object's state as described in section \ref{SEC_ACTIV_MODES}
and tell the BOA daemon to use the new implementation from now on. See
\verb|demo/boa/account4| for an example.

The current version of \MICO\/ can only perform the migration when the
destination implementation is not currently active, which means that:

\begin{itemize}
\item
  you cannot migrate an object to a persistent server
\item
  you cannot migrate an object to a shared server that is already running
\end{itemize}

\noindent
This limitation will be removed in a future version of \MICO.

%-------------------------------------------------------------------------
\section{POA}
\label{SEC_POA}

The Basic Object Adapter provides a bare minimum of functionality to
server applications. As a consequence, many ORBs added custom
extensions to the BOA to support more complex demands upon an object
adapter, making server implementations incompatible among different
ORB vendors. In CORBA 2.2, the new \emph{Portable Object Adapter} was
introduced. It provides a much-extended interface that addresses many
needs that were wished for, but not available with the original BOA
specification. POA features include:
\begin{itemize}
\item Support for transparent activation of objects. Servers can
export object references for not-yet-active servants that will be
incarnated on demand.
\item Allow a single servant to support many object identities.
\item Allow many POAs in a single server, each governed by its own set
of \emph{policies}.
\item Delegate requests for non-existent servants either to a default
servant, or ask a servant manager for an appropriate servant.
\end{itemize}
These features, make the POA much more powerful than the BOA and
should fulfill most server applications' needs. As an example,
object references for some million entries in a database can be
generated, which are all implemented by a single default servant.

%-------------------------------------------------------------------------
\subsection{Architecture}
\label{SEC_POA_ARCH}

The general idea is to have each server contain a hierarchy of
POAs. Only the \emph{Root POA} is created by default; a reference to
the Root POA is obtained using the
\texttt{resolve\_\-initial\_\-references()} operation on the ORB. New
POAs can be created as the child of an existing POA, each with its own
set of policies.

Each POA maintains an \emph{Active Object Map} that maps all objects
that have been activated in the POA to a servant. For each incoming
request, the POA looks up the object reference in the Active Object
Map and tries to find the responsible servant. If none is found, the
request is either delegated to a default servant, or a servant manager
is invoked to activate or locate an appropriate servant.

Associated with each POA is a \emph{POA Manager} object. A POA Manager
can control one or many POAs. For each incoming request to an object,
the POA Manager's state is checked, which can be one of the following:

\begin{description}
\item[Active] ~\newline
Requests are performed immediately.
\item[Holding] ~\newline
Incoming requests are queued. This is the initial state of a POA
Manager; to perform requests, the POA Manager must be explicitely set
to the \emph{Active} state.
\item[Discarding] ~\newline
Requests are discarded. Clients receive a \texttt{TRANSIENT}
exception.
\item[Inactive] ~\newline
This is the ``final'' state of a POA Manager, which is entered prior
to destruction of the associated POAs. Clients receive an
\texttt{OBJ\_ADAPTER} exception.
\end{description}

Before continuing, we should more precisely define a few terms that
have already been freely used.

\begin{description}
\item[Object Reference] ~\newline
On the client side, an object reference encapsulates the identity of
a distinct abstract object. On the server side, an object reference is
composed of the POA identity in which the object is realized, and a
\emph{Object Id} that uniquely identifies the object within the
POA.
\item[Object Id] ~\newline
An Object Id is an opaque sequence of octets. Object Ids can be either
system generated (the POA assigns a unique Id upon object activation),
or user generated (the user must provide an Id upon object
activation). The object's Object Id cannot be changed through the
object's lifetime.

In many cases, object references and Object Id can be used
synonymously, since an object reference is just an Object Id with
opaque POA-added ``internal'' information.
\item[Servant] ~\newline
A servant provides the implementation for one or more object
references. In the C++ language mapping, a servant is an instance of a
C++ class that inherits from \texttt{PortableServer::ServantBase}.
This is true for dynamic skeleton implementations (DSI), or for
classes that inherit from IDL-generated skeletons.

The process of associating a servant with an Object Id is called
\emph{activation} and is performed using POA methods. A servant can be
activated more than once (to serve many different Object Ids) and can
be activated in many POAs. After activation, object references can be
obtained using other POA methods.

Servants are \emph{not} objects and do not inherit from
\texttt{CORBA::Object}. It is illegal to perform operations directly
upon a servant -- all invocations must be routed through the
ORB. Also, memory management of servants is entirely left to the
user. POAs keep only a pointer to a servant, so they must not be
deleted while being activated.
\item[Server] ~\newline
``Server'' refers to a complete process in which servants exist. A
server can contain one or more POAs, each of which can provide zero,
one or more active servants. Each active servant can then serve one or
more object references.
\end{description}

%-------------------------------------------------------------------------
\subsection{Policies}
\label{SEC_POA_POLICIES}

We have already mentioned the \emph{policies} that control various
aspects of POA behaviour. POA policies do not change over the POA's
lifetime. When creating a new POA as a child of an existing POA,
policies are not inherited from the parent, but instead each POA is
assigned a set of default policies if not explicitely defined.

\begin{description}
\item[Thread Policy] ~
\begin{description}
\item[\texttt{ORB\_CTRL\_MODEL}] (default)\newline
Invocations are performed as scheduled by the ORB. Potentially, many
upcalls are perfomed simultaneously.
\item[\texttt{SINGLE\_THREAD\_MODEL}] ~\newline
Invocations are serialized. At most a single upcall is performed at
any time.
\end{description}
Non-reentrant servants should only be activated in POAs with the
\texttt{SINGLE\_\-THREAD\_\-MODEL} policy.

As the current version of \MICO\ is not multithreaded, this policy is
not yet evaluated.
\item[Lifespan Policy] ~
\begin{description}
\item[\texttt{TRANSIENT}] (default)\newline
Objects activated in this POA cannot outlive the server process.
\item[\texttt{PERSISTENT}] ~\newline
Objects can outlive the server process
\end{description}
\item[Id Uniqueness Policy] ~
\begin{description}
\item[\texttt{UNIQUE\_ID}] (default)\newline
Servants can be activated at most once in this POA.
\item[\texttt{MULTIPLE\_ID}] ~\newline
Servants can be activated more than once in this POA and can therefore
serve more than one object reference.
\end{description}
\item[Id Assignment Policy] ~
\begin{description}
\item[\texttt{SYSTEM\_ID}] (default)\newline
Object Ids are assigned by the POA upon object activation.
\item[\texttt{USER\_ID}] ~\newline
Upon activation, each servant must be provided with a unique Id by the
user.
\end{description}
\item[Servant Retention Policy] ~
\begin{description}
\item[\texttt{RETAIN}] (default)\newline
The POA maintains a map of active servants (the Active Object Map).
\item[\texttt{NON\_RETAIN}] ~\newline
The POA does not maintain an Active Object Map.
\end{description}
\item[Request Processing Policy] ~
\begin{description}
\item[\texttt{USE\_ACTIVE\_OBJECT\_MAP\_ONLY}] (default)\newline
To process an incoming request, the object reference is looked up in
the Active Object Map only. If no active servant serving the reference
is found, the request is rejected, and an \texttt{OBJECT\_NOT\_EXIST}
exception is returned.
\item[\texttt{USE\_DEFAULT\_SERVANT}] ~\newline
The object reference is looked up in the Active Object Map first. If
no active servant is found to serve the reference, the request is
delegated to a default servant.
\item[\texttt{USE\_SERVANT\_MANAGER}] ~\newline
The object reference is looked up in the Active Object Map first. If
no active servant is found to serve the reference, a servant manager
is invoked to locate or incarnate an appropriate servant.
\end{description}
\item[Implicit Activation Policy] ~
\begin{description}
\item[\texttt{IMPLICIT\_ACTIVATION}] ~\newline
If an inactive servant is used in a context that requires the servant
to be active, the servant is implicitly activated.
\item[\texttt{NO\_IMPLICIT\_ACTIVATION}] (default)~\newline
It is an error to use an inactive servant in a context that requires
an active servant.
\end{description}
\end{description}

The Root POA has the \texttt{ORB\_\-CTRL\_\-MODEL}, \texttt{TRANSIENT},
\texttt{UNIQUE\_\-ID}, \texttt{SYSTEM\_\-ID}, \texttt{RETAIN},
\texttt{USE\_\-ACTIVE\_\-OBJECT\_\-MAP\_\-ONLY} and
\texttt{IMPLICIT\_\-ACTIVATION} policies.

%-------------------------------------------------------------------------
\subsection{Example}

As an example, let's write a simple POA-based server. You can find the
full code in the \texttt{demo/poa/hello-1} directory in the
\MICO\ distribution. Imagine a simple IDL description in the file
``hello.idl'':

\small
\begin{verbatim}
  interface HelloWorld {
    void hello ();
  };
\end{verbatim}
\normalsize

The first step is to invoke the IDL to C++ compiler in a way to
produce skeleton classes that use the POA:

\small
\begin{verbatim}
  idl hello.idl
\end{verbatim}
\normalsize

The IDL compiler will generate POA-baed skeletons by default. Next, we
rewrite the server.

\footnotesize
\begin{verbatim}
 1: // file server.cc
 2:
 3: #include "hello.h"
 4:
 5: class HelloWorld_impl : virtual public POA_HelloWorld
 6: {
 7:   public:
 8:     void hello() { printf ("Hello World!\n"); };
 9: };
10: 
11: 
12: int main( int argc, char *argv[] )
13: {
14:   CORBA::ORB_var orb = CORBA::ORB_init (argc, argv, "mico-local-orb");
15:   CORBA::Object_var poaobj = orb->resolve_initial_references ("RootPOA");
16:   PortableServer::POA_var poa = PortableServer::POA::_narrow (poaobj);
17:   PortableServer::POAManager_var mgr = poa->the_POAManager();
18:
19:   HelloWorld_impl * servant = new HelloWorld_impl;
20:
21:   PortableServer::ObjectId_var oid = poa->activate_object (servant);
22:
23:   mgr->activate ();
24:   orb->run();
25:
26:   poa->destroy (TRUE, TRUE);
27:   delete servant;
28:   return 0;
29: }
\end{verbatim}
\normalsize

The object implementation does not change much with respect to a
BOA-based one, the only difference is that \texttt{HelloWorld\_impl}
does not inherit from the BOA-based skeleton \texttt{HelloWorld\_skel}
any more, but from the POA-based skeleton \texttt{POA\_HelloWorld}.

In \texttt{main()}, we first initialize the ORB, then we obtain a
reference to the Root POA (lines 15--16) and to its POA Manager (line
17).

Then, we create an instance of our server object. In line 21, the
servant is activated. Since the Root POA has the \texttt{SYSTEM\_ID}
policy, a unique Object Id is generated automatically and returned. At
this point, clients can use the \MICO\ binder to connect to the
HelloWorld object.

However, client invocations upon the HelloWorld object are not yet
processed. The Root POA's POA Manager is created in the holding state,
so in line 23, we transition the POA Manager, and therefore the Root
POA, to the active state. We then enter the ORB's event loop in 24.

In this example, \texttt{run()} never returns, because we don't
provide a means to shut down the ORB. If that ever happened, lines
26--27 would first destroy the Root POA. Since that deactivates our
active HelloWorld object, we can then safely delete the servant.

Since the Root POA has the \texttt{IMPLICIT\_ACTIVATION} policy, we
can also use several other methods to activate the servant instead of
\texttt{activate\_\-object()}. We could, for example, use
\texttt{servant\_\-to\_\-reference()}, which first implicitly
activates the inactive servant and then returns an object reference
pointing to the servant. Or, we could invoke the servant's inherited
\texttt{\_this()} method, which also implicitly activates the servant
and returns an object reference.

\subsection{Using a Servant Manager}

While the previous example did introduce the POA, it did not
demonstrate any of its abilities -- the example would have been just
as simple using the BOA.

As a more complex example, we want to show a server that generates
``virtual'' object references that point to non-existent objects. We
then provide the POA with a servant manager that incarnates the
objects on demand.

We continue our series of ``Account'' examples. We provide the
implementation for a Bank object with a single ``create'' operation
that opens a new account. However, the Account object is not put into
existence at that point, we just return a reference that will cause
activation of an Account object when it is first accessed. This text
will only show some code fragments; find the full code in the
\texttt{demo/poa/account-2} directory.

The implementation of the Account object does not differ from
before. More interesting is the implementation of the Bank's
\texttt{create} operation:

\small
\begin{verbatim}
  Account_ptr
  Bank_impl::create ()
  {
    CORBA::Object_var obj = mypoa->create_reference ("IDL:Account:1.0");
    Account_ptr aref = Account::_narrow (obj);
    assert (!CORBA::is_nil (aref));
    return aref;
  }
\end{verbatim}
\normalsize

The \texttt{create\_reference()} operation on the POA does not cause
an activation to take place. It only creates a new object reference
encapsulating information about the supported interface and a unique
(system-generated) Object Id. This reference is then returned to the
client.

Now, when the client invokes an operation on the returned reference,
the POA will first search its Active Object Map, but will find no
servant to serve the request. We therefore implement a servant
manager, which will be asked to find an appropriate implementation.

There are two types of servant managers: a \texttt{Servant Activator}
activates a new servant, which will be retained in the POA's Active
Object Map to serve further requests on the same object. A
\texttt{Servant Locator} is used to locate a servant for a single
invocation only; the servant will not be retained for future use. The
type of servant manager depends on the POA's Servant Retention
policy.

In our case, we use a servant activator, which will incarnate and
activate a new servant whenever the account is used
\emph{first}. Further operations on the same object reference will use
the already active servant. Since the \texttt{create\_\-reference()}
operation uses a unique Object Id each time it is called, one new
servant will be incarnated for each Account -- this represents the
BOA's \emph{Unshared} activation mode.

A servant activator provides two operations, \texttt{incarnate} and
\texttt{etherealize}. The former one is called when a new servant
needs to be incarnated to serve a previously unknown Object
Id. \texttt{etherealize} is called when the servant is deactivated
(for example in POA shutdown) and allows the servant manager to clean
up associated data.

\small
\begin{verbatim}
  class AccountManager : public virtual POA_PortableServer::ServantActivator
  { /* declarations */ };

  PortableServer::Servant
  AccountManager::incarnate (/* params */)
  {
    return new Account_impl;
  }

  void
  AccountManager::etherealize (PortableServer::Servant serv,
                               /* many more params */)
  {
    delete serv;
  }
\end{verbatim}
\normalsize

Our servant activator implements the
\texttt{POA\_PortableServer::ServantActivator} interface. Since
servant managers are servants themselves, they must be activated like
any other servant (see below).

The \texttt{incarnate} operation has nothing to do but to create a new
Account servant. \texttt{incarnate} receives the current POA and the
requested Object Id as parameters, so it would be possible to perform
special initialization based on the Object Id that is to be served.

\texttt{etherealize} is just as simple, and deletes the servant. In
``real life'', the servant manager would have to make sure that the
servant is not in use anywhere else before deleting it. Here, this is
guaranteed by our program logic.

The \texttt{main()} code is a little more extensive than
before. Because the Root POA has the
\texttt{USE\_\-ACTIVE\_\-OBJECT\_\-MAP\_\-ONLY} policy and does not
allow a servant manager, we must create our own POA with the
\texttt{USE\_\-SERVANT\_\-MANAGER} policy.

\small
\begin{verbatim}
  CORBA::ORB_var orb = CORBA::ORB_init (argc, argv, "mico-local-orb");
  CORBA::Object_var poaobj = orb->resolve_initial_references ("RootPOA");
  PortableServer::POA_var poa = PortableServer::POA::_narrow (poaobj);
  PortableServer::POAManager_var mgr = poa->the_POAManager();

  CORBA::PolicyList pl;
  pl.length(1);
  pl[0] = poa->
    create_request_processing_policy (PortableServer::USE_SERVANT_MANAGER);
  PortableServer::POA_var mypoa = poa->create_POA ("MyPOA", mgr, pl);
\end{verbatim}
\normalsize

Note that we use the Root POA's POA Manager when creating the new
POA. This means that the POA Manager has now control over both POAs,
and changing its state affects both POAs. If we passed \texttt{NULL}
as the second parameter to \texttt{create\_POA()}, a new POA Manager
would have been created, and we would have to change both POA's states
separately.

We can now register the servant manager.

\small
\begin{verbatim}
  AccountManager * am = new AccountManager;
  PortableServer::ServantManager_var amref = am->_this ();
  mypoa->set_servant_manager (amref);
\end{verbatim}
\normalsize

After creating an instance of our servant manager, we obtain an object
reference using the inherited \texttt{\_this()} method. This also
implicitly activates the servant manager in the Root POA.

\small
\begin{verbatim}
  Bank_impl * micocash = new Bank_impl (mypoa);
  PortableServer::ObjectId_var oid = poa->activate_object (micocash);
  mgr->activate ();
  orb->run();
\end{verbatim}
\normalsize

Now the only thing left to do is to activate a Bank object, to change
both POAs to the active state, and to enter the ORB's event loop.

%-------------------------------------------------------------------------
\subsection{Persistent Objects}

Our previous examples used ``transient'' objects which cannot outlive
the server process they were created in. If you write a server that
activates a servant and export its object reference, and then stop and
re-start the server, clients will receive an exception that their
object reference has become invalid.

In many cases it is desirable to have persistent objects. A persistent
object has an infinite lifetime, not bound by the process that
implements the object. You can kill and restart the server process,
for example to save resources while it is not needed, or to update the
implementation, and the client objects will not notice as long as the
server is running whenever an invocation is performed.

An object is persistent if the servant that implements them is
activated in a POA that has the \verb|PERSISTENT| lifespan policy.

As an example, we will expand our Bank to create persistent
accounts. When the server goes down, we want to write the account
balances to a disk file, and when the server is restarted, the
balances are read back in. To accomplish this, we use a persistent POA
to create our accounts in. Using a servant manager provides us with
the necessary hooks to save and restore the state: when etherealizing
an account, the balance is written to disk, and when incarnating an
account, we check if an appropriately named file with a balance
exists.

We also make the Bank itself persistent, but use a different POA to
activate the Bank in. Of course, we could use the Accounts' POA for
the Bank, too, but then, our servant manager would have to
discriminate whether it is etherealizing an Account or a Bank: using a
different POA comes more cheaply.

The implementation of the Account object is the same as in the
previous examples. The Bank is basically the same, too. One change is
that the \texttt{create} operation has been extended to activate
accounts with a specific Object Id -- we will use an Account's Object
Id as the name for the balance file on disk.

We also add a \texttt{shutdown} operation to the Bank interface, which
is supposed to terminate the server process. This is accomplished
simply by calling the ORB's shutdown method:

\small
\begin{verbatim}
  void
  Bank_impl::shutdown (void)
  {
    orb->shutdown (TRUE);
  }
\end{verbatim}
\normalsize

Invoking \texttt{shutdown()} on the ORB first of all causes the
destruction of all object adapters. Destruction of the Account's POA
next causes all active objects -- our accounts -- to be etherealized
by invoking the servant manager. Consequently, the servant manager is
all we need to save and restore our state.

One problem is that the servant manager's \texttt{etherealize()}
method receives a \texttt{Portable\-Server::Servant} value. However, we
need access to the implementation's type, \texttt{Account\_impl*}, to
query the current balance. Since CORBA does not provide narrowing for
servant types, we have to find a solution on our own. Here, we use an
STL map mapping the one to the other:\footnote{If supported by the C++
compiler, the \texttt{dynamic\_cast<>} operator could be used instead.}

\small
\begin{verbatim}
  class Account_impl;
  typedef map<PortableServer::Servant,
    Account_impl *,
    less<PortableServer::Servant> > ServantMap;
  ServantMap svmap;
\end{verbatim}
\normalsize

When incarnating an account, we populate this map; when etherealizing
the account, we can retrieve the implementation's pointer.

\small
\begin{verbatim}
  PortableServer::Servant
  AccountManager::incarnate (/* params */)
  {
    Account_impl * account = new Account_impl;
    CORBA::Long amount = ...  // retrieve balance from disk
    account->deposit (amount);

    svmap[account] = account; // populate map
    return account;
  }

  void
  AccountManager::etherealize (PortableServer::Servant serv,
                               /* many more params */)
  {
    ServantMap::iterator it = svmap.find (serv);
    Account_impl * impl = (*it).second;
    ... // save balance to disk
    svmap.erase (it);
    delete serv;
  }
\end{verbatim}
\normalsize

Please find the full source code in the \texttt{demo/poa/account-3}
directory.

One little bit of magic is left to do. Persistent POAs need a key, a
unique ``implementation name'' to identify their objects with. This
name must be given using the \texttt{-POAImplName} command line
option:\footnote{If you omit this option, you will receive an
``Invalid Policy'' exception when trying to create a persistent POA.}

\small
\begin{verbatim}
  ./server -POAImplName Bank
\end{verbatim}
\normalsize

Now we have persistent objects, but still have to start up the
server by hand. It would be much more convenient if the server was
started automatically. This can be achieved using the MICO Daemon
(\texttt{micod}) (see section \ref{SEC_BOA_DAEMON}).

For POA-based persistent servers, the implementation repository entry
must use the ``\texttt{poa}'' activation mode, for example

\small
\begin{verbatim}
  imr create Bank poa ./server IDL:Bank:1.0
\end{verbatim}
\normalsize

The second parameter to imr, \texttt{Bank}, is the same implementation
name as above; it must be unique within the implementation repository.
If a persistent POA is in contact with the MICO Daemon, object
references to a persistent object, when exported from the  server
process, will not point directly to the server but to the MICO
Daemon. Whenever a request is received by \texttt{micod}, it checks if
your server is running. If it is, the request is simply forwarded,
else a new server is started.

Usually, the first instance of your server must be started manually
for bootstrapping, so that you have a chance to export object
references to your persistent objects. An alternative is to use the
MICO Binder: the \texttt{IDL:Bank:1.0} in the command line above
tells \texttt{micod} that \texttt{bind()} requests for this
repository id can be forwarded to this server -- after starting it.

With POA-based persistent objects, you can also take advantage of the
``iioploc:'' addressing scheme that is introduced by the Interoperable
Naming Service. Instead of using a stringified object reference, you
can use a much simpler, URL-like scheme. The format for an
iioploc address is

\small
\begin{verbatim}
  iioploc://<host>:<port>/<object-key>
\end{verbatim}
\normalsize

\texttt{host} and \texttt{port} are as given with the
\texttt{-ORBIIOPAddr} command-line option, and the object key is
composed of the implementation name, the POA name and the Object Id,
separated by slashes. So, if you start a server using

\small
\begin{verbatim}
  ./server -ORBIIOPAddr inet:thishost:1234 -POAImplName MyService
\end{verbatim}
\normalsize

create a persistent POA with the name ``MyPOA'', and then activate an
object using the ``MyObject'' Object Id, you could refer to that
object using the IOR

\small
\begin{verbatim}
  iioploc://thishost:1234/MyService/MyPOA/MyObject
\end{verbatim}
\normalsize

These ``iioploc'' addresses are understood and translated by the
\texttt{string\_to\_object()} method and can therefore be used wherever
a stringified object reference can be used.

For added convenience, if the implementation name, the POA name and
the Object Id are the same, they are collapsed into a single
string. An example for this is the NameService implementation, which
uses the ``NameService'' implementation name. The root naming context
is then activated in the ``NameService'' POA using the ``NameService''
ObjectId. Consequently, the NameService can be addressed using

\small
\begin{verbatim}
  iioploc://<host>:<port>/NameService
\end{verbatim}
\normalsize

Please see the Interoperable Naming Service specification for more
details.

%-------------------------------------------------------------------------
\subsection{Reference Counting}

With the POA, implementations do not inherit from
\texttt{CORBA::Object}. Consequently, memory management for servants is
the user's responsibility. Eventually, a servant must be deleted with
C++'s \texttt{delete} operator, and a user must know when a servant is
safe to be deleted -- deleting a servant that is still known to a POA
leads to undesired results.

CORBA 2.3 addresses this problem and introduces reference counting for
servants. However, to maintain compatibility, this feature is optional
and must be explicitly activated by the user. This is done by adding
\texttt{POA\_PortableServer::RefCountServantBase} as a base class of
your implementation:

\small
\begin{verbatim}
class HelloWorld_impl :
  virtual public POA_HelloWorld
  virtual public PortableServer::RefCountServantBase
{
  ...
}
\end{verbatim}
\normalsize

This activates two new operations for your implementation,
\texttt{\_add\_ref()} and \texttt{\_remove\_ref()}. A newly
constructed servant has a reference count of 1, and it is deleted
automatically once its reference count drops to zero. This way, you
can, for example, forget about your servant just after it has been
created and activated:

\small
\begin{verbatim}
  HelloWorld_impl * hw = new HelloWorld_impl;
  HelloWorld_var ref = hw->_this(); // implicit activation
  hw->_remove_ref ();
\end{verbatim}
\normalsize

During activation, the POA has increased the reference count for the
servant, so you can remove your reference immediately afterwards. The
servant will be deleted automatically once the object is deactivated
or the POA is destroyed. Note, however, that once you introduce
reference counting, you must keep track of the references yourself:
All POA operations that return a servant
(i.e. \texttt{id\_to\_servant()} will increase the servants' reference
count. The \texttt{PortableServer::ServantBase\_var} class is provided
for automated reference counting, acting the same as
\texttt{CORBA::Object\_var} does for Objects.

%-------------------------------------------------------------------------
\section{IDL Compiler}
\label{SEC_IDL_COMPILER}

\MICO\ offers its own IDL--compiler called \texttt{idl} which is
briefly described in this section. The tool is used for translating
IDL--specifications to C++ as well as feeding IDL--specifications into
the interface repository.  The \texttt{idl} tool takes its input
either from a file or an interface repository and generates code for
C++ or CORBA--IDL. If the input is taken from a file, the \texttt{idl}
tool can additionally feed the specification into the interface
repository. The synopsis for \texttt{idl} is as follows:

\small
\begin{verbatim}
  idl [--help] [--version] [--config] [-D<define>] [-B<prefix>] [-I<path>] \
      [--no-exceptions] [--codegen-c++] [--no-codegen-c++] \
      [--codegen-c++] [--no-codegen-c++] [--codegen-idl] \
      [--no-codegen-idl] [--codegen-midl] [--no-codegen-midl] \
      [--c++-suffix=<suffix>] [--c++-impl] [--c++-skel] \
      [--hh-prefix=<hh-prefix>] [--hh-suffix=<suffix>] \
      [--use-quotes] [--no-paths] [--emit-repoids] \
      [--do-not-query-server-for-narrow] [--feed-ir] \
      [--feed-included-defs] [--repo-id=<id>] [--name=<prefix>] \
      [--pseudo] [--any] [--typecode] \
      [--poa] [--no-poa] [--boa] [--no-boa] [--no-poa-ties] \
      [--gen-included-defs] [--gen-full-dispatcher] \
      [--include-prefix=<include-prefix>] \
      [--include-suffix=<include-suffix>] \
      [<file>]
\end{verbatim}
\normalsize

\noindent
In the following a detailed description of all the options is
given:

\begin{description}
\item[\texttt{--help}]
  ~\newline
  Gives an overview of all supported command line options.
\item[\texttt{--version}]
  ~\newline
  Prints the version of \MICO.
\item[\texttt{--config}]
  ~\newline
  Prints some important configuration infos.
\item[\texttt{-D<define>}]
  ~\newline
  Defines a preprocessor macro. This option is equivalent to the
  \texttt{-D} switch of most C--compilers.
\item[\texttt{-B<prefix>}]
  ~\newline
  This option specifies the prefix to the include directory where to
  find the include files of the compiler itself.
\item[\texttt{-I<path>}]
  ~\newline
  Defines a search path for \texttt{\#include} directives. This option
  is equivalent to the \texttt{-I} switch of most C-compilers.
  When generating \texttt{\#include} directives, the IDL compiler
  relativizes the included file against the best match among the defined
  search paths.
\item[\texttt{--no-exceptions}]
  ~\newline
  Tells \texttt{idl} to disable exception handling in the generated code.
  Code for the exception classes is still generated but throwing exceptions
  will result in an error message and abort the program. This option
  can only be used in conjunction with \texttt{--codegen-c++}. This
  option is off by default.
\item[\texttt{--codegen-c++}]
  ~\newline
  Tells \texttt{idl} to generate code for C++ as defined by the
  language mapping IDL to C++. The \texttt{idl} tool will generate two
  files, one ending in \texttt{.h} and one in \texttt{.cc} with the
  same basenames. This option is the default.
\item[\texttt{--no-codegen-c++}]
  ~\newline
  Turns off the code generation for C++.
\item[\texttt{--codegen-idl}]
  ~\newline
  Turns on the code generation for CORBA--IDL. The \texttt{idl} tool
  will generate a file which contains the IDL specification which can
  again be fed into the \texttt{idl} tool.  The basename of the file
  is specified with the \texttt{--name} option.
\item[\texttt{--no-codegen-idl}]
  ~\newline
  Turns off the code generation of CORBA--IDL. This option is the
  default.
\item[\texttt{--c++-suffix=<suffix>}]
  ~\newline
  If \texttt{--codegen-c++} is selected, then this option determines
  the suffix for the C++ implementation file. The default is
  ``\texttt{cc}''.
\item[\texttt{--c++-impl}]
  ~\newline
  This option will cause the generation of some default C++
  implementation classes for all interfaces contained in the IDL
  specification. This option requires \texttt{--codegen-c++}.
\item[\texttt{--c++-skel}]
  ~\newline
  Generate a separate file with suffix \texttt{\_skel.cc}
  that contains code only needed by servers (i.e., the skeletons).
  By default this code is emitted in the standard C++ implementation files.
  This option requires \texttt{--codegen-c++}.
\item[\texttt{--hh-prefix=<hh-prefix>}]
  ~\newline
  If \texttt{--codegen-c++} is selected, then this option causes the IDL
  compiler to generate the include statement for the C++ header file with
  the path prefix hh-prefix. The default is not to prefix a path.
\item[\texttt{--hh-suffix=<suffix>}]
  ~\newline
  If \texttt{--codegen-c++} is selected, then this option determines
  the suffix for the C++ header file. The default is ``\texttt{h}''.
\item[\texttt{--use-quotes}]
  ~\newline
  If selected, \texttt{\#include} directives are generated as
  \texttt{\#include\ $"$...$"$} instead of \texttt{\#include\ $<$...$>$}. 
\item[\texttt{--no-paths}]
  ~\newline
  If selected, \texttt{\#include} directives are generated without any path
  components.
\item[\texttt{--include-prefix <include-prefix>}]
  ~\newline
  This option causes the IDL compiler to substitute any occurrence of the
  include path specified by the closest preceeding \texttt{-I} option with
  \texttt{include-prefix} when generating \texttt{\#include} directives.
\item[\texttt{--include-postfix <include-postfix>}]
  ~\newline
  This option causes the IDL compiler to insert \texttt{include-postfix}
  between any occurrence of the include path specified by the closest
  preceeding \texttt{-I} option and the remaining subdirectory and file name
  when generating \texttt{\#include} directives.
\item[\texttt{--emit-repoids}]
  ~\newline
  This option will cause \texttt{\#pragma} directives to be emitted,
  which associate the repository id of each IDL construct.
  This option can only be used in conjunction with the option
  \texttt{--codegen-idl}.
\item[\texttt{--do-not-query-server-for-narrow}]
  ~\newline
  If this option is used, the IDL compiler will omit special code for
  all \texttt{\_narrow()} methods which inhibits the querying of
  remote servers at runtime. In certain circumstances this is
  permissible, resulting in more efficient runtime behaviour. See
  \texttt{test/idl/26/README} for further comments.
\item[\texttt{--feed-ir}]
  ~\newline
  The CORBA--IDL which is specified as a command line option is fed
  into the \emph{interface repository}. This option requires the
  \texttt{ird} daemon to be running.
\item[\texttt{--feed-included-defs}]
  ~\newline
  This option can only be used in conjunction with \texttt{--feed-ir}.
  If this option is used, IDL definitions located in included files
  are fed into the interface repository as well. The default is to feed
  only the definitions of the main IDL file into the IR.
\item[\texttt{--repo-id=<id>}]
  ~\newline
  The code generation is done from the information contained in the
  \emph{interface repository} instead from a file. This option
  requires the \texttt{ird} daemon to be running. The parameter
  \texttt{id} is a repository identifier and must denote a CORBA
  module.
\item[\texttt{--name=<prefix>}]
  ~\newline
  This option controls the prefix of the file names if a code
  generation is selected. This option is mandatory if the input is
  taken from the interface repository. If the input is taken from a
  file, the prefix is derived from the basename of the file name.
\item[\texttt{--pseudo}]
  ~\newline
  Generates code for ``pseudo interfaces''. No stubs, skeletons or code
  for marshalling data to and from ``any'' variables is produced. Only
  supported for C++ code generation.
\item[\texttt{--any}]
  ~\newline
  Activates support for insertion and extraction operators of user
  defined IDL types for \texttt{Any}. Can only be used in conjunction
  with \texttt{--codegen-c++}. This option implies
  \texttt{--typecode}.
\item[\texttt{--typecode}]
  ~\newline
  Generates code for TypeCodes of user defined IDL types. Can only be
  used in conjunction with \texttt{--codegen-c++}.
\item[\texttt{--poa}]
  ~\newline
  Turns on generation of skeleton classes based on the Portable Object
  Adapter (POA). This is the default.
\item[\texttt{--no-poa}]
  ~\newline
  Turns off generation of POA-based skeletons.
\item[\texttt{--no-poa-ties}]
  ~\newline
  When using \texttt{--poa}, this option can be used to turn off
  generation of Tie classes if not needed.
\item[\texttt{--boa}]
  ~\newline
  Turns on generation of skeleton classes using the Basic Object
  Adapter (BOA).
\item[\texttt{--no-boa}]
  ~\newline
  Turns off generation of BOA-based skeletons. This is the default.
\item[\texttt{--gen-included-defs}]
  ~\newline
  Generate code that was included using the \texttt{\#include} directive.
\item[\texttt{--gen-full-dispatcher}]
  ~\newline
  Usually the skeleton class generated for an interface contains only
  the dispatcher for the operations and attributes defined in this
  interface. With this option, the dispatcher will also include
  operations and attributes inherited from all base interfaces.
\end{description}

\noindent
Here are some examples on how to use the \texttt{idl} tool:

\begin{description}
\item[\texttt{idl account.idl}]
  ~\newline
  Translates the IDL--specification contained in account.idl according
  to the C++ language mapping. This will generate two files in the
  current directory.
\item[\texttt{idl --feed-ir account.idl}]
  ~\newline
  Same as above but the IDL--specification is also fed into the
  interface repository.
\item[\texttt{idl --feed-ir --no-codegen-c++ account.idl}]
  ~\newline
  Same as above but the generation of C++ stubs and skeletons is
  omitted.
\item[\texttt{idl --repo-id=IDL:Account:1.0 --no-codegen-c++
  --codegen-idl --name=out}]
  ~\newline
  This command will generate IDL--code from the information contained
  in the interface repository. This requires the \texttt{ird} daemon
  to be running.  The output is written to a file called
  \texttt{out.idl}.
\item[\texttt{idl --no-codegen-c++ --codegen-idl --name=out
  account.idl}]
  ~\newline
  This command will translate the IDL--specification contained in
  \texttt{account.idl} and into a semantical equivalent
  IDL--specification in file \texttt{out.idl}. This could be useful if
  you want to misuse the IDL--compiler as a pretty printer.
\end{description}

%-------------------------------------------------------------------------
\section{Compiler and Linker Wrappers}
\label{SEC_WRAPPERS}

It can be quite complicated to compile and link \MICO\ applications
because you have to specify system dependent compiler flags, linker flags
and libraries. This is why \MICO\/ provides you with four shells scripts:

\begin{description}
\item[\texttt{mico-c++}]
  ~\newline
  should be used as the C++ compiler when compiling the C++ source files of
  a \MICO--application.
\item[\texttt{mico-ld}]
  ~\newline
  should be used as the linker when linking together the \texttt{.o} files
  of a \MICO--application.
\item[\texttt{mico-shc++}]
  ~\newline
  should be used as the C++ compiler when compiling the C++ source files of
  a \MICO\/ dynamically loadable module. \texttt{mico-shc++} will not be
  available unless you specified the \texttt{--enable-dynamic} option
  during configuration.
\item[\texttt{mico-shld}]
  ~\newline
  should be used as the linker when linking together the \texttt{.o} files
  of a \MICO\/ dynamically loadable module. \texttt{mico-shld} will not be
  available unless you specified the \texttt{--enable-dynamic} option
  during configuration.
\end{description}

\noindent
The scripts can be used just like the normal compiler/linker, except that
for \texttt{mico-shld} you do not specify a file name suffix for the output
file because \texttt{mico-shld} will append a system dependent shared object
suffix (\verb|.so| on most systems) to the specified output file name.

\subsection{Examples}

Let us consider building a simple \MICO--aplication that consists of two
files: \verb|account.idl| and \verb|main.cc|. Here is how to build
\verb|account|:

\small
\begin{verbatim}
  idl account.idl
  mico-c++ -I. -c account.cc -o account.o
  mico-c++ -I. -c main.cc -o main.o
  mico-ld account.o main.o -o account -lmico@DOTVERSION@
\end{verbatim}
\normalsize

\noindent
As a second example let us consider building a dynamically loadable module
and a client program that loads the module. We have three source files
now: \verb|account.idl|, \verb|client.cc|, and \verb|module.cc|:

\small
\begin{verbatim}
  idl account.idl
  mico-shc++ -I. -c account.cc -o account.o
  mico-shc++ -I. -c module.cc -o module.o
  mico-shld -o module module.o account.o -lmico@DOTVERSION@

  mico-c++ -I. -c client.cc -o client.o
  mico-ld account.o client.o -o client -lmico@DOTVERSION@
\end{verbatim}
\normalsize

\noindent
Note that

\begin{itemize}
\item all files that go into the module must be compiled using
  \texttt{mico-shc++} instead of \texttt{mico-c++}.
\item \texttt{module} was specified as the output file, but
  \texttt{mico-shld} will generate \texttt{module.so} (the extension depends
  on your system).
\item \verb|account.o| must be linked both into the module and the client but
  is compiled only once using \texttt{mico-shc++}. One would expect that
  \texttt{account.cc} had to be compiled twice: once with \texttt{mico-c++}
  for use in the client and once with \texttt{mico-shc++} for use in the
  module. The rule is that using \texttt{mico-shc++} where \texttt{mico-c++}
  should be used does not harm, but \emph{not} the other way around.
\end{itemize}

%-------------------------------------------------------------------------
\chapter{C++ mapping}

This chapter features some highlights of the IDL to C++ mapping.
Sometimes we just quote facts from the CORBA standard, sometimes
we describe some details which are specific to \MICO.


%-------------------------------------------------------------------------
\section{Using strings}

Strings have always been a source of confusion. The CORBA standard
adopts a not necessarily intuitive mapping for strings for the C++
language. The following description is partially taken from chapter
the CORBA specification.

As in the C mapping, the OMG IDL string type, whether bounded or
unbounded, is mapped to \texttt{char*} in C++. String data is
null--terminated.  In addition, the CORBA module defines a class
\texttt{String\_var} that contains a \texttt{char*} value and
automatically frees the pointer when a \texttt{String\_var} object is
deallocated. When a \texttt{String\_var} is constructed or assigned
from a \texttt{char*}, the \texttt{char*} is consumed and thus the
string data may no longer be accessed through it by the caller.
Assignment or construction from a \texttt{const char*} or from another
\texttt{String\_var} causes a copy. The \texttt{String\_var} class
also provides operations to convert to and from \texttt{char*} values,
as well as subscripting operations to access characters within the
string. The full definition of the \texttt{String\_var} interface is
given in appendix of the CORBA specification.

For dynamic allocation of strings, compliant programs must use the
following functions from the CORBA namespace:

\small
\begin{verbatim}
  // C++
  namespace CORBA {
    char *string_alloc( ULong len );
    char *string_dup( const char* );
    void string_free( char * );
    ...
  }
\end{verbatim}
\normalsize

The \texttt{string\_alloc} function dynamically allocates a string, or
returns a null pointer if it cannot perform the allocation. It
allocates \texttt{len+1} characters so that the resulting string has
enough space to hold a trailing NULL character. The
\texttt{string\_dup} function dynamically allocates enough space to
hold a copy of its string argument, including the NULL character,
copies its string argument into that memory, and returns a pointer to
the new string. If allocation fails, a null pointer is returned. The
\texttt{string\_free} function deallocates a string that was allocated
with \texttt{string\_alloc} or \texttt{string\_dup}. Passing a null
pointer to \texttt{string\_free} is acceptable and results in no
action being performed.

Note that a static array of char in C++ decays to a \texttt{char*}, so
care must be taken when assigning one to a \texttt{String\_var}, since
the \texttt{String\_var} will assume the pointer points to data
allocated via \texttt{string\_alloc} and thus will eventually attempt
to \texttt{string\_free} it:

\small
\begin{verbatim}
  // C++
  // The following is an error, since the char* should point to
  // data allocated via string_alloc so it can be consumed
  String_var s = "static string"; // error
  
  // The following are OK, since const char* are copied,
  // not consumed
  const char* sp = "static string";
  s = sp;
  s = (const char*)"static string too";
\end{verbatim}
\normalsize

\noindent
See the directory \texttt{mico/test/idl/5} for some examples on how to
use strings in conjunction with operations.

%-------------------------------------------------------------------------
\section{Untyped values}

The handling of untyped values is one of CORBAs strengths. The
pre--defined C++ class \texttt{Any} in the namespace \texttt{CORBA}
provides this support. An instance of class \texttt{Any} represents a
value of an arbitrary IDL--type. For each type, the class \texttt{Any}
defines the overloaded operators \texttt{>>=} and \texttt{<<=}. These
two operators are responsible for the insertion and extraction of the
data values. The following code fragment demonstrates the usage of
these operators:

\small
\begin{verbatim}
  // C++
  CORBA::Any a;

  // Insertion into any
  a <<= (CORBA::ULong) 10;

  // Extraction from any
  CORBA::ULong l;
  a >>= l;
\end{verbatim}
\normalsize

At the end of this example the variable \texttt{l} should have the
value 10.  The library of \MICO\ provides overloaded definitions of
these operators for all basic data types. Some of these data types are
ambiguous in the sense that they collide with other basic data types.
This is true for the IDL--types \texttt{boolean}, \texttt{octet},
\texttt{char} and \texttt{string}. For each of these IDL--types, CORBA
prescribes a pair of supporting functions which help to disambiguate
the type clashes. For the type \texttt{boolean} for example the usage
of these supporting function is:

\small
\begin{verbatim}
  CORBA::Any a;

  // Insertion into any
  a <<= CORBA::Any::from_boolean( TRUE );

  // Extraction from any
  CORBA::Boolean b;
  a >>= CORBA::Any::to_boolean( b );
\end{verbatim}
\normalsize

The usage of the other supporting functions for \texttt{octet},
\texttt{char} and \texttt{string} is equivalent. For bounded strings
the supporting functions \texttt{from\_string} and \texttt{to\_string}
accept an additional \texttt{long}--parameter which reflects the
bound.

For each type defined in an IDL specification, the IDL--compiler
generates an overloaded version of the operators \texttt{>>=} and
\texttt{<<=}. For example given the following IDL specification:


\small
\begin{verbatim}
  // IDL
  struct S1 {
    long x;
    char c;
  };

  struct S2 {
    string str;
  };
\end{verbatim}
\normalsize

The \MICO\ IDL--compiler will automatically generate appropriate
definitions of \texttt{>>=} and \texttt{<<=} for the IDL types
\texttt{S1} and \texttt{S2}. The following code fragment demonstrates
the usage of these operators:

\small
\begin{verbatim}
 1:  void show_any( const CORBA::Any& a )
 2:  {
 3:    S1 s1;
 4:    S2 s2;
 5:  
 6:    if( a >>= s1 ) {
 7:      cout << "Found struct S1" << endl;
 8:      cout << s1.x << endl;
 9:      cout << s1.c << endl;
10:    }
11:    if( a >>= s2 ) {
12:      cout << "Found struct S2" << endl;
13:      cout << s2.str << endl;
14:    }
15:  }
16:
17:  int main( int argc, char *argv[] )
18:  {
19:    //...
20:    CORBA::Any a;
21:  
22:    S2 s2;
23:    s2.str = (const char *) "Hello";
24:    a <<= s2;
25:    show_any( a );
26:  
27:    S1 s1;
28:    s1.x = 42;
29:    s1.c = 'C';
30:    a <<= s1;
31:    show_any( a );
32:  }
\end{verbatim}
\normalsize

The main program first initializes an instance of a \texttt{S2} (lines
22--24) and then calls the function \texttt{show\_any}. Function
\texttt{show\_any} tries to extract the value contained in the any.
This example also demonstrates how to tell whether the extraction was
successful or not. The operator \texttt{>>=} returns true, iff the
type of the value contained in the any matches with the type of the
variable of the right side of \texttt{>>=}. If the any should contain
something else than \texttt{S1} or \texttt{S2}, then
\texttt{show\_any} will fall through both \texttt{if}--statements in
lines 6 and 11. The complete sources for the above example can be
found in \texttt{mico/test/idl/14}.


For some IDL types two different \verb|>>=| and \verb|<<=| operators
are provided: a copying and a non--copying version. The copying
version of the \verb|<<=| operator takes a reference to the IDL type
and inserts a copy of it into the \verb|Any|.  The non--copying version
takes a pointer to the IDL type and moves it into the \verb|Any|
without making a copy. The user must not access the inserted value
afterwards. The copying version of the \verb|>>=| operator takes a
reference to the IDL type and copies the value of the \verb|Any| into
it. The non--copying version takes a reference to a pointer to the IDL
type and points it to the value in the \verb|Any|. The user
must not free the returned value. Here are some examples:

\small
\begin{verbatim}
  // IDL
  struct foo {
    long l;
    short s;
  };

  // C++
  CORBA::Any a;

  // copying <<=
  foo f;
  a <<= f;

  // non-copying <<=
  foo *f = new foo;
  a <<= f;
  // do not touch 'f' here ...

  // copying >>=
  foo f;
  a >>= f;

  // non-copying >>=
  foo *f;
  a >>= f;
  // do not free 'f'
  // changing 'a' invalidates 'f'
\end{verbatim}
\normalsize

\noindent
Table \ref{TAB_ANY_OPS} gives an overview of the operators provided for
each IDL type (nc. means non--copying).

\begin{table}
\centering
\begin{tabular}{l||c|c|c|c}
IDL type & \texttt{<<=} & nc. \texttt{<<=} & \texttt{>>=} & nc. \texttt{>>=} \\
\hline
base type   & + &   & + &   \\
enum        & + &   & + &   \\
any         & + & + & + & + \\
fixed       & + & + & + & + \\
string      & + & + &   & + \\
wstring     & + & + &   & + \\
sequence    & + & + & + & + \\
array       & + & + &   & + \\
struct      & + & + & + & + \\
union       & + & + & + & + \\
interface   & + & + &   & + \\
pseudo objs & + & + &   & + \\
valuetype   & + & + &   & + \\
\end{tabular}
\caption{Any insertion and extraction operators}
\label{TAB_ANY_OPS}
\end{table}

\subsection{Unknown Constructed Types}

\MICO's \verb|Any| implementation offers an extended interface for
typesafe insertion and extraction of constructed types that were not
known at compile time. This interface is also used by the \verb|<<=| and
\verb|>>=| operators generated by the IDL compiler for constructed
types. Lets look at the generated operators for a simple structure:

\small
\begin{verbatim}
 1:  // IDL
 2:  struct foo {
 3:    long l;
 4:    short s;
 5:  };
 6:
 7:  // C++
 8:  void operator<<= ( CORBA::Any &a, const foo &s )
 9:  {
10:    a.type( _tc_foo );
11:    a.struct_put_begin();
12:    a <<= s.l;
13:    a <<= s.s;
14:    a.struct_put_end();
15:  }
16:
17:  CORBA::Boolean operator>>=( const CORBA::Any &a, foo &s )
18:  {
19:    return a.struct_get_begin() &&
20:           (a >>= s.l) &&
21:           (a >>= s.s) &&
22:           a.struct_get_end();
23:  }
\end{verbatim}
\normalsize

\noindent
The \verb|<<=| operator tells the \verb|Any| the \verb|TypeCode|
(\verb|_tc_foo|) of the to be inserted structure in line 10. Those
\verb|_tc_*| constants are generated by the IDL compiler as well. If you
want to insert a constructed type that was not known at compile time you
have to get the \verb|TypeCode| from somewhere else (e.g., from the
interface repository) or you have to create one using the
\verb|create_*_tc()| ORB methods.

After telling the \verb|Any| the \verb|TypeCode| the \verb|<<=| operator
opens a structure in line 11, shifts in the elements of the struct in lines
12--13 and closes the struct in line 14. While doing so the \verb|Any|
checks the correctness of the inserted items using the \verb|TypeCode|. If
it detects an error (e.g., the \verb|TypeCode| says the first element of the
struct is a short and you insert a float) the corresponding method or
\verb|<<=| operator will return FALSE. If the structure contained another
constructed type you had to make nested calls to \verb|struct_put_begin()|
and \verb|struct_put_end()| or the corresponding methods for unions,
exceptions, arrays, or sequences.

The \verb|>>=| operator in lines 17--23 has the same structure as
the \verb|<<=| operator but uses \verb|>>=| operators to extract the struct
elements and \verb|struct_get_begin()| and \verb|struct_get_end()| to open
and close the structure. There is no need to specify a \verb|TypeCode| before
extraction because the \verb|Any| knows it already.

\subsection{Subtyping}

Another feature of \MICO's \verb|Any| implementation is its subtyping
support. The extraction operators of type \verb|Any| implement the
subtyping rules for recursive types as prescribed by the
\emph{Reference Model for Open Distributed Processing} (RM--ODP), see
\cite{odprm1,odprm2,odprm3,odprm4} for details. The idea behind
subtyping is the following: Imagine you want to call a CORBA method

\begin{verbatim}
  void bar (in long x);
\end{verbatim}

\noindent
but want to pass a \verb|short| as an argument instead of the required
\verb|long|. This should work in theory since each possible
\verb|short| value is also a \verb|long| value which means
\verb|short| is a subtype of \verb|long|. More generally speaking a
type $T_1$ is a subtype of type $T_2$ if you could pass $T_1$ as an
input parameter where a $T_2$ is expected. This means for basic types
such as \verb|long|: a basic type $T_1$ is a subtype of a basic type
$T_2$ iff the set of possible values of $T_1$ is a subset of the set
of possible values of $T_2$.  Figure \ref{FIG_SUBTYPE} shows the
subtype relations between CORBA's basic data types. In C++ the
compiler can automatically convert types along a chain of arrows, but
in a distributed CORBA application this can't be done by the compiler
alone because binding between client and server is performed at
runtime using a trader or a naming service. That is the subtype
checking must be done at runtime as well.

\begin{figure}
\begin{center}
\ \psfig{file=pics/subtype.eps,width=7cm}
\end{center}
\caption{\label{FIG_SUBTYPE} Subtype relations between basic CORBA types.}
\end{figure}

\noindent
In \MICO\/ the \verb|Any| type performs subtype checking at runtime. For
example:

\small
\begin{verbatim}
  // C++
  CORBA::Any a;
  a <<= (CORBA::Short) 42;
  ...
  CORBA::Double d;
  a >>= d;
\end{verbatim}
\normalsize

\noindent
will work because \verb|short| is a subtype of \verb|double| according to
figure \ref{FIG_SUBTYPE} but:

\small
\begin{verbatim}
  // C++
  CORBA::Any a;
  a <<= (CORBA::Long) 42;
  ...
  CORBA::ULong d;
  a >>= d;
\end{verbatim}
\normalsize

\noindent
will fail because \texttt{long} is not a subtype of \texttt{unsigned
  long}.  There is a special subtyping rule for structured types: A
struct type $T_1$ is a subtype of a struct type $T_2$ iff the elements
of $T_2$ are supertypes of the first elements of $T_1$. \texttt{struct
  S1} is for example a subtype of \texttt{struct S2}:

\small
\begin{verbatim}
  struct S1 {
    short s;
    long l;
  };

  struct S2 {
    long s;
  };
\end{verbatim}
\normalsize

\noindent
That is you can put a \verb|struct S1| into an \verb|Any| and unpack it
as a \verb|struct S2| later:

\small
\begin{verbatim}
  // C++
  CORBA::Any a;
  S1 s1 = { 10, 20 };
  a <<= s1;
  ...
  S2 s2;
  a >>= s2;
\end{verbatim}
\normalsize

\noindent
There are similar rules for the other constructed types.


%-------------------------------------------------------------------------
\section{Arrays}
\label{SEC_ARRAY}

Arrays are handled somewhat awkwardly in CORBA. The C++ mapping for
the declaration of an array is straight forward. Things are getting a
bit more complicated when arrays are being passed around as parameters
of operations.  Arrays are mapped to the corresponding C++ array
definition, which allows the definition of statically--initialized
data using the array. If the array element is a string or an object
reference, then the mapping uses the same type as for structure
members. That is, assignment to an array element will release the
storage associated with the old value.

\small
\begin{verbatim}
  // IDL
  typedef string V[10];
  typedef string M[1][2][3];

  // C++
  V v1; V_var v2;
  M m1; M_var m2;

  v1[1] = v2[1]; // free old storage, copy
  m1[0][1][2] = m2[0][1][2]; // free old storage, copy
\end{verbatim}
\normalsize

In the above example, the two assignments result in the storage
associated with the old value of the left--hand side being
automatically released before the value from the right--hand side is
copied.

Because arrays are mapped into regular C++ arrays, they present
special problems for the type--safe \texttt{Any} mapping described in
$[$16.14$]$. To facilitate their use with the type \texttt{Any},
\MICO\ also provides for each array type a distinct C++ type whose
name consists of the array name followed by the suffix
\texttt{\_forany}.  Like \texttt{Array\_var} types,
\texttt{Array\_forany} types allow access to the underlying array
type.  The interface of the \texttt{Array\_forany} type is identical
to that of the \texttt{Array\_var} type.

\small
\begin{verbatim}
  // IDL
  typedef string V[10];

  // C++
  V_forany v1, v2;
  v1[0] = ...;  // Initialize array

  CORBA::Any any;
  any <<= v1;
  any >>= v2;   // v1 and v2 now have identical contents
\end{verbatim}
\normalsize

Besides the \texttt{Array\_forany} mapping the CORBA standard also
describes a mapping for an \emph{array slice}. A slice of an array is
an array with all the dimension of the original but the first. Output
parameters and results are handled via pointers to array slices. The
array slice is named like the array itself plus appending the suffix
\texttt{\_slice}. For the declaration of type \texttt{M} in the
example above, the IDL compiler would generate the following type
definition:

\small
\begin{verbatim}
  // Generated by IDL compiler, C++
  typedef M M_slice[2][3];
\end{verbatim}
\normalsize

\noindent
Let's consider the following IDL specification (see also
\texttt{mico/test/idl/18}):

\small
\begin{verbatim}
  // IDL
  // Note: long_arr is an array of fixed length data type
  typedef long long_arr[ 10 ];

  // Note: SS is an array of variable data type
  typedef string SS[ 5 ][ 4 ];

  interface foo {
    SS bar( in SS x, inout SS y, out SS z, out long_arr w );
  };
\end{verbatim}
\normalsize

\noindent
The implementation of interface \texttt{foo} will look like this:

\small
\begin{verbatim}
class foo_impl : virtual public foo_skel
{
  //...
  SS_slice* bar( const SS ss1, SS ss2, SS_slice*& ss3, long_arr arr )
  {
    //...
    ss3 = SS_alloc();
    SS_slice *res = SS_alloc();
    return res;
  };
};
\end{verbatim}
\normalsize

Note that the result value of the operation \texttt{bar} is a pointer
to an array slice. Output parameters where the type is an array to a
variable length data type, are handled via a reference to a pointer of
an array slice. In order to facilitate memory management with array
slices, the CORBA standard prescribes the usage of special functions
defined at the same scope as the array type. For the array
\texttt{SS}, the following functions will be available to a program:

\small
\begin{verbatim}
  // C++
  SS_slice *SS_alloc();
  SS_slice *SS_dup( const SS_slice* );
  void SS_free( SS_slice * );
\end{verbatim}
\normalsize

The \texttt{SS\_alloc} function dynamically allocates an array, or
returns a null pointer if it cannot perform the allocation. The
\texttt{SS\_dup} function dynamically allocates a new array with the
same size as its array argument, copies each element of the argument
array into the new array, and returns a pointer to the new array. If
allocation fails, a null pointer is returned. The \texttt{SS\_free}
function deallocates an array that was allocated with
\texttt{SS\_alloc} or \texttt{SS\_dup}. Passing a null pointer to
\texttt{SS\_free} is acceptable and results in no action being
performed.


%-------------------------------------------------------------------------
\section{Unions}

Unions and structs in the CORBA--IDL allow the definition of
constructed data types. Each of them is defined through a set of
members. Is a struct used as an input parameter of an operation, all
of its members will be transmitted, whereas for a union at most one of
its members will actually be transmitted. The purpose of an IDL--union
is similar to that of a C--union: reduction of memory usage. This is
especially important in a middleware platform where less memory space
for a data type also means less data to transfer over the network. One
must carefully consider, when structs or unions should be used.

A special problem arises with unions when they are being used as
parameters of operation invocations: how does the receiving object
know which of the different members holds a valid value? In order to
make a distinction for this case, the IDL--union is a combination of a
C--union and a C--switch statement. Each member is clearly tagged with
a value of a given discriminator type (see also
\texttt{mico/test/idl/21}):

\small
\begin{verbatim}
  // IDL
  typedef octet Bytes[64];
  struct S { long len; };
  interface A;

  union U switch (long) {
    case 1: long x;
    case 2: Bytes y;
    case 3: string z;
    case 4:
    case 5: S w;
    default: A obj;
  };
\end{verbatim}
\normalsize

In the union \texttt{U} as shown above, \texttt{long} is the
discriminator type. The values following the case label must belong to
this discriminator type.  All integer types and enums are valid
discriminator types.  Unions map to C++ classes with access functions
for the union members and discriminant. The default union constructor
performs no application--visible initialization of the union. It does
not initialize the discriminator, nor does it initialize any union
members to a state useful to an application.  It is therefore an error
for an application to access the union before setting it. The copy
constructor and assignment operator both perform a deep--copy of their
parameters, with the assignment operator releasing old storage if
necessary. The destructor releases all storage owned by the union.
The following example helps illustrate the mapping for union types for
the union \texttt{U} as shown above:

\small
\begin{verbatim}
  // Generated C++ code
  typedef CORBA::Octet Bytes[64];
  typedef CORBA::Octet Bytes_slice;
  template<...> Bytes_forany;
  struct S { CORBA::Long len; };
  typedef ... A_ptr;

  class U {
    public:
      //...
      void _d( CORBA::Long );
      CORBA::Long _d() const;

      void x( CORBA::Long );
      CORBA::Long x() const;

      void y( Bytes );
      Bytes_slice *y() const;

      void z( char* );             // free old storage, no copy
      void z( const char* );       // free old storage, copy
      void z( const String_var& ); // free old storage, copy
      const char *z() const;

      void w( const S & ); // deep copy
      const S &w() const;  // read-only access
      S &w();              // read-write access

      void obj( A_ptr ); // release old objref, duplicate
      A_ptr obj() const; // no duplicate
  };
\end{verbatim}
\normalsize

The union discriminant access functions have the name \texttt{\_d} to
both be brief and avoid name conflicts with the members. The
\texttt{\_d} discriminator modifier function can only be used to set
the discriminant to a value within the same union member. In addition
to the \texttt{\_d} accessors, a union with an implicit default member
provides a \texttt{\_default()} member function that sets the
discriminant to a legal default value. A union has an implicit default
member if it does not have a default case and not all permissible
values of the union discriminant are listed.

Setting the union value through an access function automatically sets
the discriminant and may release the storage associated with the
previous value. Attempting to get a value through an access function
that does not match the current discriminant results in undefined
behavior. If an access function for a union member with multiple legal
discriminant values is used to set the value of the discriminant, the
union implementation will choose the value of the first case label in
the union (e.g.\ value $4$ for the member \texttt{w} of union
\texttt{U}), although it could be any other value for that member as
well.

The restrictions for using the \texttt{\_d} discriminator modifier
function are shown by the following examples, based on the definition
of the union \texttt{U} shown above:

\small
\begin{verbatim}
  // C++
  S s = ...;
  A_ptr a = ...;
  U u;

  u.w( s );   // member w selected, discrimintator == 4
  u._d( 4 );  // OK, member w selected
  u._d( 5 );  // OK, member w selected
  u._d( 1 );  // error, different member selected
  u.obj( a ); // member obj selected
  u._d( 7 );  // OK, member obj selected
  u._d( 1 );  // error, different member selected
\end{verbatim}
\normalsize

As shown here, the \texttt{\_d} modifier function cannot be used to
implicitly switch between different union members. The following shows
an example of how the \texttt{\_default()} member function is used:

\small
\begin{verbatim}
  // IDL
  union Z switch(boolean) {
    case TRUE: short s;
  };

  // C++
  Z z;
  z._default();  // implicit default member selected
  CORBA::Boolean disc = z._d(); // disc == FALSE
  U u;           // union U from previous example
  u._default();  // error, no _default() provided
\end{verbatim}
\normalsize

For union \texttt{Z}, calling the \texttt{\_default()} member function
causes the union's value to be composed solely of the discriminator
value of \texttt{FALSE}, since there is no explicit default member.
For union \texttt{U}, calling \texttt{\_default()} causes a
compilation error because \texttt{U} has an explicitly declared
default case and thus no \texttt{\_default()} member function. A
\texttt{\_default()} member function is only generated for unions with
implicit default members.

For an array union member, the accessor returns a pointer to the array
slice, where the slice is an array with all dimensions of the original
except the first (see section \ref{SEC_ARRAY} for a discussion on
array slices). The array slice return type allows for read--write
access for array members via regular subscript operators. For members
of an anonymous array type, supporting typedefs for the array are
generated directly into the union. For example:

\small
\begin{verbatim}
  // IDL
  union U switch (long) {
    case 1: long array[ 3 ][ 4 ];
  };

  // Generated C++ code
  class U {
    public:
    // ...
    typedef long _array_slice[ 4 ];
    void array( long arg[ 3 ][ 4 ] );
    _array_slice* array();
  };
\end{verbatim}
\normalsize

The name of the supporting array slice typedef is created by
prepending an underscore and appending \texttt{\_slice} to the union
member name. In the example above, the array member named
\texttt{\_array} results in an array slice typedef called
\texttt{\_array\_slice} nested in the union class.


%-------------------------------------------------------------------------
\section{Interface inheritance}
\label{SEC_INTERF_INHERITANCE}

The CORBA standard prescribes that IDL--interfaces need to be mapped
to C++ classes for the C++ language binding. The question arises, how
things are handled when interface inheritance is used. \MICO\ offers
two alternatives for implementing the skeletons when using interface
inheritance. Consider the following IDL definitions:

\small
\begin{verbatim}
  interface Base {
    void op1();
  };
 
  interface Derived : Base {
    void op2();
  };
\end{verbatim}
\normalsize

\texttt{Base} is an interface and serves as a base for interface
\texttt{Derived}. This means that all declarations in \texttt{Base}
are inherited to \texttt{Derived}. As we have seen before, the
\texttt{idl} tool creates stub-- and skeleton--classes for each
interface. The operations map to pure virtual functions which have to
be implemented by the programmer. For the interface \texttt{Base} this
is straight forward:

\small
\begin{verbatim}
  class Base_impl : virtual public Base_skel
  {
  public:
    Base_impl()
    {
    };
    void op1()
    {
      cout << "Base::op1()" << endl;
    };
  };
\end{verbatim}
\normalsize

The skeleton for \texttt{Derived} allows two different possible ways
to implement the skeleton. The difference between the two is, whether
the implementation of \texttt{Derived} inherits the implementation of
\texttt{Base} or not.  Let's take a look on how this translates to
lines of code. Here is the first alternative:

\small
\begin{verbatim}
  class Derived_impl : 
    virtual public Base_impl,
    virtual public Derived_skel
  {
  public:
    Derived_impl()
    {
    };
    void op2()
    {
      cout << "Derived::op2()" << endl;
    };
  };
\end{verbatim}
\normalsize

In the code fragment above, the implementation of \texttt{Derived}
inherits the implementation of \texttt{Base}. Note that
\texttt{Derived\_impl} inherits from \texttt{Base\_impl} and therefore
needs only to implement \texttt{op2()} since \texttt{op1()} is already
implemented in \texttt{Base\_impl}.

\textbf{Important note:} when implementing a class \verb|X_impl| that
inherits from multiple base classes you have to ensure that the
\verb|X_skel| constructor is the last one that is called. This can be
accomplished by making \verb|X_skel| the rightmost entry in the inheritance
list:

\begin{verbatim}
  class X_impl : ..., virtual public X_skel {
    ...
  };
\end{verbatim}


Now comes the second alternative
(note that the skeleton classes are still the same; there is no
particular switch with the \texttt{idl} tool where you have to decide
between the two alternatives):

\small
\begin{verbatim}
  class Derived_impl : 
    virtual public Base_skel,
    virtual public Derived_skel
  {
  public:
    Derived_impl()
    {
    };
    void op1()
    {
      cout << "Derived::op1()" << endl;
    };
    void op2()
    {
      cout << "Derived::op2()" << endl;
    };
  };
\end{verbatim}
\normalsize

You should notice two things: first of all \texttt{Derived\_impl} is
no longer derived from \texttt{Base\_impl} but rather from
\texttt{Base\_skel}. For this reason the class \texttt{Derived\_impl}
needs to implement the operation \texttt{op2()} itself. Figure
\ref{FIG_INHERITANCE_HIERARCHY} shows the inheritance hierarchy for
the classes generated by the IDL--compiler and their relationship to
the classes contained in the \MICO\ library. Compare this with figure
\ref{FIG_STUB_SKEL_HIERARCHY} on page
\pageref{FIG_STUB_SKEL_HIERARCHY}. This example can also be found in
the directory \texttt{mico/test/idl/15}.


\begin{figure}
\begin{center}
\ \psfig{file=pics/inheritance-hierarchy.eps,width=12cm}
\end{center}
\caption{\label{FIG_INHERITANCE_HIERARCHY} C++ class hierarchy for
  interface inheritance.}
\end{figure}


%-------------------------------------------------------------------------
\section{Modules}
\label{SEC_IDL_MODULE}

In contrast to other middleware platforms, CORBA does not assign an
universal unique identifier (UUID) to an interface. To avoid name
clashes, CORBA offers a structured name space, similar to the
directory structure of a UNIX file system. Within an IDL a scope is
defined by the keyword \texttt{module}. For example the following
IDL--code excerpt defines two modules called \texttt{Mod1} and
\texttt{Mod2} on the same level:

\small
\begin{verbatim}
  module Mod1 {
    //...
    interface foo;
  };

  module Mod2
  {
    //...
  };
\end{verbatim}
\normalsize

Module declarations can be nested which leads to the above mentioned
hierarchical namespace. The IDL to C++ mapping offers different
alternatives on how to map a module to C++. Those C++ compilers which
support the namespace feature of the C++ language, IDL--modules are
directly mapped to C++ namespaces. Unfortunately the GNU compiler
currently does not support namespaces. In this case the CORBA
specification offers two alternatives: either do some name mangling
such that a name reflects the absolute name of the IDL--identifier
where the names are separated by undersores (e.g.\ 
\texttt{Mod1\_foo}). The second alternative is to map an IDL--module
to a C++ \texttt{struct}.

The second alternative has two drawbacks: without a proper support for
namespaces all names have to be referenced by their absolute names,
i.e.\ there is no C++ keyword \texttt{using} (note that this is also
true for the first alternative). The second drawback has to do with
the possibility to re--open CORBA--modules which allows cyclic
definitions:

\small
\begin{verbatim}
  module M1 {
    typedef char A;
  };

  module M2
  {
    typedef M1::A B;
  };

  module M1 {  // re-open module M1
  {
    typedef M2::B C;
  };
\end{verbatim}
\normalsize

The declaration of a C++ \texttt{struct} has to occur in one location
(i.e.\ a \texttt{struct} can not be re--opened). Mapping IDL--modules
to C++ structs therefore implies, that re--opening of modules can not
be translated to C++. However, if the C++ compiler supports
namespaces, \MICO's IDL--compiler allows the re--opening of modules.
The backend of \MICO's IDL--compiler generates a dependency graph to
compute the correct ordering of IDL definitions. Figure
\ref{FIG_IDL_DEP} shows the dependency graph for the IDL specification
shown above. The correct ordering of IDL definitions is done by doing
a left--to--right, depth--first, post--order traversal of the
dependency graph starting from \texttt{\_top}, and omitting previously
visited nodes of the graph.

\begin{figure}
\begin{center}
\ \psfig{file=pics/idl-dep.eps,width=6.5cm}
\end{center}
\caption{\label{FIG_IDL_DEP} Dependency graph.}
\end{figure}


Sometimes it is necessary to have some control over the top--level
modules. This for example is used in \texttt{CORBA.h} where some
definitions have to be read in one at a time. The IDL--compiler
inserts some \texttt{\#define} in the generated \texttt{.h} file.
Setting and unsetting these defines allows to read the module
definitions one at a time. Given the two modules \texttt{Mod1} and
\texttt{Mod2} as above, the following C++ code fragment demonstrates
how to do this:


\small
\begin{verbatim}
 1:  // These #includes need to be done manually if
 2:  // MICO_NO_TOPLEVEL_MODULES is defined
 3:  #include <CORBA.h>
 4:  #include <mico/template_impl.h>
 5:
 6:  #define MICO_NO_TOPLEVEL_MODULES
 7:
 8:  // Get module Mod1
 9:  #define MICO_MODULE_Mod1
10:  struct Mod1 {
11:    #include "module.h"
11:  };
12:  #undef MICO_MODULE_Mod1
13:
14:  // Get module Mod2
15:  #define MICO_MODULE_Mod2
16:  struct Mod2 {
17:    #include "module.h"
18:  };
19:  #undef MICO_MODULE_Mod2
20:
21:  // Get global definitions in module.h
22:  #define MICO_MODULE__GLOBAL
23:  #include "module.h"
24:  #undef MICO_MODULE__GLOBAL
25:  #undef MICO_NO_TOPLEVEL_MODULES
\end{verbatim}
\normalsize

In this example we assume that the definitions are located in a file
called \texttt{module.h}.  First of all you need to define
\texttt{MICO\_NO\_TOPLEVEL\_MODULES} which simply means that you wish
to read in the definitions yourself (line 6). For each toplevel module
\texttt{XYZ} in an IDL--file there exists a define called
\texttt{MICO\_MODULE\_XYZ}.  Setting this define will activate all
definitions which belong to module \texttt{XYZ} (see lines 9 and 15).
Do not forget to undefine these definitions after the definitions are
read in (lines 12 and 19). There are some global definitions which do
not belong to any module. For these definitions there in a special
define called \texttt{MICO\_MODULE\_\_GLOBAL} (see line 22; the two
underscores are no typo).  The last thing we need to do is to undefine
\texttt{MICO\_MODULE\_\_GLOBAL} and
\texttt{MICO\_NO\_TOPLEVEL\_MODULE} (see lines 24 and 25).  This
example can also be found in the directory \texttt{mico/test/idl/10}.

%-------------------------------------------------------------------------
\section{Exceptions}

Due to the limited support for exceptions in earlier versions of the
GNU C++ compiler (namely gcc 2.7.2) \MICO\/ supports several kinds
of exception handling:

\begin{itemize}
\item CORBA compliant exception handling
\item MICO specific exception handling
\item no exception handling
\end{itemize}

\noindent
Two common problems with exception handling are ``catching by base
classes'' and ``exceptions in shared libraries'':

\begin{itemize}
\item catching by base classes: when throwing exception \verb|X| it should
  be possible to catch it by specifying a base class of \verb|X| in the
  catch clause. Some compilers (noteably gcc 2.7) do not support this.
\item exceptions in shared libraries: throwing an exception from a
  shared library into non shared library code does not work with
  some compilers on some platforms (gcc 2.7, gcc 2.8 and egcs 1.x
  on some platforms).
\end{itemize}

\noindent
Which kind of exception handling is used is determined by the
capabilities of the C++ compiler and command line options passed to
the \texttt{configure} script. By default \emph{CORBA compliant
exception handling} will be selected if the C++ compiler supports
catching by base classes, otherwise \emph{MICO specific exception
handling} is selected if the compiler supports exception handling at
all. If exceptions in shared libraries do not work then \emph{no
exception handling} is selected for code in shared libraries.
You can enforce \emph{MICO specific exception handling} by specifying
\texttt{--disable-std-eh} as a command line option to \texttt{configure}.
You can disable exception handling by specifying \texttt{--disable-except}
as a command line option to \texttt{configure}.

You can find out about the exception handling support of your \MICO\/
binaries by running the IDL--Compiler with the \texttt{--config}
command line option:

\small
\begin{verbatim}
  $ idl --config
  MICO version: 2.2.7
  supported CORBA version: 2.2
  exceptions: CORBA compliant
  modules are mapped to: namespaces
  STL is: miniSTL
  SSL support: no
  loadable modules: yes
\end{verbatim}
\normalsize

%$
\noindent
The following sections go into detail about each of the exception handling
modes supported by \MICO.

\subsection{CORBA Compliant Exception Handling}

As the name already indicates this exception handling mode is conformant
to the CORBA specification. You can use \texttt{throw} to throw
exceptions. Exceptions are caught by specifying the exact type or one of
the base types of the exception. Here are some examples:

\footnotesize
\begin{verbatim}
  // throw CORBA::UNKNOWN exception
  throw CORBA::UNKNOWN();

  // catch CORBA::UNKNOWN exception
  try {
    ...
  } catch (CORBA::UNKNOWN &ex) {
    ...
  }

  // catch all system exceptions (including CORBA::UNKNOWN)
  try {
    ...
  } catch (CORBA::SystemException &ex) {
    ...
  }

  // catch all user exceptions (wont catch CORBA::UNKNOWN)
  try {
    ...
  } catch (CORBA::UserException &ex) {
    ...
  }

  // catch all exceptions (including CORBA::UNKNOWN)
  try {
    ...
  } catch (CORBA::Exception &ex) {
    ...
  }
\end{verbatim}
\normalsize

\noindent
If an exception is thrown but not caught \MICO\/ will print out a short
description of the exception and terminate the process.

\subsection{MICO Specific Exception Handling}

This kind of exception handling has been invented for C++ compilers
that do not support catching by base classes. For example it is quite
common to catch all system exceptions. Since catching
\texttt{CORBA::SystemException \&} does not work one would have to
write one catch clause for each of the 30 system exceptions. To work
around this problem the function \verb|mico_throw()| and special \verb|_var|
types have been introduced.

You must not use the \verb|throw| operator directly to throw an
exception, instead you should use the function \verb|mico_throw()|
defined in \verb|mico/throw.h|, which is automatically included by IDL
compiler generated code:

\begin{verbatim}
  // ok
  mico_throw (CORBA::UNKNOWN());

  // wrong
  throw CORBA::UNKNOWN();
\end{verbatim}

\noindent
will throw the CORBA system exception \verb|UNKNOWN|. User defined exceptions
are thrown the same way.

Exceptions are always caught by reference using the \verb|_var| types.
System exceptions must be caught by \verb|SystemException_var|:

\footnotesize
\begin{verbatim}
  // ok
  try {
    ...
    mico_throw (CORBA::UNKNOWN());
    ...
  } catch (CORBA::SystemException_var &ex) {
    ...
  }

  // wrong
  try {
    ...
    mico_throw (CORBA::UNKNOWN());
    ...
  } catch (CORBA::UNKNOWN_var &ex) {
    ...
  }

  // wrong
  try {
    ...
    mico_throw (CORBA::UNKNOWN());
    ...
  } catch (CORBA::Exception_var &ex) {
    ...
  }
\end{verbatim}
\normalsize

\noindent
Sometimes it is necessary to know exactly which system exception has been
thrown:

\footnotesize
\begin{verbatim}
  // ok
  try {
    ...
    mico_throw (CORBA::UNKNOWN());
    ...
  } catch (CORBA::SystemException_var &sys_ex) {
    if (CORBA::UNKNOWN *ukn_ex = CORBA::UNKNOWN::_narrow (sys_ex)) {
      // something1
    } else {
      // something2
    }
  }

  // wrong
  try {
    ...
  } catch (CORBA::UNKNOWN_var &ukn_ex) {
    // something1
  } catch (CORBA::SystemException_var &other_ex) {
    // something2
  }
\end{verbatim}
\normalsize

\noindent
In contrast to system exceptions a user exception \verb|X| must be caught by
\verb|X_var| (i.e., not by \verb|UserException_var|):

\footnotesize
\begin{verbatim}
  // ok
  try {
    ...
    mico_throw (SomeExcept());
    ...
  } catch (SomeExcept_var &some_ex) {
    ...
  }

  // wrong
  try {
    ...
    mico_throw (SomeExcept());
    ...
  } catch (CORBA::UserException_var &usr_ex) {
    ...
  }

  // wrong
  try {
    ...
    mico_throw (SomeExcept());
    ...
  } catch (CORBA::Exception_var &ex) {
    ...
  }
\end{verbatim}
\normalsize

\noindent
It is possible to write code that works both with CORBA compliant
exception handling and MICO specific exception handling. For this
one should follow the instructions in this section but replace
\verb|_var| by \verb|_catch|. In \MICO\/ specific exception handling
mode \verb|X_catch| is typedef'ed to \verb|X_var|, in CORBA compliant
exception handling mode \verb|X_catch| is typedef'ed to \verb|X|.
Furthermore each exception \verb|X| provides an overloaded \verb|->|
operator so that you can use \verb|->| to access the exception members
in the catch body independent of the exception handling mode. Here
is an example:

\footnotesize
\begin{verbatim}
  // throw
  mico_throw (CORBA::UNKNOWN());

  // catch
  try {
    ...
  } catch (CORBA::SystemException_catch &ex) {
    cout << ex->minor() << endl;
  }
\end{verbatim}
\normalsize

\noindent
If an exception is thrown but not caught \MICO\/ will print out a short
description of the exception and terminate the process.

\subsection{No Exception handling}

Some C++ compilers do not properly support exceptions in shared
libraries, others do not support exceptions at all. In these cases
exception handling is not available in shared libraries or not
available at all, respectively.

Exception handling related C++ keywords (\texttt{try}, \texttt{throw},
\texttt{catch}) cannot be used in this mode. \verb|mico_throw()| can
be used but will only print out a short description of the passed
exception and terminate the process.

%-------------------------------------------------------------------------
\chapter{Time Service}

This is a short description off the OMG Time Service and its implementation.
The Time Service specification contains two parts, the basic Time
Service and the Time Event Service. The former is described here and
already implemented. The later offers services for a create an event a
certain time and is not implemented so far.

There are three interfaces specified in the basic Time Service:
\texttt{TimeService}, \texttt{UTO} and \texttt{TIO}. The interface
\texttt{TimeService} works as factory object to create the objects
representation time (UTO) and intervals (TIO). 



\section{Types}

Time is represented in an integer with steps of 100 nanosecond each. The
time base is not the *NIX epoch but the 15th. of October 1582 00:00:00
o'clock. This was choosen because it was already in use with the X/Open DCE
Time Service. Unlike the *NIX epoch the approximate range is 30,000 years,
so there will be no problem in 2038 A.D.

There is a convenience procedure \texttt{timeT2epoch} to create a *NIX
time\_t from a TimeBase::TimeT variable.

The types used to transport time and intervall are declared in the namespace
\texttt{TimeBase}, they are described here:

\begin{itemize}
  \item {\ttfamily typedef unsigned long long TimeT}\\ Time in steps off 100 nano seconds 
  \item {\ttfamily typedef TimeT InaccuracyT}\\ estimated inaccuracy of time source  
  \item {\ttfamily typedef short TdfT}\\ timezone as displacement in minutes from Greenwich  
  \item {\ttfamily struct UtcT}\\ contains time, inaccuracy and timezone. Due to historical reasons,
    inaccuracy is storedin splitted over two unsigned long variables
    \texttt{inacclo} and \texttt{inacchi} storing lower and higher bits of
    InaccurcyT.
  \item {\ttfamily struct IntervaT}\\ contains \texttt{lower\_bound} and
    \texttt{upper\_bound} as TimeT two represent an intervall
  \item {\ttfamily enum TimeComparison}\\ types to be used as result of a comparison, see
    figure \ref{fig:TimeComparison}
  \item {\ttfamily enum ComparisonT}\\ types to describe, wether a comparison should use
    the inaccuracy around a time (\texttt{IntervalC}) or not (\texttt{MidC})
\end{itemize}


\begin{figure}
\begin{center}
\ \psfig{file=overlap.eps}    
\end{center}
\caption{Results comparing two intervalls}
\label{fig:TimeComparison}
\end{figure}




\section{Interface TimeService}

The TimeService is the factory object for TIOs and UTOs. The actual time
from the system is used, so the accuracy of the service is based on your
systems clock. Use a precision source like a DCF77 receiver if you have high
demand on precision. The actual routines to get the time from the system are
containe in \texttt{TimeService\_help.cc}, so you may easily use a better
way than depending on $<$time.h$>$. 

\begin{itemize}


\item \texttt{UTO universal\_time();}\\
returns the actual time of the TimeServic in a UTO

\item \texttt{UTO secure\_universal\_time();}\\
same as above, additional restrictions, see Appendix A of the specs,
currently disabled on compile time

\item \texttt{ UTO new\_universal\_time(inTimeBase::TimeT, \newline
  in TimeBase::InaccuracyT, in TimeBase::TdfT);}\\
creates a new UTO filled with the arguments

\item \texttt{  UTO utop\_from\_utc(in TimeBase::UtcT);}\\
 same as above, but with UtcT as argument
 
\item \texttt{  TIO new\_intervall(in TimeBase::TimeT, \newline in TimeBase::TimeT);}\\
 creates a new TIO with lower and upper set from arguments

\end{itemize}


If you provide a hint to a MICO naming service when starting the service,
the time service exports its reference. Otherwise you may use the
stringified  object reference.


\section{Interface UTO}

This is an object containing time, inaccuracy and timezone. you may query
the variables and compare with other objects. UTOs are created by the
interface TimeService. I think the OMG specification lacks the method to
destroy an UTO, so this non standard feature was added.

\begin{itemize}
\item{\ttfamily  readonly attribute TimeBase::TimeT time;}\\
time value
\item{\ttfamily  readonly attribute TimeBase::TimeT inaccuracy;}\\
inaccuracy
\item{\ttfamily  readonly attribute TimeBase::TdfT tdf;}\\
time displacement factor.
\item{\ttfamily  readonly attribute TimeBase::UtcT utc\_time;}\\
structure including absolute time, inaccuracy and the time displacement
\item{\ttfamily   UTO absolute\_time ();}\\
return the base time to the relative time in the object.
\item{\ttfamily  TimeComparison compare\_time (\newline
    in ComparisonType comparison\_type, in UTO uto);}\\
Compares the time contained in the object with the time in
    the supplied uto according to the supplied comparison type
\item{\ttfamily  TIO time\_to\_interval (in UTO uto);}\\
 Returns a TIO representing the time interval between the time
 in the object and the time in the UTO passed as a
 parameter. The interval returned is the interval between the
 mid-points of the two UTOs. 

\item{\ttfamily  TIO interval ();}\\
 Returns a TIO object representing the error interval around
the time value in the UTO.
\item{\ttfamily  void destroy ();}\\
This is a non-standard extension of the official OMG specs, it destroys the
object to save memory
\end{itemize}




\section{TIO}


This objects represents an intervall with start and endpoint. You may query
the values and compare it with other objects. TIOs are created by the
interface TimeService. I think the OMG specification lacks the method to
destroy an TIO, so this non standard feature was added.


\begin{itemize}

\item{\ttfamily  readonly attribute \newline 
    TimeBase::IntervalT time\_interval;}\\
 Consists of a lower and an upper bound for the time interval.

\item{\ttfamily  CosTime::OverlapType spans (in UTO time, \newline out TIO overlap);}\\
 This operation compares the time in this interface with the time in the
 supplied UTO and returns the overlap type as well as the
 interval of overlap in the form of a TIO.

\item{\ttfamily  CosTime::OverlapType overlaps (in TIO interval, \newline out TIO overlap);}\\
 This operation compares the time in this interface with the time in the
 supplied TIO and returns the overlap type as well as the interval of
 overlap in the form of a TIO.

\item{\ttfamily  UTO time ();}\\
 Converts the time interval in this interface into a UTO
 object by taking the midpoint of the interval as the time and the interval
 as the error envelope around the time.

\item{\ttfamily  void destroy ();}\\
This is a non-standard extension of the official OMG specs, it destroys the
object to save memory
\end{itemize}


%-------------------------------------------------------------------------
\chapter{Java Interface}

We have implemented a generic user interface to \MICO's dynamic
invocation interface. The interface is written is Java and allows the
invocation of arbitrary operations. The specification of an operation
invocation is done with the help of a knowledge representation technique
called \emph{conceptual graphs}. This chapter gives an overview of this
interface. The outline of this chapter is as follows: in section
\ref{SEC_CG} be provide a brief introduction to the theory of conceptual
graphs. In section \ref{SEC_DII} we describe CORBAs dynamic invocation
interface and the problems related to a generic user interface which
allows run--time access to this interface. In section \ref{SEC_OP_DECL}
we present the anatomy of an operation declaration as defined by the
CORBA standard. In section \ref{SEC_GUI_FOR_DII} we finally present our
solution for a generic user interface to CORBAs dynamic invocation
interface based on an interactive conceptual graph editor. In section
\ref{SEC_DII_EXAMPLE} we finally show how to run the Java applet using
standard JDK tools in conjunction with a graphical browsing tool for
the contents of the interface repository. The work in this chapter has
been presented in \cite{puder:97a}.

%-------------------------------------------------------------------------
\section{Conceptual Graphs}
\label{SEC_CG}

The theory of \emph{conceptual graphs} (CG) has been developed to model
the semantics of natural language (see \cite{sowa:84}). Specifications
based on conceptual graphs are therefore intuitive in the sense that
there is a close relationship to the way human beings represent and
organize their knowledge. From a mathematical point of view a conceptual
graph is a finite, connected, directed, bipartite graph. The nodes of
the graph are either \emph{concept} or \emph{relation nodes}. Due to the
bipartite nature of the graphs, two concept nodes may only be connected
via a relation node.  A concept node represents either a concrete or an
abstract object in the world of discourse whereas a relation nodes
defines a context between two or more concepts.


\begin{figure}
\begin{center}
\fbox{\psfig{file=pics/sample-cg.ps,width=9cm}}\\
\caption{\label{FIG_SAMPLE_CG} A simple conceptual graph with two
  concepts and one relation.}
\end{center}
\end{figure}

A sample CG is depicted in figure \ref{FIG_SAMPLE_CG}. This CG
consists of two concepts (white nodes) and one relation (black node).
This CG expresses the fact that a printer is a hardware device. The
two concepts --- \texttt{PRINTER} and \texttt{HARDWARE-DEVICE} --- are
placed in a semantical context via the binary relation \texttt{IS-A}.  The
theory of CGs defines a mapping from conceptual graphs to first--order
calculus. This mapping, which is described in \cite{sowa:84}, would
map the CG depicted in figure \ref{FIG_SAMPLE_CG} to the first order
formula $\exists x \exists y: \mbox{\texttt{PRINTER}}(x) \land
\mbox{\texttt{HARDWARE-DEVICE}}(y) \land \mbox{\texttt{IS-A}}(x,y)$.
As can be seen, the variables $x$ and $y$ form the link between the
two concepts via the predicate \texttt{IS-A}.

Given a conceptual and relational catalogue, one can express arbitrary
knowledge. For this reason the theory of CG represents a
\emph{knowledge representation technique}. The work done in
\cite{sowa:84} focuses on the representation of natural language. We
have shown, that with a suitable conceptual and relational catalogue
one can translate operational interface specifications to conceptual
graphs (see \cite{aitrader}).  We have written translators which
translate arbitrary DCE and CORBA--IDL specifications to CGs. Thus we
have already demonstrated that an implementation of an interface
repository, which is based on such a meta--notation, can be used in
different middleware platforms. In the following we show how a
meta--notation can also be exploited for the construction of a generic
user interface to CORBAs \emph{dynamic invocation interface} (DII).

%-------------------------------------------------------------------------
\section{Dynamic Invocation Interface}
\label{SEC_DII}

In this section we present a description for CORBAs DII. For the
following discussions we refer to the interface \texttt{Account} as
specified in section \ref{SEC_MICO_APP}.  A client application written in
C++ might for example use this interface in the following way:

\footnotesize
\begin{verbatim}
  Account_ptr acc = ...;  // Obtain a reference to an Account-object

  acc->deposit( 100 );
  acc->withdraw( 20 );

  cout << "Total balance is " << acc->balance() << endl;
\end{verbatim}
\normalsize

If we assume that the current balance of the server object was $0$
when the variable \texttt{acc} was bound with a refence to this
object, then this program fragment prints out \emph{``Total balance is
  80''}.  It should be clear that this program fragment requires the
definition of the class \texttt{Account\_ptr}. This class, which
allows a type safe access to a CORBA object implementing the interface
\texttt{Account}, is generated using an IDL compiler. Thus the type of
the operational interface of the server object is known at compile
time. But what if we did not know about the interface \texttt{Account}
at compile--time? The only possible way to access the object in this
case is to use CORBA's \emph{dynamic invocation interface} (DII). This
interface to an ORB offers the possibility to invoke operation calls
whose signature was not known at compile time. The following code
excerpt shows the usage of the DII:

\footnotesize
\begin{verbatim}
    CORBA::Object_ptr obj = ...;
    CORBA::Request_ptr req = obj->_request( "deposit" );
    req->add_in_arg( "amount" ) <<= (CORBA::ULong) 100;
    req->invoke();
\end{verbatim}
\normalsize

Note that the variable \texttt{obj} is of type \texttt{Object\_ptr}
and not \texttt{Account\_ptr}. The code fragment demonstrates how to
model the operation call \verb|acc->deposit( 100 )| from the code
fragment above. It does not require the \texttt{Account\_ptr} client
stub as in the last example. Despite the generic manner how the
operation is invoked, the problem remains how to write a generic user
interface to access CORBAs DII. Such an interface would allow a user
to invoke arbitrary operations of \emph{a priori} unknown interfaces.
The next section gives a brief overview of the specific details of an
operation invocation.

%-------------------------------------------------------------------------
\section{Anatomy of an operation declaration}
\label{SEC_OP_DECL}


The CORBA specification describes the syntax of an \emph{operation
  declaration} (see \cite{corba}). The syntax is part of the Interface
Definition Language (IDL). The grammar presented in that section
describes the syntax which induces a formal language. In figure
\ref{FIG_OP_DECL} the anatomy of an operation declaration is given,
using a graphical representation of the grammar where the arrows
denote ``consists of'' relations. Thus, according to the CORBA
standard, an operation declaration consists of a result type, an
ordered list of parameters and so on. A parameter declaration itself
consists of a directional attribute (\texttt{in}, \texttt{out} or
\texttt{inout}), a parameter type and an identifier.

Note that the ``graph'' depicted in figure \ref{FIG_OP_DECL} already
has some resemblance to a conceptual graph. We propose to model the
information pertinent to an operation invocation through a CG. The
anatomy of an operation declaration as depicted in figure
\ref{FIG_OP_DECL} provides a hint on how to accomplish this task.


\begin{figure}
\begin{center}
\mbox{\psfig{file=pics/op-decl.eps,width=7.5cm}}
\end{center}
\caption{\label{FIG_OP_DECL} Syntax of an operation declaration.}
\end{figure}



%-------------------------------------------------------------------------
\section{A generic DII interface}
\label{SEC_GUI_FOR_DII}

Just consider if we had an application which allowed the browsing of an
interface repository. A user would find a suitable interface at
\emph{run--time} and decide to invoke operations without having to write
a specific client object. What would be nice to have is a \emph{generic
  client} which could cope with \emph{a priori} unknown operational
interfaces.  As we have seen in figure \ref{FIG_OP_DECL} and from the
discussion of the previous section, an \emph{operation invocation}
consists of the following elements:

\begin{itemize}
\item a name of the operation
\item a return type
\item an ordered list of actual parameters
\end{itemize}

With this ``anatomy'' of an operation invocation we can assemble a
domain--specific conceptual and relational catalogue. We have developed
such a catalogue which provides the ``vocabulary'' to express the
information needed for the specification of an operation invocation.
The conceptual graph depicted in figure \ref{FIG_OP_DEPOSIT} shows how
to translate the operation invocation for {\tt deposit( 100 )} using the
DII (again concept nodes are denoted by white rectangles and relation
nodes by black rectangles).  As can be seen, a meta--notation based on
CG provides an easy readable, formal specification of an operation
invocation. It should be clear that the CG template can be extended
arbitrarily to cover the specifics of the CORBA--IDL like complex type
definitions or sequences of arbitrary types.


\begin{figure}
\begin{center}
\fbox{\psfig{file=pics/op-deposit.ps,width=12cm}}\\
\caption{\label{FIG_OP_DEPOSIT} Conceptual graph
    representing the specification of the operation {\tt deposit()}.}
\end{center}
\end{figure}



%-------------------------------------------------------------------------
\section{Running the example}
\label{SEC_DII_EXAMPLE}

The \MICO\ sources include an interactive conceptual graph editor
written in Java. The sources of the example are located in the
directory \texttt{mico/tools/ir-browser}. Note that you need the Java
Developers Kit 1.1.5 as well as a parser generator for Java called
JavaCUP (see chapter \ref{SEC_INSTALLATION} on where to obtain these
tools). We assume that you have succefully compiled the \MICO\ sources
contained in the aforementioned directory. Alternatively you can run
the Java applet from your favorite WWW browser by visiting the
\MICO--homepage.

\noindent
Two files in the \texttt{ir-browser} directory are of importance to
run the example:

\begin{itemize}
\item \texttt{runproxy}: this shell script starts \texttt{diiproxy} and the
  interface repository. The IR server is then feed with some IDL's
  so you have something to browse.
\item \texttt{dii.html}: a HTML page which makes reference to the main
  Java--class \texttt{DII} implementing the interactive interface
  repository browser.
\end{itemize}

In order to run the demonstration, you first have to run the shell
script \texttt{runproxy}. You simply do this by starting it from an
UNIX shell:

\small
\begin{verbatim}
  ./runproxy
\end{verbatim}
\normalsize

After this you can load the applet by either using a Java capable
browser or the appletviewer tool which is part of the JDK. You can
run the applet be running the following command from an UNIX shell:

\small
\begin{verbatim}
  appletviewer dii.html
\end{verbatim}
\normalsize

Once the applet has been loaded, click on the button called \emph{Start
  IR browser}. A new window opens. The right side of this window shows
all top--level objects contained in the interface repository. For each
object there is one icon. If you click on one of these icons using
the left mouse button, the IDL source code of that object is shown in
the left side of the window. You can ``enter'' an object using the
right mouse button (this of course works only on container objects
like interfaces or modules). If you press the right mouse button on an
operation object, another window will open containing a conceptual
graph representing this operation. You can change the input parameters
of that CG before invoking it on an object.

Here is a short step--by--step tour:

\begin{enumerate}
\item click with the left mouse button on the \emph{Account} icon
\item click with the right mouse button on the \emph{Account} icon
\item click on the \emph{deposit} icon with the right mouse button
      to invoke the \texttt{deposit()} method
\item click on the \texttt{ULONG:0} node while holding down the shift key,
      enter 100 into the appearing entry box and press return
\item use \emph{Server/Invoke} to do the actual invocation
\item click on the \emph{withdraw} icon with the right mouse button
      in the browser window to invoke the \texttt{withdraw()} method
\item click on the \texttt{ULONG:0} node while holding down the shift key,
      enter 20 into the appearing entry box and press return
\item use \emph{Server/Invoke} to do the actual invocation
\item click on the \emph{withdraw} icon with the right mouse button
      in the browser window to invoke the \texttt{withdraw()} method
\item use \emph{Server/Invoke} to do the actual invocation
\item the rightmost node of the graph should change to
       \texttt{LONG:80}
\end{enumerate}


HINT: If you move the pointer over a node of the graph the status line
will show you the actions possible on this node. For example
\emph{Shift--Button1: edit} means: To edit the contents of the node
press the left mouse button while holding down the SHIFT key.


%-------------------------------------------------------------------------
\section{Using the CG--editor}

The CG--editor allows the insertion, editing and removal of nodes. The
editor supports the following actions on conceptual graph nodes:

\begin{description}
\item[left mouse button]
  ~\newline
  If the working area was empty before this will insert a new root node,
  otherwise if you click on a node you can drag it around.
\item[shift + left mouse button]
  ~\newline
  Edit the contents of conceptual graph node currently pointed at.
\item[control + shift + left mouse button]
  ~\newline
  Remove the node (and all its descendents) currently pointed at.
\item[right mouse button]
  ~\newline
  Bring up a context sensitive popup menu. Selecting an entry from it
  will add a corresponding subtree to the node currently pointed at.
\end{description}

\noindent
Not all of the above functions work on all conceptual graph nodes. If
you move the pointer over a node, the status line will show you the
actions which are possible for that node.

The order of the child nodes of a conceptual graph node is determined by
their Y--positions. The first child node is the one with the smallest
Y--position (with Y--position increasing from top to bottom). So if you
want to swap nodes A and B, just move A below B (if A was above B
before).

The \emph{Edit} menu offers you some functions which come in handy:
\emph{New graph} will delete the current graph, \emph{Arrange graph}
will layout the nodes of the graph currently being edited and
\emph{Linear from...} will show you the textual representation of the
conceptual graph.


%-------------------------------------------------------------------------
\chapter{LICENSE}
\label{SEC_GNU_LICENSE}

This chapter contains the license conditions for \MICO. All libraries
are covered by the GNU Library General Public License (LGPL)
version 2 or later, code generated by the IDL compiler is not copyrighted,
everything else is covered by the GNU General
Public License (GPL) version 2 or later.

The idea behind this is that MICO can be used for developing
commercial applications without requiring the manufacturer of the
commercial application to put the application under (L)GPL.
On the other hand it is not possible to derive commercial applications
from MICO without putting that application under (L)GPL.

Section \ref{SEC_LGPL} contains terms and conditions of the LGPL, section
\ref{SEC_GPL} contains terms and conditions of the GPL.

%-------------------------------------------------------------------------
\section{GNU Library General Public License}
\label{SEC_LGPL}

\begin{center}
   TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION
\end{center}

\begin{description}
\item[0.] This License Agreement applies to any software library which
contains a notice placed by the copyright holder or other authorized
party saying it may be distributed under the terms of this Library
General Public License (also called ``this License'').  Each licensee is
addressed as ``you''.

  A ``library'' means a collection of software functions and/or data
prepared so as to be conveniently linked with application programs
(which use some of those functions and data) to form executables.

  The ``Library'', below, refers to any such software library or work
which has been distributed under these terms.  A ``work based on the
Library'' means either the Library or any derivative work under
copyright law: that is to say, a work containing the Library or a
portion of it, either verbatim or with modifications and/or translated
straightforwardly into another language.  (Hereinafter, translation is
included without limitation in the term ``modification''.)

  ``Source code'' for a work means the preferred form of the work for
making modifications to it.  For a library, complete source code means
all the source code for all modules it contains, plus any associated
interface definition files, plus the scripts used to control compilation
and installation of the library.

  Activities other than copying, distribution and modification are not
covered by this License; they are outside its scope.  The act of
running a program using the Library is not restricted, and output from
such a program is covered only if its contents constitute a work based
on the Library (independent of the use of the Library in a tool for
writing it).  Whether that is true depends on what the Library does
and what the program that uses the Library does.
  
\item[1.] You may copy and distribute verbatim copies of the Library's
complete source code as you receive it, in any medium, provided that
you conspicuously and appropriately publish on each copy an
appropriate copyright notice and disclaimer of warranty; keep intact
all the notices that refer to this License and to the absence of any
warranty; and distribute a copy of this License along with the
Library.

  You may charge a fee for the physical act of transferring a copy,
and you may at your option offer warranty protection in exchange for a
fee.

\item[2.] You may modify your copy or copies of the Library or any portion
of it, thus forming a work based on the Library, and copy and
distribute such modifications or work under the terms of Section 1
above, provided that you also meet all of these conditions:

    \begin{description}
    \item[a)] The modified work must itself be a software library.

    \item[b)] You must cause the files modified to carry prominent notices
    stating that you changed the files and the date of any change.

    \item[c)] You must cause the whole of the work to be licensed at no
    charge to all third parties under the terms of this License.

    \item[d)] If a facility in the modified Library refers to a function or a
    table of data to be supplied by an application program that uses
    the facility, other than as an argument passed when the facility
    is invoked, then you must make a good faith effort to ensure that,
    in the event an application does not supply such function or
    table, the facility still operates, and performs whatever part of
    its purpose remains meaningful.

    (For example, a function in a library to compute square roots has
    a purpose that is entirely well--defined independent of the
    application.  Therefore, Subsection 2d requires that any
    application--supplied function or table used by this function must
    be optional: if the application does not supply it, the square
    root function must still compute square roots.)
    \end{description}

These requirements apply to the modified work as a whole.  If
identifiable sections of that work are not derived from the Library,
and can be reasonably considered independent and separate works in
themselves, then this License, and its terms, do not apply to those
sections when you distribute them as separate works.  But when you
distribute the same sections as part of a whole which is a work based
on the Library, the distribution of the whole must be on the terms of
this License, whose permissions for other licensees extend to the
entire whole, and thus to each and every part regardless of who wrote
it.

Thus, it is not the intent of this section to claim rights or contest
your rights to work written entirely by you; rather, the intent is to
exercise the right to control the distribution of derivative or
collective works based on the Library.

In addition, mere aggregation of another work not based on the Library
with the Library (or with a work based on the Library) on a volume of
a storage or distribution medium does not bring the other work under
the scope of this License.

\item[3.] You may opt to apply the terms of the ordinary GNU General Public
License instead of this License to a given copy of the Library.  To do
this, you must alter all the notices that refer to this License, so
that they refer to the ordinary GNU General Public License, version 2,
instead of to this License.  (If a newer version than version 2 of the
ordinary GNU General Public License has appeared, then you can specify
that version instead if you wish.)  Do not make any other change in
these notices.

  Once this change is made in a given copy, it is irreversible for
that copy, so the ordinary GNU General Public License applies to all
subsequent copies and derivative works made from that copy.

  This option is useful when you wish to copy part of the code of
the Library into a program that is not a library.

\item[4.] You may copy and distribute the Library (or a portion or
derivative of it, under Section 2) in object code or executable form
under the terms of Sections 1 and 2 above provided that you accompany
it with the complete corresponding machine--readable source code, which
must be distributed under the terms of Sections 1 and 2 above on a
medium customarily used for software interchange.

  If distribution of object code is made by offering access to copy
from a designated place, then offering equivalent access to copy the
source code from the same place satisfies the requirement to
distribute the source code, even though third parties are not
compelled to copy the source along with the object code.

\item[5.] A program that contains no derivative of any portion of the
Library, but is designed to work with the Library by being compiled or
linked with it, is called a ``work that uses the Library''.  Such a
work, in isolation, is not a derivative work of the Library, and
therefore falls outside the scope of this License.

  However, linking a ``work that uses the Library'' with the Library
creates an executable that is a derivative of the Library (because it
contains portions of the Library), rather than a ``work that uses the
library''.  The executable is therefore covered by this License.
Section 6 states terms for distribution of such executables.

  When a ``work that uses the Library'' uses material from a header file
that is part of the Library, the object code for the work may be a
derivative work of the Library even though the source code is not.
Whether this is true is especially significant if the work can be
linked without the Library, or if the work is itself a library.  The
threshold for this to be true is not precisely defined by law.

  If such an object file uses only numerical parameters, data
structure layouts and accessors, and small macros and small inline
functions (ten lines or less in length), then the use of the object
file is unrestricted, regardless of whether it is legally a derivative
work.  (Executables containing this object code plus portions of the
Library will still fall under Section 6.)

  Otherwise, if the work is a derivative of the Library, you may
distribute the object code for the work under the terms of Section 6.
Any executables containing that work also fall under Section 6,
whether or not they are linked directly with the Library itself.

\item[6.] As an exception to the Sections above, you may also compile or
link a ``work that uses the Library'' with the Library to produce a
work containing portions of the Library, and distribute that work
under terms of your choice, provided that the terms permit
modification of the work for the customer's own use and reverse
engineering for debugging such modifications.

  You must give prominent notice with each copy of the work that the
Library is used in it and that the Library and its use are covered by
this License.  You must supply a copy of this License.  If the work
during execution displays copyright notices, you must include the
copyright notice for the Library among them, as well as a reference
directing the user to the copy of this License.  Also, you must do one
of these things:

    \begin{description}
    \item[a)] Accompany the work with the complete corresponding
    machine--readable source code for the Library including whatever
    changes were used in the work (which must be distributed under
    Sections 1 and 2 above); and, if the work is an executable linked
    with the Library, with the complete machine--readable ``work that
    uses the Library'', as object code and/or source code, so that the
    user can modify the Library and then relink to produce a modified
    executable containing the modified Library.  (It is understood
    that the user who changes the contents of definitions files in the
    Library will not necessarily be able to recompile the application
    to use the modified definitions.)

    \item[b)] Accompany the work with a written offer, valid for at
    least three years, to give the same user the materials
    specified in Subsection 6a, above, for a charge no more
    than the cost of performing this distribution.

    \item[c)] If distribution of the work is made by offering access to copy
    from a designated place, offer equivalent access to copy the above
    specified materials from the same place.

    \item[d)] Verify that the user has already received a copy of these
    materials or that you have already sent this user a copy.
    \end{description}

  For an executable, the required form of the ``work that uses the
Library'' must include any data and utility programs needed for
reproducing the executable from it.  However, as a special exception,
the source code distributed need not include anything that is normally
distributed (in either source or binary form) with the major
components (compiler, kernel, and so on) of the operating system on
which the executable runs, unless that component itself accompanies
the executable.

  It may happen that this requirement contradicts the license
restrictions of other proprietary libraries that do not normally
accompany the operating system.  Such a contradiction means you cannot
use both them and the Library together in an executable that you
distribute.

\item[7.] You may place library facilities that are a work based on the
Library side--by--side in a single library together with other library
facilities not covered by this License, and distribute such a combined
library, provided that the separate distribution of the work based on
the Library and of the other library facilities is otherwise
permitted, and provided that you do these two things:

    \begin{description}
    \item[a)] Accompany the combined library with a copy of the same work
    based on the Library, uncombined with any other library
    facilities.  This must be distributed under the terms of the
    Sections above.

    \item[b)] Give prominent notice with the combined library of the fact
    that part of it is a work based on the Library, and explaining
    where to find the accompanying uncombined form of the same work.
    \end{description}

\item[8.] You may not copy, modify, sublicense, link with, or distribute
the Library except as expressly provided under this License.  Any
attempt otherwise to copy, modify, sublicense, link with, or
distribute the Library is void, and will automatically terminate your
rights under this License.  However, parties who have received copies,
or rights, from you under this License will not have their licenses
terminated so long as such parties remain in full compliance.

\item[9.] You are not required to accept this License, since you have not
signed it.  However, nothing else grants you permission to modify or
distribute the Library or its derivative works.  These actions are
prohibited by law if you do not accept this License.  Therefore, by
modifying or distributing the Library (or any work based on the
Library), you indicate your acceptance of this License to do so, and
all its terms and conditions for copying, distributing or modifying
the Library or works based on it.

\item[10.] Each time you redistribute the Library (or any work based on the
Library), the recipient automatically receives a license from the
original licensor to copy, distribute, link with or modify the Library
subject to these terms and conditions.  You may not impose any further
restrictions on the recipients' exercise of the rights granted herein.
You are not responsible for enforcing compliance by third parties to
this License.

\item[11.] If, as a consequence of a court judgment or allegation of patent
infringement or for any other reason (not limited to patent issues),
conditions are imposed on you (whether by court order, agreement or
otherwise) that contradict the conditions of this License, they do not
excuse you from the conditions of this License.  If you cannot
distribute so as to satisfy simultaneously your obligations under this
License and any other pertinent obligations, then as a consequence you
may not distribute the Library at all.  For example, if a patent
license would not permit royalty--free redistribution of the Library by
all those who receive copies directly or indirectly through you, then
the only way you could satisfy both it and this License would be to
refrain entirely from distribution of the Library.

If any portion of this section is held invalid or unenforceable under any
particular circumstance, the balance of the section is intended to apply,
and the section as a whole is intended to apply in other circumstances.

It is not the purpose of this section to induce you to infringe any
patents or other property right claims or to contest validity of any
such claims; this section has the sole purpose of protecting the
integrity of the free software distribution system which is
implemented by public license practices.  Many people have made
generous contributions to the wide range of software distributed
through that system in reliance on consistent application of that
system; it is up to the author/donor to decide if he or she is willing
to distribute software through any other system and a licensee cannot
impose that choice.

This section is intended to make thoroughly clear what is believed to
be a consequence of the rest of this License.

\item[12.] If the distribution and/or use of the Library is restricted in
certain countries either by patents or by copyrighted interfaces, the
original copyright holder who places the Library under this License may add
an explicit geographical distribution limitation excluding those countries,
so that distribution is permitted only in or among countries not thus
excluded.  In such case, this License incorporates the limitation as if
written in the body of this License.

\item[13.] The Free Software Foundation may publish revised and/or new
versions of the Library General Public License from time to time.
Such new versions will be similar in spirit to the present version,
but may differ in detail to address new problems or concerns.

Each version is given a distinguishing version number.  If the Library
specifies a version number of this License which applies to it and
``any later version'', you have the option of following the terms and
conditions either of that version or of any later version published by
the Free Software Foundation.  If the Library does not specify a
license version number, you may choose any version ever published by
the Free Software Foundation.

\item[14.] If you wish to incorporate parts of the Library into other free
programs whose distribution conditions are incompatible with these,
write to the author to ask for permission.  For software which is
copyrighted by the Free Software Foundation, write to the Free
Software Foundation; we sometimes make exceptions for this.  Our
decision will be guided by the two goals of preserving the free status
of all derivatives of our free software and of promoting the sharing
and reuse of software generally.

\begin{center}
                            NO WARRANTY
\end{center}

\item[15.] BECAUSE THE LIBRARY IS LICENSED FREE OF CHARGE, THERE IS NO
WARRANTY FOR THE LIBRARY, TO THE EXTENT PERMITTED BY APPLICABLE LAW.
EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR
OTHER PARTIES PROVIDE THE LIBRARY ``AS IS'' WITHOUT WARRANTY OF ANY
KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE
IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
PURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE
LIBRARY IS WITH YOU.  SHOULD THE LIBRARY PROVE DEFECTIVE, YOU ASSUME
THE COST OF ALL NECESSARY SERVICING, REPAIR OR CORRECTION.

\item[16.] IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN
WRITING WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MAY MODIFY
AND/OR REDISTRIBUTE THE LIBRARY AS PERMITTED ABOVE, BE LIABLE TO YOU
FOR DAMAGES, INCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR
CONSEQUENTIAL DAMAGES ARISING OUT OF THE USE OR INABILITY TO USE THE
LIBRARY (INCLUDING BUT NOT LIMITED TO LOSS OF DATA OR DATA BEING
RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD PARTIES OR A
FAILURE OF THE LIBRARY TO OPERATE WITH ANY OTHER SOFTWARE), EVEN IF
SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH
DAMAGES.

\begin{center}
                     END OF TERMS AND CONDITIONS
\end{center}

\end{description}


%-------------------------------------------------------------------------
\section{GNU General Public License}
\label{SEC_GPL}

\begin{center}
   TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION
\end{center}

\begin{description}
\item[0.] This License applies to any program or other work which
  contains a notice placed by the copyright holder saying it may be
  distributed under the terms of this General Public License.  The
  ``Program'', below, refers to any such program or work, and a ``work
  based on the Program'' means either the Program or any derivative work
  under copyright law: that is to say, a work containing the Program or
  a portion of it, either verbatim or with modifications and/or
  translated into another language.  (Hereinafter, translation is
  included without limitation in the term ``modification''.)  Each
  licensee is addressed as ``you''.

  Activities other than copying, distribution and modification are not
  covered by this License; they are outside its scope.  The act of
  running the Program is not restricted, and the output from the Program
  is covered only if its contents constitute a work based on the Program
  (independent of having been made by running the Program).  Whether
  that is true depends on what the Program does.

\item[1.] You may copy and distribute verbatim copies of the Program's
  source code as you receive it, in any medium, provided that you
  conspicuously and appropriately publish on each copy an appropriate
  copyright notice and disclaimer of warranty; keep intact all the
  notices that refer to this License and to the absence of any warranty;
  and give any other recipients of the Program a copy of this License
  along with the Program.

  You may charge a fee for the physical act of transferring a copy, and
  you may at your option offer warranty protection in exchange for a
  fee.

\item[2.] You may modify your copy or copies of the Program or any
  portion of it, thus forming a work based on the Program, and copy and
  distribute such modifications or work under the terms of Section 1
  above, provided that you also meet all of these conditions:

  \begin{description}
  \item[a)] You must cause the modified files to carry prominent notices
    stating that you changed the files and the date of any change.

  \item[b)] You must cause any work that you distribute or publish, that
    in whole or in part contains or is derived from the Program or any
    part thereof, to be licensed as a whole at no charge to all third
    parties under the terms of this License.

  \item[c)] If the modified program normally reads commands
    interactively when run, you must cause it, when started running for
    such interactive use in the most ordinary way, to print or display
    an announcement including an appropriate copyright notice and a
    notice that there is no warranty (or else, saying that you provide a
    warranty) and that users may redistribute the program under these
    conditions, and telling the user how to view a copy of this License.
    (Exception: if the Program itself is interactive but does not
    normally print such an announcement, your work based on the Program
    is not required to print an announcement.)
  \end{description}

  These requirements apply to the modified work as a whole.  If
  identifiable sections of that work are not derived from the Program,
  and can be reasonably considered independent and separate works in
  themselves, then this License, and its terms, do not apply to those
  sections when you distribute them as separate works.  But when you
  distribute the same sections as part of a whole which is a work based
  on the Program, the distribution of the whole must be on the terms of
  this License, whose permissions for other licensees extend to the
  entire whole, and thus to each and every part regardless of who wrote
  it.

  Thus, it is not the intent of this section to claim rights or contest
  your rights to work written entirely by you; rather, the intent is to
  exercise the right to control the distribution of derivative or
  collective works based on the Program.

  In addition, mere aggregation of another work not based on the Program
  with the Program (or with a work based on the Program) on a volume of
  a storage or distribution medium does not bring the other work under
  the scope of this License.

\item[3.] You may copy and distribute the Program (or a work based on
  it, under Section 2) in object code or executable form under the terms
  of Sections 1 and 2 above provided that you also do one of the
  following:

  \begin{description}
  \item[a)] Accompany it with the complete corresponding
    machine--readable source code, which must be distributed under the
    terms of Sections 1 and 2 above on a medium customarily used for
    software interchange; or,

  \item[b)] Accompany it with a written offer, valid for at least three
    years, to give any third party, for a charge no more than your cost
    of physically performing source distribution, a complete
    machine--readable copy of the corresponding source code, to be
    distributed under the terms of Sections 1 and 2 above on a medium
    customarily used for software interchange; or,

  \item[c)] Accompany it with the information you received as to the
    offer to distribute corresponding source code.  (This alternative is
    allowed only for noncommercial distribution and only if you received
    the program in object code or executable form with such an offer, in
    accord with Subsection b above.)
  \end{description}

  The source code for a work means the preferred form of the work for
  making modifications to it.  For an executable work, complete source
  code means all the source code for all modules it contains, plus any
  associated interface definition files, plus the scripts used to
  control compilation and installation of the executable.  However, as a
  special exception, the source code distributed need not include
  anything that is normally distributed (in either source or binary
  form) with the major components (compiler, kernel, and so on) of the
  operating system on which the executable runs, unless that component
  itself accompanies the executable.

  If distribution of executable or object code is made by offering
  access to copy from a designated place, then offering equivalent
  access to copy the source code from the same place counts as
  distribution of the source code, even though third parties are not
  compelled to copy the source along with the object code.

\item[4.] You may not copy, modify, sublicense, or distribute the
  Program except as expressly provided under this License.  Any attempt
  otherwise to copy, modify, sublicense or distribute the Program is
  void, and will automatically terminate your rights under this License.
  However, parties who have received copies, or rights, from you under
  this License will not have their licenses terminated so long as such
  parties remain in full compliance.

\item[5.] You are not required to accept this License, since you have
  not signed it.  However, nothing else grants you permission to modify
  or distribute the Program or its derivative works.  These actions are
  prohibited by law if you do not accept this License.  Therefore, by
  modifying or distributing the Program (or any work based on the
  Program), you indicate your acceptance of this License to do so, and
  all its terms and conditions for copying, distributing or modifying
  the Program or works based on it.

\item[6.] Each time you redistribute the Program (or any work based on
  the Program), the recipient automatically receives a license from the
  original licensor to copy, distribute or modify the Program subject to
  these terms and conditions.  You may not impose any further
  restrictions on the recipients' exercise of the rights granted herein.
  You are not responsible for enforcing compliance by third parties to
  this License.

\item[7.] If, as a consequence of a court judgment or allegation of
  patent infringement or for any other reason (not limited to patent
  issues), conditions are imposed on you (whether by court order,
  agreement or otherwise) that contradict the conditions of this
  License, they do not excuse you from the conditions of this License.
  If you cannot distribute so as to satisfy simultaneously your
  obligations under this License and any other pertinent obligations,
  then as a consequence you may not distribute the Program at all.  For
  example, if a patent license would not permit royalty--free
  redistribution of the Program by all those who receive copies directly
  or indirectly through you, then the only way you could satisfy both it
  and this License would be to refrain entirely from distribution of the
  Program.

  If any portion of this section is held invalid or unenforceable under
  any particular circumstance, the balance of the section is intended to
  apply and the section as a whole is intended to apply in other
  circumstances.

  It is not the purpose of this section to induce you to infringe any
  patents or other property right claims or to contest validity of any
  such claims; this section has the sole purpose of protecting the
  integrity of the free software distribution system, which is
  implemented by public license practices.  Many people have made
  generous contributions to the wide range of software distributed
  through that system in reliance on consistent application of that
  system; it is up to the author/donor to decide if he or she is willing
  to distribute software through any other system and a licensee cannot
  impose that choice.

  This section is intended to make thoroughly clear what is believed to
  be a consequence of the rest of this License.

\item[8.] If the distribution and/or use of the Program is restricted in
  certain countries either by patents or by copyrighted interfaces, the
  original copyright holder who places the Program under this License
  may add an explicit geographical distribution limitation excluding
  those countries, so that distribution is permitted only in or among
  countries not thus excluded.  In such case, this License incorporates
  the limitation as if written in the body of this License.

\item[9.] The Free Software Foundation may publish revised and/or new
  versions of the General Public License from time to time.  Such new
  versions will be similar in spirit to the present version, but may
  differ in detail to address new problems or concerns.

  Each version is given a distinguishing version number.  If the Program
  specifies a version number of this License which applies to it and
  ``any later version'', you have the option of following the terms and
  conditions either of that version or of any later version published by
  the Free Software Foundation.  If the Program does not specify a
  version number of this License, you may choose any version ever
  published by the Free Software Foundation.

\item[10.] If you wish to incorporate parts of the Program into other
  free programs whose distribution conditions are different, write to
  the author to ask for permission.  For software which is copyrighted
  by the Free Software Foundation, write to the Free Software
  Foundation; we sometimes make exceptions for this.  Our decision will
  be guided by the two goals of preserving the free status of all
  derivatives of our free software and of promoting the sharing and
  reuse of software generally.

\begin{center}
                            NO WARRANTY
\end{center}

\item[11.] BECAUSE THE PROGRAM IS LICENSED FREE OF CHARGE, THERE IS NO
  WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY APPLICABLE LAW.
  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR
  OTHER PARTIES PROVIDE THE PROGRAM ``AS IS'' WITHOUT WARRANTY OF ANY
  KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE
  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
  PURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE
  PROGRAM IS WITH YOU.  SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME
  THE COST OF ALL NECESSARY SERVICING, REPAIR OR CORRECTION.

\item[12.] IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN
  WRITING WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MAY MODIFY
  AND/OR REDISTRIBUTE THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU
  FOR DAMAGES, INCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR
  CONSEQUENTIAL DAMAGES ARISING OUT OF THE USE OR INABILITY TO USE THE
  PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF DATA OR DATA BEING
  RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD PARTIES OR A
  FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS), EVEN IF
  SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH
  DAMAGES.

\begin{center}
                     END OF TERMS AND CONDITIONS
\end{center}
\end{description}


\begin{appendix}
\input{faq}
\end{appendix}


\cleardoublepage
\addcontentsline{toc}{chapter}{Bibliography}

\bibliography{lit}
\bibliographystyle{plain}

\end{document}
